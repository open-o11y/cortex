<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.72.0"><meta name=ROBOTS content="INDEX, FOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Cortex Arguments | Cortex</title><meta property="og:title" content="Cortex Arguments"><meta property="og:description" content="General Notes Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.
Duration arguments should be specified with a unit like 5s or 3h."><meta property="og:type" content="article"><meta property="og:url" content="/docs/configuration/arguments/"><meta property="og:image" content="/images/logo-twitter-card.jpg"><meta property="og:site_name" content="Cortex"><meta itemprop=name content="Cortex Arguments"><meta itemprop=description content="General Notes Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.
Duration arguments should be specified with a unit like 5s or 3h."><meta itemprop=wordCount content="4262"><meta itemprop=image content="/images/logo-twitter-card.jpg"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/images/logo-twitter-card.jpg"><meta name=twitter:title content="Cortex Arguments"><meta name=twitter:description content="General Notes Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.
Duration arguments should be specified with a unit like 5s or 3h."><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-63872299-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=preload href=/scss/main.min.e90eaa454320b057abaa93e650772218ea4d1e3c83e8c45ecd880c9ee9f60107.css as=style><link href=/scss/main.min.e90eaa454320b057abaa93e650772218ea4d1e3c83e8c45ecd880c9ee9f60107.css rel=stylesheet integrity><link href=/css/offline-search.css rel=stylesheet><script src=https://code.jquery.com/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.1.6/lunr.js></script><script src=/js/offline-search.js></script><title>Cortex Arguments | Cortex</title></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar navbar-nocover"><a id=cortex-logo class=navbar-brand href=/><span class=navbar-logo><svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="-17.92 -14.92 1191.84 462.84"><defs><style>.cls-1{fill:#fff}</style></defs><path d="M214.531 8.017C99.353 8.017 5.65 101.72 5.65 216.899S99.353 425.78 214.531 425.78s208.882-93.704 208.882-208.882S329.71 8.017 214.531 8.017zm0 408.558c-110.102.0-199.676-89.574-199.676-199.676S104.429 17.222 214.53 17.222 414.208 106.797 414.208 216.9 324.633 416.575 214.53 416.575z" class="cls-1"/><circle cx="327.452" cy="221.633" r="34.571" class="cls-1"/><circle cx="213.713" cy="353.584" r="34.571" class="cls-1"/><path d="M299.992 167.913l-59-56.05a34.578 34.578.0 10-4.343 4.34l57.828 54.937a60.158 60.158.0 00-27.168 49.123h-12.97l-23.456-67.02-26.055 64.718H175.73l-24.724 57.22-21.808-54.524-.063.025v-.586h-22.048a34.582 34.582.0 10-.275 6.138h18.005l25.97 64.925 28.977-67.06h29.207l21.51-53.424 19.503 55.725H267.5a60.173 60.173.0 0025.202 44.11l-56.52 56.52 4.34 4.338 57.492-57.492a60.155 60.155.0 101.977-105.963zm81.481 53.515a54.02 54.02.0 11-54.022-54.02 54.083 54.083.0 0154.022 54.02zm175.707 42.568q-8.797 8.178-24.405 8.177a34.858 34.858.0 01-17.095-3.965 33.188 33.188.0 01-11.643-10.529 46.374 46.374.0 01-6.566-14.99 71.134 71.134.0 01-2.105-17.341 86.99 86.99.0 011.982-18.706 46.804 46.804.0 016.565-15.98 34.028 34.028.0 0112.263-11.149 7.675-4.21 19.077-4.212 13.38.0 21.306 6.69 7.927 6.689 10.405 18.829h21.803a50.76 50.76.0 00-5.946-19.696 44.06 44.06.0 00-12.015-13.75 49.842 49.842.0 00-16.848-8.051 77.44 77.44.0 00-20.44-2.601q-15.114.0-26.509 5.326a52.935 52.935.0 00-18.952 14.617 62.165 62.165.0 00-11.273 21.8 94.013 94.013.0 00-3.717 26.883 86.195 86.195.0 003.84 26.386 57.783 57.783.0 0011.397 20.686 50.138 50.138.0 0018.829 13.38 66.766 66.766.0 0025.891 4.705 24.527.0 38.772-12.882 14.245-12.878 17.715-36.668h-21.556q-1.986 14.867-10.776 23.041zm157.44-87.828a56.338 56.338.0 00-19.447-14.244q-11.52-5.203-26.882-5.203-15.115.0-26.756 5.203a56.009 56.009.0 00-19.573 14.244 59.75 59.75.0 00-11.892 21.307 85.299 85.299.0 00-3.965 26.386 84.117 84.117.0 003.965 26.262 59.853 59.853.0 0011.892 21.183 54.61 54.61.0 0019.573 14.12 11.643 5.077 26.756 5.08 15.36.0 26.882-5.08a54.908 54.908.0 0019.447-14.12 59.95 59.95.0 0011.892-21.183 84.181 84.181.0 003.965-26.262 85.364 85.364.0 00-3.965-26.386 59.846 59.846.0 00-11.892-21.307zm-9.538 68.38a43.305 43.305.0 01-8.548 15.113 37.061 37.061.0 01-12.759 9.29 38.825 38.825.0 01-30.968.0 37.003 37.003.0 01-12.76-9.29 43.209 43.209.0 01-8.547-15.114 70.669 70.669.0 010-41.373 44.634 44.634.0 018.547-15.237 36.428 36.428.0 0112.76-9.415 38.826 38.826.0 0130.968.0 36.484 36.484.0 0112.76 9.415 44.735 44.735.0 018.547 15.237 70.624 70.624.0 010 41.373zm81.141-80.89q-11.147 7.434-18.83 23.041h-.493v-27.005h-19.82V287.78h21.057v-56.984a87.528 87.528.0 012.478-21.924 41.993 41.993.0 017.93-16.228 33.951 33.951.0 0114.368-10.158q8.919-3.468 21.555-3.468V156.72q-17.097-.493-28.245 6.937zm80.761-42.366h-21.06v38.402h-21.8v18.581h21.8v81.51a48.668 48.668.0 001.734 14.37 17.432 17.432.0 005.326 8.423 20.57 20.57.0 009.415 4.088 75.59 75.59.0 0013.999 1.115h16.104v-18.582h-9.664a70.335 70.335.0 01-8.05-.37 10.361 10.361.0 01-4.833-1.611 6.108 6.108.0 01-2.354-3.469 23.006 23.006.0 01-.617-5.946v-79.528h25.518v-18.581h-25.518zm148.522 60.452a56.135 56.135.0 00-18.085-17.962q-11.276-7.063-28.367-7.06a58.263 58.263.0 00-24.155 4.953 56.796 56.796.0 00-19.079 13.875 63.949 63.949.0 00-12.51 21.058 77.064 77.064.0 00-4.461 26.758 102.521 102.521.0 004.338 27.004 58.87 58.87.0 0011.519 21.307 52.43 52.43.0 0018.953 13.873 11.272 4.954 26.632 4.955 21.8.0 36.173-10.901 14.364-10.898 18.58-32.455h-20.81q-2.73 12.635-11.272 18.829-8.549 6.198-21.927 6.195a43.577 43.577.0 01-18.085-3.468 35.417 35.417.0 01-12.636-9.291 36.127 36.127.0 01-7.184-13.38 50.746 50.746.0 01-1.981-15.98h95.879a102.07 102.07.0 00-2.107-24.526 71.064 71.064.0 00-9.415-23.784zm-84.357 29.73a43.81 43.81.0 013.219-13.999 37.354 37.354.0 0034.013 34.013.0 111.272-7.803 000 114.74-2.85 36.062 36.062 002.85 36.492 36.492.0 111.398 0036.107.0 17.68 11.52 43.253 0013.345 14.122zm170.95 7.184 44.1-58.964h-25.271l-31.961 44.843-30.721-44.843h-27.006l44.595 60.698-48.063 67.389h25.518l35.677-53.019 35.676 53.019h27.006l-49.55-69.123z" class="cls-1"/></svg></span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/docs/><span class=active>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a href=https://twitter.com/cortexmetrics class="nav-link active"><span class=active><i class="fab fa-fw fa-twitter"></i>Twitter</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a href=https://github.com/cortexproject class="nav-link active"><span class=active><i class="fab fa-fw fa-github"></i>Github</span></a></li></ul></div><div class="navbar-nav d-none d-md-block"><div id=search-nav-container><input type=search id=search-input autocomplete=off class="form-control td-search-input" placeholder="&#xf002 Search this site…" autocomplete=on><div id=search-results class=container></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><nav class="collapse td-sidebar-nav pt-2 pl-4" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/ class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Documentation</a></li><ul><li class="collapse show" id=docs><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/getting-started/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Getting Started</a></li><ul><li class=collapse id=docsgetting-started><a class="td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedgetting-started-chunks-storage href=/docs/getting-started/getting-started-chunks-storage/>Chunks Storage</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedgetting-started-blocks-storage href=/docs/getting-started/getting-started-blocks-storage/>Blocks Storage</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsgetting-startedgetting-started-with-gossiped-ring href=/docs/getting-started/getting-started-with-gossiped-ring/>Gossip Ring</a></li></ul></ul><a class="td-sidebar-link td-sidebar-link__page" id=m-docsarchitecture href=/docs/architecture/>Architecture</a><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/production/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Production</a></li><ul><li class=collapse id=docsproduction><a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductionrunning-in-production href=/docs/production/running-in-production/>Running Cortex in Production</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductionaws href=/docs/production/aws/>Running Cortex with AWS Services</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductioncassandra href=/docs/production/cassandra/>Running Cortex with Cassandra</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductioncaching href=/docs/production/caching/>Caching in Cortex</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductioningesters-with-wal href=/docs/production/ingesters-with-wal/>Ingesters with WAL</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductiontls href=/docs/production/tls/>Securing communication between Cortex components with TLS</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductionauth href=/docs/production/auth/>Authentication and Authorisation</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproductionha-pair-handling href=/docs/production/ha-pair-handling/>Config for sending HA Pairs data to Cortex</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/api/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">HTTP API</a></li><ul><li class=collapse id=docsapi></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/guides/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Guides</a></li><ul><li class=collapse id=docsguides><a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidesdeleting-series href=/docs/guides/deleting-series/>Deleting Series</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidesgrpc-based-plugin href=/docs/guides/grpc-based-plugin/>gRPC storage plugin</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidesruler-sharding href=/docs/guides/ruler-sharding/>Config for horizontally scaling the Ruler</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidesshuffle-sharding href=/docs/guides/shuffle-sharding/>Shuffle Sharding</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguideszone-aware-replication href=/docs/guides/zone-aware-replication/>Zone Aware Replication</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguideskubernetes href=/docs/guides/kubernetes/>Running Cortex on Kubernetes</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidestracing href=/docs/guides/tracing/>Tracing</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidesingesters-rolling-updates href=/docs/guides/ingesters-rolling-updates/>Ingesters rolling updates</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsguidescapacity-planning href=/docs/guides/capacity-planning/>Capacity Planning</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/configuration/ class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Configuration</a></li><ul><li class="collapse show" id=docsconfiguration><a class="td-sidebar-link td-sidebar-link__page" id=m-docsconfigurationconfiguration-file href=/docs/configuration/configuration-file/>Configuration file</a>
<a class="td-sidebar-link td-sidebar-link__page active" id=m-docsconfigurationarguments href=/docs/configuration/arguments/>Cortex Arguments Explained</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsconfigurationprometheus-frontend href=/docs/configuration/prometheus-frontend/>Prometheus Frontend</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsconfigurationschema-configuration href=/docs/configuration/schema-configuration/>Schema Configuration</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsconfigurationsingle-process-config href=/docs/configuration/single-process-config/>Single-process</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsconfigurationv1guarantees href=/docs/configuration/v1guarantees/>v1.x Guarantees</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/operations/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Operations</a></li><ul><li class=collapse id=docsoperations><a class="td-sidebar-link td-sidebar-link__page" id=m-docsoperationsquery-auditor href=/docs/operations/query-auditor/>Query Auditor (tool)</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsoperationsquery-tee href=/docs/operations/query-tee/>Query Tee (service)</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsoperationsrequests-mirroring-to-secondary-cluster href=/docs/operations/requests-mirroring-to-secondary-cluster/>Requests mirroring to secondary cluster</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsoperationsscaling-query-frontend href=/docs/operations/scaling-query-frontend/>Scaling the Query Frontend</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/blocks-storage/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Blocks Storage</a></li><ul><li class=collapse id=docsblocks-storage><a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagequerier href=/docs/blocks-storage/querier/>Querier</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagestore-gateway href=/docs/blocks-storage/store-gateway/>Store-gateway</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagecompactor href=/docs/blocks-storage/compactor/>Compactor</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storageproduction-tips href=/docs/blocks-storage/production-tips/>Production tips</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagebinary-index-header href=/docs/blocks-storage/binary-index-header/>Binary index-header</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagemigrate-cortex-cluster-from-chunks-to-blocks href=/docs/blocks-storage/migrate-cortex-cluster-from-chunks-to-blocks/>Migrate Cortex cluster from chunks to blocks</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storageconvert-long-term-storage-from-chunks-to-blocks href=/docs/blocks-storage/convert-long-term-storage-from-chunks-to-blocks/>Convert long-term storage from chunks to blocks</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsblocks-storagemigrate-storage-from-thanos-and-prometheus href=/docs/blocks-storage/migrate-storage-from-thanos-and-prometheus/>Migrate the storage from Thanos and Prometheus</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/contributing/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Contributing</a></li><ul><li class=collapse id=docscontributing><a class="td-sidebar-link td-sidebar-link__page" id=m-docscontributingdesign-patterns-and-code-conventions href=/docs/contributing/design-patterns-and-code-conventions/>Design patterns and Code conventions</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docscontributinghow-to-run-the-website-locally href=/docs/contributing/how-to-run-the-website-locally/>How to run the website locally</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docscontributinghow-to-upgrade-golang-version href=/docs/contributing/how-to-upgrade-golang-version/>How to upgrade Golang version</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docscontributinghow-integration-tests-work href=/docs/contributing/how-integration-tests-work/>How integration tests work</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docscontributinghow-to-update-the-build-image href=/docs/contributing/how-to-update-the-build-image/>How to update the build image</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/case-studies/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Case Studies</a></li><ul><li class=collapse id=docscase-studies><a class="td-sidebar-link td-sidebar-link__page" id=m-docscase-studiesgojek href=/docs/case-studies/gojek/>Gojek</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docscase-studiesrewe-digital href=/docs/case-studies/rewe-digital/>REWE digital</a></li></ul></ul><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/governance/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Governance</a></li><ul><li class=collapse id=docsgovernance><a class="td-sidebar-link td-sidebar-link__page" id=m-docsgovernancehow-to-add-a-maintainer href=/docs/governance/how-to-add-a-maintainer/>How to add a maintainer</a></li></ul></ul><a class="td-sidebar-link td-sidebar-link__page" id=m-docschangelog href=/docs/changelog/>Changelog</a><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/docs/proposals/ class="align-left pl-0 pr-2 collapsed td-sidebar-link td-sidebar-link__section">Proposals</a></li><ul><li class=collapse id=docsproposals><a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsblocks-storage-sharding href=/docs/proposals/blocks-storage-sharding/>Blocks storage sharding</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsdocumentation-versioning href=/docs/proposals/documentation-versioning/>Documentation Versioning</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsgeneralize-modules href=/docs/proposals/generalize-modules/>Generalize Modules Service to make it extensible</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalshttp-api-design href=/docs/proposals/http-api-design/>HTTP API Design</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsingesters-migration href=/docs/proposals/ingesters-migration/>Migrating ingesters from chunks to blocks and back.</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsscalable-query-frontend href=/docs/proposals/scalable-query-frontend/>Scalable Query Frontend</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsshuffle-sharding-and-zone-awareness href=/docs/proposals/shuffle-sharding-and-zone-awareness/>Shuffle sharding and zone awareness</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalsshuffle-sharding-on-the-read-path href=/docs/proposals/shuffle-sharding-on-the-read-path/>Shuffle sharding on the read path</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsproposalssupport-metadata-api href=/docs/proposals/support-metadata-api/>Support metadata API</a></li></ul></ul><a class="td-sidebar-link td-sidebar-link__page" id=m-docscode-of-conduct href=/docs/code-of-conduct/>Code of Conduct</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-docsroadmap href=/docs/roadmap/>Roadmap</a></li></ul></ul></nav></div></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/cortexproject/cortex/edit/master/docs/configuration/arguments.md target=_blank><i class="fa fa-edit fa-fw"></i>Edit this page</a>
<a href="https://github.com/cortexproject/cortex/issues/new?title=Cortex%20Arguments" target=_blank><i class="fab fa-github fa-fw"></i>Create documentation issue</a>
<a href=https://github.com/cortexproject/cortex/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i>Create project issue</a></div><nav id=TableOfContents><ul><li><a href=#general-notes>General Notes</a></li><li><a href=#querier>Querier</a></li><li><a href=#querier-and-ruler>Querier and Ruler</a></li><li><a href=#query-frontend>Query Frontend</a></li><li><a href=#distributor>Distributor</a><ul><li><a href=#ringha-tracker-store>Ring/HA Tracker Store</a></li><li><a href=#ha-tracker>HA Tracker</a></li></ul></li><li><a href=#ingester>Ingester</a><ul><li></li></ul></li><li><a href=#runtime-configuration-file>Runtime Configuration file</a></li><li><a href=#ingester-distributor--querier-limits>Ingester, Distributor & Querier limits.</a></li><li><a href=#storage>Storage</a></li><li><a href=#dns-service-discovery>DNS Service Discovery</a><ul><li><a href=#supported-discovery-modes>Supported discovery modes</a></li></ul></li><li><a href=#logging-of-ip-of-reverse-proxy>Logging of IP of reverse proxy</a></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><nav aria-label=breadcrumb class="d-none d-md-block d-print-none"><ol class="breadcrumb spb-1"><li class=breadcrumb-item><a href=/docs/>Documentation</a></li><li class=breadcrumb-item><a href=/docs/configuration/>Configuration</a></li><li class="breadcrumb-item active" aria-current=page><a href=/docs/configuration/arguments/>Cortex Arguments Explained</a></li></ol></nav><div class=td-content><h1>Cortex Arguments</h1><h2 id=general-notes>General Notes</h2><p>Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.</p><p>Duration arguments should be specified with a unit like <code>5s</code> or <code>3h</code>. Valid time units are &ldquo;ms&rdquo;, &ldquo;s&rdquo;, &ldquo;m&rdquo;, &ldquo;h&rdquo;.</p><h2 id=querier>Querier</h2><ul><li><p><code>-querier.max-concurrent</code></p><p>The maximum number of top-level PromQL queries that will execute at the same time, per querier process.
If using the query frontend, this should be set to at least (<code>-querier.worker-parallelism</code> * number of query frontend replicas). Otherwise queries may queue in the queriers and not the frontend, which will affect QoS. Alternatively, consider using <code>-querier.worker-match-max-concurrent</code> to force worker parallelism to match <code>-querier.max-concurrent</code>.</p></li><li><p><code>-querier.query-parallelism</code></p><p>This refers to database queries against the store (e.g. Bigtable or DynamoDB). This is the max subqueries run in parallel per higher-level query.</p></li><li><p><code>-querier.timeout</code></p><p>The timeout for a top-level PromQL query.</p></li><li><p><code>-querier.max-samples</code></p><p>Maximum number of samples a single query can load into memory, to avoid blowing up on enormous queries.</p></li></ul><p>The next three options only apply when the querier is used together with the Query Frontend:</p><ul><li><p><code>-querier.frontend-address</code></p><p>Address of query frontend service, used by workers to find the frontend which will give them queries to execute.</p></li><li><p><code>-querier.dns-lookup-period</code></p><p>How often the workers will query DNS to re-check where the frontend is.</p></li><li><p><code>-querier.worker-parallelism</code></p><p>Number of simultaneous queries to process, per query frontend.
See note on <code>-querier.max-concurrent</code></p></li><li><p><code>-querier.worker-match-max-concurrent</code></p><p>Force worker concurrency to match the -querier.max-concurrent option. Overrides <code>-querier.worker-parallelism</code>.
See note on <code>-querier.max-concurrent</code></p></li></ul><h2 id=querier-and-ruler>Querier and Ruler</h2><p>The ingester query API was improved over time, but defaults to the old behaviour for backwards-compatibility. For best results both of these next two flags should be set to <code>true</code>:</p><ul><li><p><code>-querier.batch-iterators</code></p><p>This uses iterators to execute query, as opposed to fully materialising the series in memory, and fetches multiple results per loop.</p></li><li><p><code>-querier.ingester-streaming</code></p><p>Use streaming RPCs to query ingester, to reduce memory pressure in the ingester.</p></li><li><p><code>-querier.iterators</code></p><p>This is similar to <code>-querier.batch-iterators</code> but less efficient.
If both <code>iterators</code> and <code>batch-iterators</code> are <code>true</code>, <code>batch-iterators</code> will take precedence.</p></li><li><p><code>-promql.lookback-delta</code></p><p>Time since the last sample after which a time series is considered stale and ignored by expression evaluations.</p></li></ul><h2 id=query-frontend>Query Frontend</h2><ul><li><p><code>-querier.parallelise-shardable-queries</code></p><p>If set to true, will cause the query frontend to mutate incoming queries when possible by turning <code>sum</code> operations into sharded <code>sum</code> operations. This requires a shard-compatible schema (v10+). An abridged example:
<code>sum by (foo) (rate(bar{baz=”blip”}[1m]))</code> -></p><pre><code>sum by (foo) (
 sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”0of16”}[1m])) or
 sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”1of16”}[1m])) or
 ...
 sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”15of16”}[1m]))
)
</code></pre><p>When enabled, the query-frontend requires a schema config to determine how/when to shard queries, either from a file or from flags (i.e. by the <code>-schema-config-file</code> CLI flag). This is the same schema config the queriers consume.
It&rsquo;s also advised to increase downstream concurrency controls as well to account for more queries of smaller sizes:</p><ul><li><code>querier.max-outstanding-requests-per-tenant</code></li><li><code>querier.max-query-parallelism</code></li><li><code>querier.max-concurrent</code></li><li><code>server.grpc-max-concurrent-streams</code> (for both query-frontends and queriers)</li></ul><p>Furthermore, both querier and query-frontend components require the <code>querier.query-ingesters-within</code> parameter to know when to start sharding requests (ingester queries are not sharded). It&rsquo;s recommended to align this with <code>ingester.max-chunk-age</code>.</p><p>Instrumentation (traces) also scale with the number of sharded queries and it&rsquo;s suggested to account for increased throughput there as well (for instance via <code>JAEGER_REPORTER_MAX_QUEUE_SIZE</code>).</p></li><li><p><code>-querier.align-querier-with-step</code></p><p>If set to true, will cause the query frontend to mutate incoming queries and align their start and end parameters to the step parameter of the query. This improves the cacheability of the query results.</p></li><li><p><code>-querier.split-queries-by-day</code></p><p>If set to true, will cause the query frontend to split multi-day queries into multiple single-day queries and execute them in parallel.</p></li><li><p><code>-querier.cache-results</code></p><p>If set to true, will cause the querier to cache query results. The cache will be used to answer future, overlapping queries. The query frontend calculates extra queries required to fill gaps in the cache.</p></li><li><p><code>-frontend.max-cache-freshness</code></p><p>When caching query results, it is desirable to prevent the caching of very recent results that might still be in flux. Use this parameter to configure the age of results that should be excluded.</p></li><li><p><code>-frontend.memcached.{hostname, service, timeout}</code></p><p>Use these flags to specify the location and timeout of the memcached cluster used to cache query results.</p></li><li><p><code>-frontend.redis.{endpoint, timeout}</code></p><p>Use these flags to specify the location and timeout of the Redis service used to cache query results.</p></li></ul><h2 id=distributor>Distributor</h2><ul><li><p><code>-distributor.shard-by-all-labels</code></p><p>In the original Cortex design, samples were sharded amongst distributors by the combination of (userid, metric name). Sharding by metric name was designed to reduce the number of ingesters you need to hit on the read path; the downside was that you could hotspot the write path.</p><p>In hindsight, this seems like the wrong choice: we do many orders of magnitude more writes than reads, and ingester reads are in-memory and cheap. It seems the right thing to do is to use all the labels to shard, improving load balancing and support for very high cardinality metrics.</p><p>Set this flag to <code>true</code> for the new behaviour.</p><p>Important to note is that when setting this flag to <code>true</code>, it has to be set on both the distributor and the querier (called <code>-distributor.shard-by-all-labels</code> on Querier as well). If the flag is only set on the distributor and not on the querier, you will get incomplete query results because not all ingesters are queried.</p><p><strong>Upgrade notes</strong>: As this flag also makes all queries always read from all ingesters, the upgrade path is pretty trivial; just enable the flag. When you do enable it, you&rsquo;ll see a spike in the number of active series as the writes are &ldquo;reshuffled&rdquo; amongst the ingesters, but over the next stale period all the old series will be flushed, and you should end up with much better load balancing. With this flag enabled in the queriers, reads will always catch all the data from all ingesters.</p></li><li><p><code>-distributor.extra-query-delay</code>
This is used by a component with an embedded distributor (Querier and Ruler) to control how long to wait until sending more than the minimum amount of queries needed for a successful response.</p></li><li><p><code>distributor.ha-tracker.enable-for-all-users</code>
Flag to enable, for all users, handling of samples with external labels identifying replicas in an HA Prometheus setup. This defaults to false, and is technically defined in the Distributor limits.</p></li><li><p><code>distributor.ha-tracker.enable</code>
Enable the distributors HA tracker so that it can accept samples from Prometheus HA replicas gracefully (requires labels). Global (for distributors), this ensures that the necessary internal data structures for the HA handling are created. The option <code>enable-for-all-users</code> is still needed to enable ingestion of HA samples for all users.</p></li><li><p><code>distributor.drop-label</code>
This flag can be used to specify label names that to drop during sample ingestion within the distributor and can be repeated in order to drop multiple labels.</p></li></ul><h3 id=ringha-tracker-store>Ring/HA Tracker Store</h3><p>The KVStore client is used by both the Ring and HA Tracker (HA Tracker doesn&rsquo;t support memberlist as KV store).</p><ul><li><code>{ring,distributor.ha-tracker}.prefix</code>
The prefix for the keys in the store. Should end with a /. For example with a prefix of foo/, the key bar would be stored under foo/bar.</li><li><code>{ring,distributor.ha-tracker}.store</code>
Backend storage to use for the HA Tracker (consul, etcd, inmemory, multi).</li><li><code>{ring,distributor.ring}.store</code>
Backend storage to use for the Ring (consul, etcd, inmemory, memberlist, multi).</li></ul><h4 id=consul>Consul</h4><p>By default these flags are used to configure Consul used for the ring. To configure Consul for the HA tracker,
prefix these flags with <code>distributor.ha-tracker.</code></p><ul><li><code>consul.hostname</code>
Hostname and port of Consul.</li><li><code>consul.acl-token</code>
ACL token used to interact with Consul.</li><li><code>consul.client-timeout</code>
HTTP timeout when talking to Consul.</li><li><code>consul.consistent-reads</code>
Enable consistent reads to Consul.</li></ul><h4 id=etcd>etcd</h4><p>By default these flags are used to configure etcd used for the ring. To configure etcd for the HA tracker,
prefix these flags with <code>distributor.ha-tracker.</code></p><ul><li><code>etcd.endpoints</code>
The etcd endpoints to connect to.</li><li><code>etcd.dial-timeout</code>
The timeout for the etcd connection.</li><li><code>etcd.max-retries</code>
The maximum number of retries to do for failed ops.</li><li><code>etcd.tls-enabled</code>
Enable TLS.</li><li><code>etcd.tls-cert-path</code>
The TLS certificate file path.</li><li><code>etcd.tls-key-path</code>
The TLS private key file path.</li><li><code>etcd.tls-ca-path</code>
The trusted CA file path.</li><li><code>etcd.tls-insecure-skip-verify</code>
Skip validating server certificate.</li></ul><h4 id=memberlist>memberlist</h4><p>Warning: memberlist KV works only for the <a href=/docs/architecture/#the-hash-ring>hash ring</a>, not for the HA Tracker, because propagation of changes is too slow for HA Tracker purposes.</p><p>When using memberlist-based KV store, each node maintains its own copy of the hash ring.
Updates generated locally, and received from other nodes are merged together to form the current state of the ring on the node.
Updates are also propagated to other nodes.
All nodes run the following two loops:</p><ol><li>Every &ldquo;gossip interval&rdquo;, pick random &ldquo;gossip nodes&rdquo; number of nodes, and send recent ring updates to them.</li><li>Every &ldquo;push/pull sync interval&rdquo;, choose random single node, and exchange full ring information with it (push/pull sync). After this operation, rings on both nodes are the same.</li></ol><p>When a node receives a ring update, node will merge it into its own ring state, and if that resulted in a change, node will add that update to the list of gossiped updates.
Such update will be gossiped <code>R * log(N+1)</code> times by this node (R = retransmit multiplication factor, N = number of gossiping nodes in the cluster).</p><p>If you find the propagation to be too slow, there are some tuning possibilities (default values are memberlist settings for LAN networks):</p><ul><li>Decrease gossip interval (default: 200ms)</li><li>Increase gossip nodes (default 3)</li><li>Decrease push/pull sync interval (default 30s)</li><li>Increase retransmit multiplication factor (default 4)</li></ul><p>To find propagation delay, you can use <code>cortex_ring_oldest_member_timestamp{state="ACTIVE"}</code> metric.</p><p>Flags for configuring KV store based on memberlist library:</p><ul><li><code>memberlist.nodename</code>
Name of the node in memberlist cluster. Defaults to hostname.</li><li><code>memberlist.randomize-node-name</code>
This flag adds extra random suffix to the node name used by memberlist. Defaults to true. Using random suffix helps to prevent issues when running multiple memberlist nodes on the same machine, or when node names are reused (eg. in stateful sets).</li><li><code>memberlist.retransmit-factor</code>
Multiplication factor used when sending out messages (factor * log(N+1)). If not set, default value is used.</li><li><code>memberlist.join</code>
Other cluster members to join. Can be specified multiple times.</li><li><code>memberlist.min-join-backoff</code>, <code>memberlist.max-join-backoff</code>, <code>memberlist.max-join-retries</code>
These flags control backoff settings when joining the cluster.</li><li><code>memberlist.abort-if-join-fails</code>
If this node fails to join memberlist cluster, abort.</li><li><code>memberlist.rejoin-interval</code>
How often to try to rejoin the memberlist cluster. Defaults to 0, no rejoining. Occasional rejoin may be useful in some configurations, and is otherwise harmless.</li><li><code>memberlist.left-ingesters-timeout</code>
How long to keep LEFT ingesters in the ring. Note: this is only used for gossiping, LEFT ingesters are otherwise invisible.</li><li><code>memberlist.leave-timeout</code>
Timeout for leaving memberlist cluster.</li><li><code>memberlist.gossip-interval</code>
How often to gossip with other cluster members. Uses memberlist LAN defaults if 0.</li><li><code>memberlist.gossip-nodes</code>
How many nodes to gossip with in each gossip interval. Uses memberlist LAN defaults if 0.</li><li><code>memberlist.pullpush-interval</code>
How often to use pull/push sync. Uses memberlist LAN defaults if 0.</li><li><code>memberlist.bind-addr</code>
IP address to listen on for gossip messages. Multiple addresses may be specified. Defaults to 0.0.0.0.</li><li><code>memberlist.bind-port</code>
Port to listen on for gossip messages. Defaults to 7946.</li><li><code>memberlist.packet-dial-timeout</code>
Timeout used when connecting to other nodes to send packet.</li><li><code>memberlist.packet-write-timeout</code>
Timeout for writing &lsquo;packet&rsquo; data.</li><li><code>memberlist.transport-debug</code>
Log debug transport messages. Note: global log.level must be at debug level as well.</li><li><code>memberlist.gossip-to-dead-nodes-time</code>
How long to keep gossiping to the nodes that seem to be dead. After this time, dead node is removed from list of nodes. If &ldquo;dead&rdquo; node appears again, it will simply join the cluster again, if its name is not reused by other node in the meantime. If the name has been reused, such a reanimated node will be ignored by other members.</li><li><code>memberlist.dead-node-reclaim-time</code>
How soon can dead&rsquo;s node name be reused by a new node (using different IP). Disabled by default, name reclaim is not allowed until <code>gossip-to-dead-nodes-time</code> expires. This can be useful to set to low numbers when reusing node names, eg. in stateful sets.
If memberlist library detects that new node is trying to reuse the name of previous node, it will log message like this: <code>Conflicting address for ingester-6. Mine: 10.44.12.251:7946 Theirs: 10.44.12.54:7946 Old state: 2</code>. Node states are: &ldquo;alive&rdquo; = 0, &ldquo;suspect&rdquo; = 1 (doesn&rsquo;t respond, will be marked as dead if it doesn&rsquo;t respond), &ldquo;dead&rdquo; = 2.</li></ul><h4 id=multi-kv>Multi KV</h4><p>This is a special key-value implementation that uses two different KV stores (eg. consul, etcd or memberlist). One of them is always marked as primary, and all reads and writes go to primary store. Other one, secondary, is only used for writes. The idea is that operator can use multi KV store to migrate from primary to secondary store in runtime.</p><p>For example, migration from Consul to Etcd would look like this:</p><ul><li>Set <code>ring.store</code> to use <code>multi</code> store. Set <code>-multi.primary=consul</code> and <code>-multi.secondary=etcd</code>. All consul and etcd settings must still be specified.</li><li>Start all Cortex microservices. They will still use Consul as primary KV, but they will also write share ring via etcd.</li><li>Operator can now use &ldquo;runtime config&rdquo; mechanism to switch primary store to etcd.</li><li>After all Cortex microservices have picked up new primary store, and everything looks correct, operator can now shut down Consul, and modify Cortex configuration to use <code>-ring.store=etcd</code> only.</li><li>At this point, Consul can be shut down.</li></ul><p>Multi KV has following parameters:</p><ul><li><code>multi.primary</code> - name of primary KV store. Same values as in <code>ring.store</code> are supported, except <code>multi</code>.</li><li><code>multi.secondary</code> - name of secondary KV store.</li><li><code>multi.mirror-enabled</code> - enable mirroring of values to secondary store, defaults to true</li><li><code>multi.mirror-timeout</code> - wait max this time to write to secondary store to finish. Default to 2 seconds. Errors writing to secondary store are not reported to caller, but are logged and also reported via <code>cortex_multikv_mirror_write_errors_total</code> metric.</li></ul><p>Multi KV also reacts on changes done via runtime configuration. It uses this section:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#204a87;font-weight:700>multi_kv_config</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>mirror-enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>primary</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>memberlist<span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>Note that runtime configuration values take precedence over command line options.</p><h3 id=ha-tracker>HA Tracker</h3><p>HA tracking has two of its own flags:</p><ul><li><code>distributor.ha-tracker.cluster</code>
Prometheus label to look for in samples to identify a Prometheus HA cluster. (default &ldquo;cluster&rdquo;)</li><li><code>distributor.ha-tracker.replica</code>
Prometheus label to look for in samples to identify a Prometheus HA replica. (default &ldquo;<code>__replica__</code>&rdquo;)</li></ul><p>It&rsquo;s reasonable to assume people probably already have a <code>cluster</code> label, or something similar. If not, they should add one along with <code>__replica__</code> via external labels in their Prometheus config. If you stick to these default values your Prometheus config could look like this (<code>POD_NAME</code> is an environment variable which must be set by you):</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#204a87;font-weight:700>global</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>external_labels</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cluster</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>clustername<span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>__replica__</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>$POD_NAME<span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>HA Tracking looks for the two labels (which can be overwritten per user)</p><p>It also talks to a KVStore and has it&rsquo;s own copies of the same flags used by the Distributor to connect to for the ring.</p><ul><li><code>distributor.ha-tracker.failover-timeout</code>
If we don&rsquo;t receive any samples from the accepted replica for a cluster in this amount of time we will failover to the next replica we receive a sample from. This value must be greater than the update timeout (default 30s)</li><li><code>distributor.ha-tracker.store</code>
Backend storage to use for the ring (consul, etcd, inmemory, multi). Inmemory only works if there is a single distributor and ingester running in the same process (for testing purposes). (default &ldquo;consul&rdquo;)</li><li><code>distributor.ha-tracker.update-timeout</code>
Update the timestamp in the KV store for a given cluster/replica only after this amount of time has passed since the current stored timestamp. (default 15s)</li></ul><h2 id=ingester>Ingester</h2><ul><li><p><code>-ingester.max-chunk-age</code></p><p>The maximum duration of a timeseries chunk in memory. If a timeseries runs for longer than this the current chunk will be flushed to the store and a new chunk created. (default 12h)</p></li><li><p><code>-ingester.max-chunk-idle</code></p><p>If a series doesn&rsquo;t receive a sample for this duration, it is flushed and removed from memory.</p></li><li><p><code>-ingester.max-stale-chunk-idle</code></p><p>If a series receives a <a href=https://www.robustperception.io/staleness-and-promql>staleness marker</a>, then we wait for this duration to get another sample before we close and flush this series, removing it from memory. You want it to be at least 2x the scrape interval as you don&rsquo;t want a single failed scrape to cause a chunk flush.</p></li><li><p><code>-ingester.chunk-age-jitter</code></p><p>To reduce load on the database exactly 12 hours after starting, the age limit is reduced by a varying amount up to this. Don&rsquo;t enable this along with <code>-ingester.spread-flushes</code> (default 0m)</p></li><li><p><code>-ingester.spread-flushes</code></p><p>Makes the ingester flush each timeseries at a specific point in the <code>max-chunk-age</code> cycle. This means multiple replicas of a chunk are very likely to contain the same contents which cuts chunk storage space by up to 66%. Set <code>-ingester.chunk-age-jitter</code> to <code>0</code> when using this option. If a chunk cache is configured (via <code>-store.chunks-cache.memcached.hostname</code>) then duplicate chunk writes are skipped which cuts write IOPs.</p></li><li><p><code>-ingester.join-after</code></p><p>How long to wait in PENDING state during the <a href=/docs/guides/ingesters-rolling-updates/#chunks-storage-with-wal-disabled-hand-over>hand-over process</a> (supported only by the chunks storage). (default 0s)</p></li><li><p><code>-ingester.max-transfer-retries</code></p><p>How many times a LEAVING ingester tries to find a PENDING ingester during the <a href=/docs/guides/ingesters-rolling-updates/#chunks-storage-with-wal-disabled-hand-over>hand-over process</a> (supported only by the chunks storage). Negative value or zero disables hand-over process completely. (default 10)</p></li><li><p><code>-ingester.normalise-tokens</code></p><p>Deprecated. New ingesters always write &ldquo;normalised&rdquo; tokens to the ring. Normalised tokens consume less memory to encode and decode; as the ring is unmarshalled regularly, this significantly reduces memory usage of anything that watches the ring.</p><p>Cortex 0.4.0 is the last version that can <em>write</em> denormalised tokens. Cortex 0.5.0 and above always write normalised tokens.</p><p>Cortex 0.6.0 is the last version that can <em>read</em> denormalised tokens. Starting with Cortex 0.7.0 only normalised tokens are supported, and ingesters writing denormalised tokens to the ring (running Cortex 0.4.0 or earlier with <code>-ingester.normalise-tokens=false</code>) are ignored by distributors. Such ingesters should either switch to using normalised tokens, or be upgraded to Cortex 0.5.0 or later.</p></li><li><p><code>-ingester.chunk-encoding</code></p><p>Pick one of the encoding formats for timeseries data, which have different performance characteristics.
<code>Bigchunk</code> uses the Prometheus V2 code, and expands in memory to arbitrary length.
<code>Varbit</code>, <code>Delta</code> and <code>DoubleDelta</code> use Prometheus V1 code, and are fixed at 1K per chunk.
Defaults to <code>Bigchunk</code> starting version 0.7.0.</p></li><li><p><code>-store.bigchunk-size-cap-bytes</code></p><p>When using bigchunks, start a new bigchunk and flush the old one if the old one reaches this size. Use this setting to limit memory growth of ingesters with a lot of timeseries that last for days.</p></li><li><p><code>-ingester-client.expected-timeseries</code></p><p>When <code>push</code> requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. This should match the <code>max_samples_per_send</code> in your <code>queue_config</code> for Prometheus.</p></li><li><p><code>-ingester-client.expected-samples-per-series</code></p><p>When <code>push</code> requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. Under normal conditions, Prometheus scrapes should arrive with one sample per series.</p></li><li><p><code>-ingester-client.expected-labels</code></p><p>When <code>push</code> requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. The optimum value will depend on how many labels are sent with your timeseries samples.</p></li><li><p><code>-store.chunk-cache.cache-stubs</code></p><p>Where you don&rsquo;t want to cache every chunk written by ingesters, but you do want to take advantage of chunk write deduplication, this option will make ingesters write a placeholder to the cache for each chunk.
Make sure you configure ingesters with a different cache to queriers, which need the whole value.</p></li></ul><h4 id=wal>WAL</h4><ul><li><p><code>-ingester.wal-dir</code>
Directory where the WAL data should be stored and/or recovered from.</p></li><li><p><code>-ingester.wal-enabled</code></p><p>Setting this to <code>true</code> enables writing to WAL during ingestion.</p></li><li><p><code>-ingester.checkpoint-duration</code>
This is the interval at which checkpoints should be created.</p></li><li><p><code>-ingester.recover-from-wal</code>
Set this to <code>true</code> to recover data from an existing WAL. The data is recovered even if WAL is disabled and this is set to <code>true</code>. The WAL dir needs to be set for this.</p></li></ul><h4 id=flusher>Flusher</h4><ul><li><p><code>-flusher.wal-dir</code>
Directory where the WAL data should be recovered from.</p></li><li><p><code>-flusher.concurrent-flushes</code>
Number of concurrent flushes.</p></li><li><p><code>-flusher.flush-op-timeout</code>
Duration after which a flush should timeout.</p></li></ul><h2 id=runtime-configuration-file>Runtime Configuration file</h2><p>Cortex has a concept of &ldquo;runtime config&rdquo; file, which is simply a file that is reloaded while Cortex is running. It is used by some Cortex components to allow operator to change some aspects of Cortex configuration without restarting it. File is specified by using <code>-runtime-config.file=&lt;filename></code> flag and reload period (which defaults to 10 seconds) can be changed by <code>-runtime-config.reload-period=&lt;duration></code> flag. Previously this mechanism was only used by limits overrides, and flags were called <code>-limits.per-user-override-config=&lt;filename></code> and <code>-limits.per-user-override-period=10s</code> respectively. These are still used, if <code>-runtime-config.file=&lt;filename></code> is not specified.</p><p>At the moment, two components use runtime configuration: limits and multi KV store.</p><p>Example runtime configuration file:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#204a87;font-weight:700>overrides</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>tenant1</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ingestion_rate</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>10000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_metric</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>tenant2</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_samples_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1000000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_metric</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>multi_kv_config</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>mirror-enabled</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>false</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>primary</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span>memberlist<span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>When running Cortex on Kubernetes, store this file in a config map and mount it in each services&rsquo; containers. When changing the values there is no need to restart the services, unless otherwise specified.</p><h2 id=ingester-distributor--querier-limits>Ingester, Distributor & Querier limits.</h2><p>Cortex implements various limits on the requests it can process, in order to prevent a single tenant overwhelming the cluster. There are various default global limits which apply to all tenants which can be set on the command line. These limits can also be overridden on a per-tenant basis by using <code>overrides</code> field of runtime configuration file.</p><p>The <code>overrides</code> field is a map of tenant ID (same values as passed in the <code>X-Scope-OrgID</code> header) to the various limits. An example could look like:</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#204a87;font-weight:700>overrides</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>tenant1</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ingestion_rate</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>10000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_metric</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>tenant2</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_samples_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1000000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_metric</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>max_series_per_query</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>100000</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>Valid per-tenant limits are (with their corresponding flags for default values):</p><ul><li><p><code>ingestion_rate_strategy</code> / <code>-distributor.ingestion-rate-limit-strategy</code></p></li><li><p><code>ingestion_rate</code> / <code>-distributor.ingestion-rate-limit</code></p></li><li><p><code>ingestion_burst_size</code> / <code>-distributor.ingestion-burst-size</code></p><p>The per-tenant rate limit (and burst size), in samples per second. It supports two strategies: <code>local</code> (default) and <code>global</code>.</p><p>The <code>local</code> strategy enforces the limit on a per distributor basis, actual effective rate limit will be N times higher, where N is the number of distributor replicas.</p><p>The <code>global</code> strategy enforces the limit globally, configuring a per-distributor local rate limiter as <code>ingestion_rate / N</code>, where N is the number of distributor replicas (it&rsquo;s automatically adjusted if the number of replicas change). The <code>ingestion_burst_size</code> refers to the per-distributor local rate limiter (even in the case of the <code>global</code> strategy) and should be set at least to the maximum number of samples expected in a single push request. For this reason, the <code>global</code> strategy requires that push requests are evenly distributed across the pool of distributors; if you use a load balancer in front of the distributors you should be already covered, while if you have a custom setup (ie. an authentication gateway in front) make sure traffic is evenly balanced across distributors.</p><p>The <code>global</code> strategy requires the distributors to form their own ring, which is used to keep track of the current number of healthy distributor replicas. The ring is configured by <code>distributor: { ring: {}}</code> / <code>-distributor.ring.*</code>.</p></li><li><p><code>max_label_name_length</code> / <code>-validation.max-length-label-name</code></p></li><li><p><code>max_label_value_length</code> / <code>-validation.max-length-label-value</code></p></li><li><p><code>max_label_names_per_series</code> / <code>-validation.max-label-names-per-series</code></p><p>Also enforced by the distributor, limits on the on length of labels and their values, and the total number of labels allowed per series.</p></li><li><p><code>reject_old_samples</code> / <code>-validation.reject-old-samples</code></p></li><li><p><code>reject_old_samples_max_age</code> / <code>-validation.reject-old-samples.max-age</code></p></li><li><p><code>creation_grace_period</code> / <code>-validation.create-grace-period</code></p><p>Also enforce by the distributor, limits on how far in the past (and future) timestamps that we accept can be.</p></li><li><p><code>max_series_per_user</code> / <code>-ingester.max-series-per-user</code></p></li><li><p><code>max_series_per_metric</code> / <code>-ingester.max-series-per-metric</code></p><p>Enforced by the ingesters; limits the number of active series a user (or a given metric) can have. When running with <code>-distributor.shard-by-all-labels=false</code> (the default), this limit will enforce the maximum number of series a metric can have &lsquo;globally&rsquo;, as all series for a single metric will be sent to the same replication set of ingesters. This is not the case when running with <code>-distributor.shard-by-all-labels=true</code>, so the actual limit will be N/RF times higher, where N is number of ingester replicas and RF is configured replication factor.</p><p>An active series is a series to which a sample has been written in the last <code>-ingester.max-chunk-idle</code> duration, which defaults to 5 minutes.</p></li><li><p><code>max_global_series_per_user</code> / <code>-ingester.max-global-series-per-user</code></p></li><li><p><code>max_global_series_per_metric</code> / <code>-ingester.max-global-series-per-metric</code></p><p>Like <code>max_series_per_user</code> and <code>max_series_per_metric</code>, but the limit is enforced across the cluster. Each ingester is configured with a local limit based on the replication factor, the <code>-distributor.shard-by-all-labels</code> setting and the current number of healthy ingesters, and is kept updated whenever the number of ingesters change.</p><p>Requires <code>-distributor.replication-factor</code> and <code>-distributor.shard-by-all-labels</code> set for the ingesters too.</p></li><li><p><code>max_series_per_query</code> / <code>-ingester.max-series-per-query</code></p></li><li><p><code>max_samples_per_query</code> / <code>-ingester.max-samples-per-query</code></p><p>Limits on the number of timeseries and samples returns by a single ingester during a query.</p></li></ul><h2 id=storage>Storage</h2><ul><li><p><code>s3.force-path-style</code></p><p>Set this to <code>true</code> to force the request to use path-style addressing (<code>http://s3.amazonaws.com/BUCKET/KEY</code>). By default, the S3 client will use virtual hosted bucket addressing when possible (<code>http://BUCKET.s3.amazonaws.com/KEY</code>).</p></li></ul><h2 id=dns-service-discovery>DNS Service Discovery</h2><p>Some clients in Cortex support service discovery via DNS to find addresses of backend servers to connect to (ie. caching servers). The clients supporting it are:</p><ul><li><a href=/docs/blocks-storage/store-gateway/#caching>Blocks storage&rsquo;s memcached cache</a></li><li><a href=/docs/configuration/configuration-file/#memcached-client-config>All caching memcached servers</a></li><li><a href=/docs/configuration/configuration-file/#memberlist-config>Memberlist KV store</a></li></ul><h3 id=supported-discovery-modes>Supported discovery modes</h3><p>The DNS service discovery, inspired from Thanos DNS SD, supports different discovery modes. A discovery mode is selected adding a specific prefix to the address. The supported prefixes are:</p><ul><li><strong><code>dns+</code></strong><br>The domain name after the prefix is looked up as an A/AAAA query. For example: <code>dns+memcached.local:11211</code></li><li><strong><code>dnssrv+</code></strong><br>The domain name after the prefix is looked up as a SRV query, and then each SRV record is resolved as an A/AAAA record. For example: <code>dnssrv+_memcached._tcp.memcached.namespace.svc.cluster.local</code></li><li><strong><code>dnssrvnoa+</code></strong><br>The domain name after the prefix is looked up as a SRV query, with no A/AAAA lookup made after that. For example: <code>dnssrvnoa+_memcached._tcp.memcached.namespace.svc.cluster.local</code></li></ul><h2 id=logging-of-ip-of-reverse-proxy>Logging of IP of reverse proxy</h2><p>If a reverse proxy is used in front of Cortex it might be diffult to troubleshoot errors. The following 3 settings can be used to log the IP address passed along by the reverse proxy in headers like X-Forwarded-For.</p><ul><li><p><code>-server.log_source_ips_enabled</code></p><p>Set this to <code>true</code> to add logging of the IP when a Forwarded, X-Real-IP or X-Forwarded-For header is used. A field called <code>sourceIPs</code> will be added to error logs when data is pushed into Cortex.</p></li><li><p><code>-server.log-source-ips-header</code></p><p>Header field storing the source IPs. It is only used if <code>-server.log-source-ips-enabled</code> is true and if <code>-server.log-source-ips-regex</code> is set. If not set the default Forwarded, X-Real-IP or X-Forwarded-For headers are searched.</p></li><li><p><code>-server.log-source-ips-regex</code></p><p>Regular expression for matching the source IPs. It should contain at least one capturing group the first of which will be returned. Only used if <code>-server.log-source-ips-enabled</code> is true and if <code>-server.log-source-ips-header</code> is set. If not set the default Forwarded, X-Real-IP or X-Forwarded-For headers are searched.</p></li></ul><div class="text-muted mt-5 pt-3 border-top"></div></div></main></div></div><footer class="row td-box td-box--dark td-box--gradient td-box--height-auto text-white p-5"><div class="col-12 col-sm-4 pb-5 pb-sm-0"><img src=/images/cortex-stacked-white.png width=75px class="img-fluid float-left"></div><div class="col-12 col-sm-4 pb-5 pb-sm-0"><h6 class=font-weight-bold>Community</h6><ul class=list-unstyled><li><a href=https://slack.cncf.io class="text-reset text-white"><i class="fab fa-fw fa-slack"></i>Slack</a></li><li><a href=https://github.com/cortexproject/cortex class="text-reset text-white"><i class="fab fa-fw fa-github"></i>GitHub</a></li><li><a href=https://twitter.com/cortexmetrics class="text-reset text-white"><i class="fab fa-fw fa-twitter"></i>Twitter</a></li></ul></div><div class="col-12 col-sm-4"><h6 class=font-weight-bold>About</h6><p>Cortex is an OSS licensed project as Apache License 2.0</p></div></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script><script src=/js/main.min.29b0315468c00226fa6f4556a9cebc0ac4fe1ce1457a01b22c0a06b329877383.js integrity="sha256-KbAxVGjAAib6b0VWqc68CsT+HOFFegGyLAoGsymHc4M=" crossorigin=anonymous></script></body></html>