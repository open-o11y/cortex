[{"body":" Author: Marco Pracucci Date: March 2020 Status: accepted Problem In Cortex, when using the experimental blocks storage, each querier internally runs the Thanos BucketStore. This means that each querier has a full view over all blocks in the long-term storage and all blocks index headers are loaded in each querier memory. The querier memory usage linearly increase with number and size of all blocks in the storage, imposing a scalability limit to the blocks storage.\nIn this proposal we want to solve this. In particular, we want to:\n Shard blocks (index headers) across a pool of nodes Do not compromise HA on the read path (if a node fails, queries should continue to work) Do not compromise correctness (either the query result is correct or it fails) Proposed solution The idea is to introduce a new Cortex service - store-gateway - internally running the Thanos BucketStore. At query time, a querier will run a query fetching the matching series both from ingesters and the subset of gateways holding the related blocks (based on the query time range). Blocks are replicated across the gateways in order to guarantee query results consistency and HA even in the case of a gateway instance failure.\nRing-based sharding and replication In order to build blocks sharding and replication, the store-gateway instances form a ring. Each gateway instance uses a custom MetaFetcherFilter to filter blocks loaded on the instance itself, keeping only blocks whose hash(block-id) is within the tokens range assigned to the gateway instance within the ring.\nWithin a gateway, the blocks synchronization is triggered in two cases:\n Periodically\nto discover new blocks uploaded by ingesters or compactor, and delete old blocks removed due to retention or by the compactor On-demand when the ring topology changes (the tokens ranges assigned to the gateway instance have changed) It\u0026rsquo;s important to outline that the sync takes time (typically will have to re-scan the bucket and download new blocks index headers) and Cortex needs to guarantee query results consistency at any given time (see below).\nQuery execution When a querier executes a query, it will need to fetch series both from ingesters and the store-gateway instances.\nFor a given query, the number of blocks to query is expected to be low, especially if the Cortex cluster is running the query-frontend with a 24h query split interval. In this scenario, whatever is the client\u0026rsquo;s query time range, the query-frontend will split the client\u0026rsquo;s query into partitioned queries each with up to 24h time range and the querier will likely hit not more than 1 block per partitioned query (except for the last 24h for which blocks may have not been compacted yet).\nGiven this assumption, we want to avoid sending every query to every store-gateway instance. The querier should be able to take an informed decision about the minimum subset of store-gateway instances which needs to query given a time range.\nThe idea is to run the MetaFetcher also within the querier, but without any sharding filter (contrary to the store-gateway). At any given point in time, the querier knows the entire list of blocks in the storage. When the querier executes the Select() (or SelectSorted()) it does:\n Compute the list of blocks by the query time range Compute the minimum list of store-gateway instances containing the required blocks (using the information from the ring) Fetch series from ingesters and the matching store-gateway instances Merge and deduplicate received series Optimization: can be skipped if the querier hits only 1 store-gateway Query results consistency When a querier executes a query, it should guarantee that either all blocks matching the time range are queried or the query fails.\nHowever, due to the (intentional) lack of a strong coordination between queriers and store-gateways, and the ring topology which can change any time, there\u0026rsquo;s no guarantee that the blocks assigned to a store-gateway shard are effectively loaded on the store-gateway itself at any given point in time.\nThe idea is introduce a consistency check in the querier. When a store-gateway receives a request from the querier, the store-gateway includes in the response the list of block IDs currently loaded on the store-gateway itself. The querier can then merge the list of block IDs received from all store-gateway hit, and match it against the list of block IDs computed at the beginning of the query execution.\nThere are three possible scenarios:\n The list match: all good All the blocks known by the querier are within the list of blocks returned by store-gateway, but the store-gateway also included blocks unknown to the querier: all good (it means the store-gateways have discovered and loaded new blocks before the querier discovered them) Some blocks known by the querier are not within the list of blocks returned by store-gateway: potential consistency issue We want to protect from a partial results response which may occur in the case #3. However, there are some legit cases which, if not handled, would lead to frequent false positives. Given the querier and store-gateway instances independently scan the bucket at a regular interval (to find new blocks or deleted blocks), we may be in one of the following cases:\na. The querier has discovered new blocks before the store-gateway successfully discovered and loaded them b. The store-gateway has offloaded blocks \u0026ldquo;marked for deletion\u0026rdquo; before the querier\nTo protect from case (a), we can exclude the blocks which have been uploaded in the last X time from the consistency check (same technique already used in other Thanos components). This X delay time is used to give the store-gateway enough time to discover and load new blocks, before the querier consider them for the consistency check. This value X should be greater than the -experimental.blocks-storage.bucket-store.consistency-delay, because we do expect the querier to consider a block for consistency check once it\u0026rsquo;s reasonably safe to assume that its store-gateway already loaded it.\nTo protect from case (b) we need to understand how blocks are offloaded. The BucketStore (running within the store-gateway) offloads a block as soon as it\u0026rsquo;s not returned by the MetaFetcher. This means we can configure the MetaFetcher with a IgnoreDeletionMarkFilter with a delay of X (could be the same value used for case (a)) and in the querier exclude the blocks which have been marked for deletion more than X time ago from the consistency check.\nTrade-offs The proposed solution comes with the following trade-offs:\n A querier is not ready until it has completed an initial full scan of the bucket, downloading the meta.json file of every block A store-gateway is not ready until it has completed an initial full scan of the bucket, downloading the meta.json and index header of each block matching its shard If a querier hits 2+ store-gateways it may receive duplicated series if the 2+ store-gateways share some blocks due to the replication factor ","excerpt":"Author: Marco Pracucci Date: March 2020 Status: accepted Problem In Cortex, when using the …","ref":"/docs/proposals/blocks-storage-sharding/","title":"Blocks storage sharding"},{"body":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary mode is easier to deploy and is aimed mainly at users wanting to try out Cortex or develop on it. The microservices mode is intended for production usage, as it allows you to independently scale different services and isolate failures. This document will focus on single-process Cortex. See the architecture doc For more information about the microservices.\nSeparately from single process vs microservices decision, Cortex can be configured to use local storage or cloud storage (DynamoDB, Bigtable, Cassandra, S3, GCS etc). This document will focus on using local storage. Local storage is explicitly not production ready at this time. Cortex can also make use of external memcacheds for caching and although these are not mandatory, they should be used in production.\nSingle instance, single process For simplicity and to get started, we\u0026rsquo;ll run it as a single process with no dependencies:\nClone and build Cortex\n$ git clone https://github.com/cortexproject/cortex.git $ cd cortex $ go build ./cmd/cortex $ ./cortex -config.file=./docs/configuration/single-process-config.yaml This starts a single Cortex node storing chunks and index to your local filesystem in /tmp/cortex. It is not intended for production use.\nClone and build prometheus\n$ git clone https://github.com/prometheus/prometheus $ cd prometheus $ go build ./cmd/prometheus Add the following to your Prometheus config (documentation/examples/prometheus.yml in Prometheus repo):\nremote_write:- url:http://localhost:9009/api/prom/pushAnd start Prometheus with that config file:\n$ ./prometheus --config.file=./documentation/examples/prometheus.yml Your Prometheus instance will now start pushing data to Cortex. To query that data, start a Grafana instance:\n$ docker run --rm -d --name=grafana -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://host.docker.internal:9009/api/prom).\nTo clean up: press CTRL-C in both terminals (for Cortex and Prometheus).\nHorizontally scale out Next we\u0026rsquo;re going to show how you can run a scale out Cortex cluster using Docker. We\u0026rsquo;ll need:\n A built Cortex image. A Docker network to put these containers on so they can resolve each other by name. A single node Consul instance to coordinate the Cortex cluster. $ make ./cmd/cortex/.uptodate $ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul Next we\u0026rsquo;ll run a couple of Cortex instances pointed at that Consul. You\u0026rsquo;ll note the Cortex configuration can be specified in either a config file or overridden on the command line. See the arguments documentation for more information about Cortex configuration options.\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 If you go to http://localhost:9001/ring (or http://localhost:9002/ring) you should see both Cortex nodes join the ring.\nTo demonstrate the correct operation of Cortex clustering, we\u0026rsquo;ll send samples to one of the instances and queries to another. In production, you\u0026rsquo;d want to load balance both pushes and queries evenly among all the nodes.\nPoint Prometheus at the first:\nremote_write:- url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml And Grafana at the second:\n$ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://cortex2:9009/api/prom).\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 consul grafana $ docker network remove cortex High availability with replication In this last demo we\u0026rsquo;ll show how Cortex can replicate data among three nodes, and demonstrate Cortex can tolerate a node failure without affecting reads and writes.\nFirst, create a network and run a new Consul and Grafana:\n$ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul $ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana Then, launch 3 Cortex nodes with replication factor 3:\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex3 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config.yaml:/etc/single-process-config.yaml \\ -p 9003:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 Configure Prometheus to send data to the first replica:\nremote_write:- url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml In Grafana, add a datasource for the 3rd Cortex replica (http://cortex3:9009/api/prom) and verify the same data appears in both Prometheus and Cortex.\nTo show that Cortex can tolerate a node failure, hard kill one of the Cortex replicas:\n$ docker rm -f cortex2 You should see writes and queries continue to work without error.\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 cortex3 consul grafana $ docker network remove cortex ","excerpt":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary …","ref":"/docs/getting-started/getting-started-chunks-storage/","title":"Getting Started with Chunks Storage"},{"body":"Cortex can be configured using a YAML file - specified using the -config.file flag - or CLI flags. In case you combine both, CLI flags take precedence over the YAML config file.\nThe current configuration of any Cortex component can be seen by visiting the /config HTTP path. Passwords are filtered out of this endpoint.\nReference To specify which configuration file to load, pass the -config.file flag at the command line. The file is written in YAML format, defined by the scheme below. Brackets indicate that a parameter is optional.\nGeneric placeholders \u0026lt;boolean\u0026gt;: a boolean that can take the values true or false \u0026lt;int\u0026gt;: any integer matching the regular expression [1-9]+[0-9]* \u0026lt;duration\u0026gt;: a duration matching the regular expression [0-9]+(ns|us|µs|ms|s|m|h|d|w|y) where y = 365 days. \u0026lt;string\u0026gt;: a regular string \u0026lt;url\u0026gt;: an URL \u0026lt;prefix\u0026gt;: a CLI flag prefix based on the context (look at the parent configuration block to see which CLI flags prefix should be used) \u0026lt;time\u0026gt;: a timestamp, with available formats: 2006-01-20 (midnight, local timezone), 2006-01-20T15:04 (local timezone), and RFC 3339 formats: 2006-01-20T15:04:05Z (UTC) or 2006-01-20T15:04:05+07:00 (explicit timezone) Use environment variables in the configuration You can use environment variable references in the config file to set values that need to be configurable during deployment by using the -config.expand-env flag. To do this, use:\n${VAR} Where VAR is the name of the environment variable.\nEach variable reference is replaced at startup by the value of the environment variable. The replacement is case-sensitive and occurs before the YAML file is parsed. References to undefined variables are replaced by empty strings unless you specify a default value or custom error text.\nTo specify a default value, use:\n${VAR:default_value} Where default_value is the value to use if the environment variable is undefined.\nSupported contents and default values of the config file # Comma-separated list of Cortex modules to load. The alias \u0026#39;all\u0026#39; can be used in# the list to load a number of core modules and will enable single-binary mode.# Use \u0026#39;-modules\u0026#39; command line flag to get a list of available modules, and to# see which modules are included in \u0026#39;all\u0026#39;.# CLI flag: -target[target:\u0026lt;string\u0026gt;|default=\u0026#34;all\u0026#34;]# Set to false to disable auth.# CLI flag: -auth.enabled[auth_enabled:\u0026lt;boolean\u0026gt;|default=true]# HTTP path prefix for Cortex API.# CLI flag: -http.prefix[http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/api/prom\u0026#34;]api:# HTTP URL path under which the Alertmanager ui and api will be served.# CLI flag: -http.alertmanager-http-prefix[alertmanager_http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/alertmanager\u0026#34;]# HTTP URL path under which the Prometheus api will be served.# CLI flag: -http.prometheus-http-prefix[prometheus_http_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;/prometheus\u0026#34;]# The server_config configures the HTTP and gRPC server of the launched# service(s).[server:\u0026lt;server_config\u0026gt;]# The distributor_config configures the Cortex distributor.[distributor:\u0026lt;distributor_config\u0026gt;]# The querier_config configures the Cortex querier.[querier:\u0026lt;querier_config\u0026gt;]# The ingester_client_config configures how the Cortex distributors connect to# the ingesters.[ingester_client:\u0026lt;ingester_client_config\u0026gt;]# The ingester_config configures the Cortex ingester.[ingester:\u0026lt;ingester_config\u0026gt;]# The flusher_config configures the WAL flusher target, used to manually run# one-time flushes when scaling down ingesters.[flusher:\u0026lt;flusher_config\u0026gt;]# The storage_config configures where Cortex stores the data (chunks storage# engine).[storage:\u0026lt;storage_config\u0026gt;]# The chunk_store_config configures how Cortex stores the data (chunks storage# engine).[chunk_store:\u0026lt;chunk_store_config\u0026gt;]# The limits_config configures default and per-tenant limits imposed by Cortex# services (ie. distributor, ingester, ...).[limits:\u0026lt;limits_config\u0026gt;]# The frontend_worker_config configures the worker - running within the Cortex# querier - picking up and executing queries enqueued by the query-frontend.[frontend_worker:\u0026lt;frontend_worker_config\u0026gt;]# The query_frontend_config configures the Cortex query-frontend.[frontend:\u0026lt;query_frontend_config\u0026gt;]# The query_range_config configures the query splitting and caching in the# Cortex query-frontend.[query_range:\u0026lt;query_range_config\u0026gt;]# The table_manager_config configures the Cortex table-manager.[table_manager:\u0026lt;table_manager_config\u0026gt;]# The blocks_storage_config configures the blocks storage.[blocks_storage:\u0026lt;blocks_storage_config\u0026gt;]# The compactor_config configures the compactor for the blocks storage.[compactor:\u0026lt;compactor_config\u0026gt;]# The store_gateway_config configures the store-gateway service used by the# blocks storage.[store_gateway:\u0026lt;store_gateway_config\u0026gt;]# The purger_config configures the purger which takes care of delete requests[purger:\u0026lt;purger_config\u0026gt;]# The ruler_config configures the Cortex ruler.[ruler:\u0026lt;ruler_config\u0026gt;]# The configs_config configures the Cortex Configs DB and API.[configs:\u0026lt;configs_config\u0026gt;]# The alertmanager_config configures the Cortex alertmanager.[alertmanager:\u0026lt;alertmanager_config\u0026gt;]runtime_config:# How often to check runtime config file.# CLI flag: -runtime-config.reload-period[period:\u0026lt;duration\u0026gt;|default=10s]# File with the configuration that can be updated in runtime.# CLI flag: -runtime-config.file[file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The memberlist_config configures the Gossip memberlist.[memberlist:\u0026lt;memberlist_config\u0026gt;]server_config The server_config configures the HTTP and gRPC server of the launched service(s).\n# HTTP server listen address.# CLI flag: -server.http-listen-address[http_listen_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP server listen port.# CLI flag: -server.http-listen-port[http_listen_port:\u0026lt;int\u0026gt;|default=80]# Maximum number of simultaneous http connections, \u0026lt;=0 to disable# CLI flag: -server.http-conn-limit[http_listen_conn_limit:\u0026lt;int\u0026gt;|default=0]# gRPC server listen address.# CLI flag: -server.grpc-listen-address[grpc_listen_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# gRPC server listen port.# CLI flag: -server.grpc-listen-port[grpc_listen_port:\u0026lt;int\u0026gt;|default=9095]# Maximum number of simultaneous grpc connections, \u0026lt;=0 to disable# CLI flag: -server.grpc-conn-limit[grpc_listen_conn_limit:\u0026lt;int\u0026gt;|default=0]http_tls_config:# HTTP server cert path.# CLI flag: -server.http-tls-cert-path[cert_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP server key path.# CLI flag: -server.http-tls-key-path[key_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP TLS Client Auth type.# CLI flag: -server.http-tls-client-auth[client_auth_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP TLS Client CA path.# CLI flag: -server.http-tls-ca-path[client_ca_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]grpc_tls_config:# GRPC TLS server cert path.# CLI flag: -server.grpc-tls-cert-path[cert_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS server key path.# CLI flag: -server.grpc-tls-key-path[key_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS Client Auth type.# CLI flag: -server.grpc-tls-client-auth[client_auth_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# GRPC TLS Client CA path.# CLI flag: -server.grpc-tls-ca-path[client_ca_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Register the intrumentation handlers (/metrics etc).# CLI flag: -server.register-instrumentation[register_instrumentation:\u0026lt;boolean\u0026gt;|default=true]# Timeout for graceful shutdowns# CLI flag: -server.graceful-shutdown-timeout[graceful_shutdown_timeout:\u0026lt;duration\u0026gt;|default=30s]# Read timeout for HTTP server# CLI flag: -server.http-read-timeout[http_server_read_timeout:\u0026lt;duration\u0026gt;|default=30s]# Write timeout for HTTP server# CLI flag: -server.http-write-timeout[http_server_write_timeout:\u0026lt;duration\u0026gt;|default=30s]# Idle timeout for HTTP server# CLI flag: -server.http-idle-timeout[http_server_idle_timeout:\u0026lt;duration\u0026gt;|default=2m]# Limit on the size of a gRPC message this server can receive (bytes).# CLI flag: -server.grpc-max-recv-msg-size-bytes[grpc_server_max_recv_msg_size:\u0026lt;int\u0026gt;|default=4194304]# Limit on the size of a gRPC message this server can send (bytes).# CLI flag: -server.grpc-max-send-msg-size-bytes[grpc_server_max_send_msg_size:\u0026lt;int\u0026gt;|default=4194304]# Limit on the number of concurrent streams for gRPC calls (0 = unlimited)# CLI flag: -server.grpc-max-concurrent-streams[grpc_server_max_concurrent_streams:\u0026lt;int\u0026gt;|default=100]# The duration after which an idle connection should be closed. Default:# infinity# CLI flag: -server.grpc.keepalive.max-connection-idle[grpc_server_max_connection_idle:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# The duration for the maximum amount of time a connection may exist before it# will be closed. Default: infinity# CLI flag: -server.grpc.keepalive.max-connection-age[grpc_server_max_connection_age:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# An additive period after max-connection-age after which the connection will be# forcibly closed. Default: infinity# CLI flag: -server.grpc.keepalive.max-connection-age-grace[grpc_server_max_connection_age_grace:\u0026lt;duration\u0026gt;|default=2562047h47m16.854775807s]# Duration after which a keepalive probe is sent in case of no activity over the# connection., Default: 2h# CLI flag: -server.grpc.keepalive.time[grpc_server_keepalive_time:\u0026lt;duration\u0026gt;|default=2h]# After having pinged for keepalive check, the duration after which an idle# connection should be closed, Default: 20s# CLI flag: -server.grpc.keepalive.timeout[grpc_server_keepalive_timeout:\u0026lt;duration\u0026gt;|default=20s]# Output log messages in the given format. Valid formats: [logfmt, json]# CLI flag: -log.format[log_format:\u0026lt;string\u0026gt;|default=\u0026#34;logfmt\u0026#34;]# Only log messages with the given severity or above. Valid levels: [debug,# info, warn, error]# CLI flag: -log.level[log_level:\u0026lt;string\u0026gt;|default=\u0026#34;info\u0026#34;]# Optionally log the source IPs.# CLI flag: -server.log-source-ips-enabled[log_source_ips_enabled:\u0026lt;boolean\u0026gt;|default=false]# Header field storing the source IPs. Only used if# server.log-source-ips-enabled is true. If not set the default Forwarded,# X-Real-IP and X-Forwarded-For headers are used# CLI flag: -server.log-source-ips-header[log_source_ips_header:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Regex for matching the source IPs. Only used if server.log-source-ips-enabled# is true. If not set the default Forwarded, X-Real-IP and X-Forwarded-For# headers are used# CLI flag: -server.log-source-ips-regex[log_source_ips_regex:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Base path to serve all API routes from (e.g. /v1/)# CLI flag: -server.path-prefix[http_path_prefix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]distributor_config The distributor_config configures the Cortex distributor.\npool:# How frequently to clean up clients for ingesters that have gone away.# CLI flag: -distributor.client-cleanup-period[client_cleanup_period:\u0026lt;duration\u0026gt;|default=15s]# Run a health check on each ingester client during periodic cleanup.# CLI flag: -distributor.health-check-ingesters[health_check_ingesters:\u0026lt;boolean\u0026gt;|default=true]ha_tracker:# Enable the distributors HA tracker so that it can accept samples from# Prometheus HA replicas gracefully (requires labels).# CLI flag: -distributor.ha-tracker.enable[enable_ha_tracker:\u0026lt;boolean\u0026gt;|default=false]# Update the timestamp in the KV store for a given cluster/replica only after# this amount of time has passed since the current stored timestamp.# CLI flag: -distributor.ha-tracker.update-timeout[ha_tracker_update_timeout:\u0026lt;duration\u0026gt;|default=15s]# Maximum jitter applied to the update timeout, in order to spread the HA# heartbeats over time.# CLI flag: -distributor.ha-tracker.update-timeout-jitter-max[ha_tracker_update_timeout_jitter_max:\u0026lt;duration\u0026gt;|default=5s]# If we don\u0026#39;t receive any samples from the accepted replica for a cluster in# this amount of time we will failover to the next replica we receive a sample# from. This value must be greater than the update timeout# CLI flag: -distributor.ha-tracker.failover-timeout[ha_tracker_failover_timeout:\u0026lt;duration\u0026gt;|default=30s]# Backend storage to use for the ring. Please be aware that memberlist is not# supported by the HA tracker since gossip propagation is too slow for HA# purposes.kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -distributor.ha-tracker.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -distributor.ha-tracker.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;ha-tracker/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: distributor.ha-tracker[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: distributor.ha-tracker[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -distributor.ha-tracker.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -distributor.ha-tracker.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -distributor.ha-tracker.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -distributor.ha-tracker.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# remote_write API max receive message size (bytes).# CLI flag: -distributor.max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# Timeout for downstream ingesters.# CLI flag: -distributor.remote-timeout[remote_timeout:\u0026lt;duration\u0026gt;|default=2s]# Time to wait before sending more than the minimum successful query requests.# CLI flag: -distributor.extra-query-delay[extra_queue_delay:\u0026lt;duration\u0026gt;|default=0s]# The sharding strategy to use. Supported values are: default, shuffle-sharding.# CLI flag: -distributor.sharding-strategy[sharding_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;default\u0026#34;]# Distribute samples based on all labels, as opposed to solely by user and# metric name.# CLI flag: -distributor.shard-by-all-labels[shard_by_all_labels:\u0026lt;boolean\u0026gt;|default=false]ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -distributor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -distributor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: distributor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: distributor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -distributor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -distributor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -distributor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -distributor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -distributor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which distributors are considered unhealthy# within the ring.# CLI flag: -distributor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -distributor.ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]ingester_config The ingester_config configures the Cortex ingester.\nwalconfig:# Enable writing of ingested data into WAL.# CLI flag: -ingester.wal-enabled[wal_enabled:\u0026lt;boolean\u0026gt;|default=false]# Enable checkpointing of in-memory chunks. It should always be true when# using normally. Set it to false iff you are doing some small tests as there# is no mechanism to delete the old WAL yet if checkpoint is disabled.# CLI flag: -ingester.checkpoint-enabled[checkpoint_enabled:\u0026lt;boolean\u0026gt;|default=true]# Recover data from existing WAL irrespective of WAL enabled/disabled.# CLI flag: -ingester.recover-from-wal[recover_from_wal:\u0026lt;boolean\u0026gt;|default=false]# Directory to store the WAL and/or recover from WAL.# CLI flag: -ingester.wal-dir[wal_dir:\u0026lt;string\u0026gt;|default=\u0026#34;wal\u0026#34;]# Interval at which checkpoints should be created.# CLI flag: -ingester.checkpoint-duration[checkpoint_duration:\u0026lt;duration\u0026gt;|default=30m]# When WAL is enabled, should chunks be flushed to long-term storage on# shutdown. Useful eg. for migration to blocks engine.# CLI flag: -ingester.flush-on-shutdown-with-wal-enabled[flush_on_shutdown_with_wal_enabled:\u0026lt;boolean\u0026gt;|default=false]lifecycler:ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# The heartbeat timeout after which ingesters are skipped for reads/writes.# CLI flag: -ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The number of ingesters to write to and read from.# CLI flag: -distributor.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# True to enable the zone-awareness and replicate ingested samples across# different availability zones.# CLI flag: -distributor.zone-awareness-enabled[zone_awareness_enabled:\u0026lt;boolean\u0026gt;|default=false]# Number of tokens for each ingester.# CLI flag: -ingester.num-tokens[num_tokens:\u0026lt;int\u0026gt;|default=128]# Period at which to heartbeat to consul.# CLI flag: -ingester.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# Observe tokens after generating to resolve collisions. Useful when using# gossiping ring.# CLI flag: -ingester.observe-period[observe_period:\u0026lt;duration\u0026gt;|default=0s]# Period to wait for a claim from another member; will join automatically# after this.# CLI flag: -ingester.join-after[join_after:\u0026lt;duration\u0026gt;|default=0s]# Minimum duration to wait before becoming ready. This is to work around race# conditions with ingesters exiting and updating the ring.# CLI flag: -ingester.min-ready-duration[min_ready_duration:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -ingester.lifecycler.interface[interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]# Duration to sleep for before exiting, to ensure metrics are scraped.# CLI flag: -ingester.final-sleep[final_sleep:\u0026lt;duration\u0026gt;|default=30s]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -ingester.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The availability zone where this instance is running.# CLI flag: -ingester.availability-zone[availability_zone:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of times to try and transfer chunks before falling back to flushing.# Negative value or zero disables hand-over. This feature is supported only by# the chunks storage.# CLI flag: -ingester.max-transfer-retries[max_transfer_retries:\u0026lt;int\u0026gt;|default=10]# Period with which to attempt to flush chunks.# CLI flag: -ingester.flush-period[flush_period:\u0026lt;duration\u0026gt;|default=1m]# Period chunks will remain in memory after flushing.# CLI flag: -ingester.retain-period[retain_period:\u0026lt;duration\u0026gt;|default=5m]# Maximum chunk idle time before flushing.# CLI flag: -ingester.max-chunk-idle[max_chunk_idle_time:\u0026lt;duration\u0026gt;|default=5m]# Maximum chunk idle time for chunks terminating in stale markers before# flushing. 0 disables it and a stale series is not flushed until the# max-chunk-idle timeout is reached.# CLI flag: -ingester.max-stale-chunk-idle[max_stale_chunk_idle_time:\u0026lt;duration\u0026gt;|default=2m]# Timeout for individual flush operations.# CLI flag: -ingester.flush-op-timeout[flush_op_timeout:\u0026lt;duration\u0026gt;|default=1m]# Maximum chunk age before flushing.# CLI flag: -ingester.max-chunk-age[max_chunk_age:\u0026lt;duration\u0026gt;|default=12h]# Range of time to subtract from -ingester.max-chunk-age to spread out flushes# CLI flag: -ingester.chunk-age-jitter[chunk_age_jitter:\u0026lt;duration\u0026gt;|default=0s]# Number of concurrent goroutines flushing to dynamodb.# CLI flag: -ingester.concurrent-flushes[concurrent_flushes:\u0026lt;int\u0026gt;|default=50]# If true, spread series flushes across the whole period of# -ingester.max-chunk-age.# CLI flag: -ingester.spread-flushes[spread_flushes:\u0026lt;boolean\u0026gt;|default=true]# Period at which metadata we have not seen will remain in memory before being# deleted.# CLI flag: -ingester.metadata-retain-period[metadata_retain_period:\u0026lt;duration\u0026gt;|default=10m]# Period with which to update the per-user ingestion rates.# CLI flag: -ingester.rate-update-period[rate_update_period:\u0026lt;duration\u0026gt;|default=15s]# Enable tracking of active series and export them as metrics.# CLI flag: -ingester.active-series-metrics-enabled[active_series_metrics_enabled:\u0026lt;boolean\u0026gt;|default=false]# How often to update active series metrics.# CLI flag: -ingester.active-series-metrics-update-period[active_series_metrics_update_period:\u0026lt;duration\u0026gt;|default=1m]# After what time a series is considered to be inactive.# CLI flag: -ingester.active-series-metrics-idle-timeout[active_series_metrics_idle_timeout:\u0026lt;duration\u0026gt;|default=10m]querier_config The querier_config configures the Cortex querier.\n# The maximum number of concurrent queries.# CLI flag: -querier.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=20]# The timeout for a query.# CLI flag: -querier.timeout[timeout:\u0026lt;duration\u0026gt;|default=2m]# Use iterators to execute query, as opposed to fully materialising the series# in memory.# CLI flag: -querier.iterators[iterators:\u0026lt;boolean\u0026gt;|default=false]# Use batch iterators to execute query, as opposed to fully materialising the# series in memory. Takes precedent over the -querier.iterators flag.# CLI flag: -querier.batch-iterators[batch_iterators:\u0026lt;boolean\u0026gt;|default=true]# Use streaming RPCs to query ingester.# CLI flag: -querier.ingester-streaming[ingester_streaming:\u0026lt;boolean\u0026gt;|default=true]# Maximum number of samples a single query can load into memory.# CLI flag: -querier.max-samples[max_samples:\u0026lt;int\u0026gt;|default=50000000]# Maximum lookback beyond which queries are not sent to ingester. 0 means all# queries are sent to ingester.# CLI flag: -querier.query-ingesters-within[query_ingesters_within:\u0026lt;duration\u0026gt;|default=0s]# The time after which a metric should only be queried from storage and not just# ingesters. 0 means all queries are sent to store. When running the blocks# storage, if this option is enabled, the time range of the query sent to the# store will be manipulated to ensure the query end is not more recent than \u0026#39;now# - query-store-after\u0026#39;.# CLI flag: -querier.query-store-after[query_store_after:\u0026lt;duration\u0026gt;|default=0s]# Maximum duration into the future you can query. 0 to disable.# CLI flag: -querier.max-query-into-future[max_query_into_future:\u0026lt;duration\u0026gt;|default=10m]# The default evaluation interval or step size for subqueries.# CLI flag: -querier.default-evaluation-interval[default_evaluation_interval:\u0026lt;duration\u0026gt;|default=1m]# Active query tracker monitors active queries, and writes them to the file in# given directory. If Cortex discovers any queries in this log during startup,# it will log them to the log file. Setting to empty value disables active query# tracker, which also disables -querier.max-concurrent option.# CLI flag: -querier.active-query-tracker-dir[active_query_tracker_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./active-query-tracker\u0026#34;]# Time since the last sample after which a time series is considered stale and# ignored by expression evaluations.# CLI flag: -querier.lookback-delta[lookback_delta:\u0026lt;duration\u0026gt;|default=5m]# Comma separated list of store-gateway addresses in DNS Service Discovery# format. This option should be set when using the blocks storage and the# store-gateway sharding is disabled (when enabled, the store-gateway instances# form a ring and addresses are picked from the ring).# CLI flag: -querier.store-gateway-addresses[store_gateway_addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]store_gateway_client:# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -querier.store-gateway-client.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -querier.store-gateway-client.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against. If# not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -querier.store-gateway-client.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -querier.store-gateway-client.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]# Second store engine to use for querying. Empty = disabled.# CLI flag: -querier.second-store-engine[second_store_engine:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If specified, second store is only used for queries before this timestamp.# Default value 0 means secondary store is always queried.# CLI flag: -querier.use-second-store-before-time[use_second_store_before_time:\u0026lt;time\u0026gt;|default=0]query_frontend_config The query_frontend_config configures the Cortex query-frontend.\n# Maximum number of outstanding requests per tenant per frontend; requests# beyond this error with HTTP 429.# CLI flag: -querier.max-outstanding-requests-per-tenant[max_outstanding_per_tenant:\u0026lt;int\u0026gt;|default=100]# Compress HTTP responses.# CLI flag: -querier.compress-http-responses[compress_responses:\u0026lt;boolean\u0026gt;|default=false]# URL of downstream Prometheus.# CLI flag: -frontend.downstream-url[downstream_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Log queries that are slower than the specified duration. Set to 0 to disable.# Set to \u0026lt; 0 to enable on all queries.# CLI flag: -frontend.log-queries-longer-than[log_queries_longer_than:\u0026lt;duration\u0026gt;|default=0s]query_range_config The query_range_config configures the query splitting and caching in the Cortex query-frontend.\n# Split queries by an interval and execute in parallel, 0 disables it. You# should use an a multiple of 24 hours (same as the storage bucketing scheme),# to avoid queriers downloading and processing the same chunks. This also# determines how cache keys are chosen when result caching is enabled# CLI flag: -querier.split-queries-by-interval[split_queries_by_interval:\u0026lt;duration\u0026gt;|default=0s]# Deprecated: Split queries by day and execute in parallel.# CLI flag: -querier.split-queries-by-day[split_queries_by_day:\u0026lt;boolean\u0026gt;|default=false]# Mutate incoming queries to align their start and end with their step.# CLI flag: -querier.align-querier-with-step[align_queries_with_step:\u0026lt;boolean\u0026gt;|default=false]results_cache:cache:# Enable in-memory cache.# CLI flag: -frontend.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# The default validity of entries for caches unless overridden.# CLI flag: -frontend.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# At what concurrency to write back to cache.# CLI flag: -frontend.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# How many key batches to buffer for background write-back.# CLI flag: -frontend.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: frontend[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: frontend[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: frontend[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: frontend[fifocache:\u0026lt;fifo_cache_config\u0026gt;]# Use compression in results cache. Supported values are: \u0026#39;snappy\u0026#39; and \u0026#39;\u0026#39;# (disable compression).# CLI flag: -frontend.compression[compression:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Cache query results.# CLI flag: -querier.cache-results[cache_results:\u0026lt;boolean\u0026gt;|default=false]# Maximum number of retries for a single request; beyond this, the downstream# error is returned.# CLI flag: -querier.max-retries-per-request[max_retries:\u0026lt;int\u0026gt;|default=5]# Perform query parallelisations based on storage sharding configuration and# query ASTs. This feature is supported only by the chunks storage engine.# CLI flag: -querier.parallelise-shardable-queries[parallelise_shardable_queries:\u0026lt;boolean\u0026gt;|default=false]ruler_config The ruler_config configures the Cortex ruler.\n# URL of alerts return path.# CLI flag: -ruler.external.url[external_url:\u0026lt;url\u0026gt;|default=]ruler_client:# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -ruler.client.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -ruler.client.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against. If# not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -ruler.client.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -ruler.client.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]# How frequently to evaluate rules# CLI flag: -ruler.evaluation-interval[evaluation_interval:\u0026lt;duration\u0026gt;|default=1m]# Deprecated. Please use -ruler.evaluation-delay-duration instead.# CLI flag: -ruler.evaluation-delay-duration-deprecated[evaluation_delay_duration:\u0026lt;duration\u0026gt;|default=0s]# How frequently to poll for rule changes# CLI flag: -ruler.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=1m]storage:# Method to use for backend rule storage (configdb, azure, gcs, s3, swift,# local)# CLI flag: -ruler.storage.type[type:\u0026lt;string\u0026gt;|default=\u0026#34;configdb\u0026#34;]# The configstore_config configures the config database storing rules and# alerts, and is used by the Cortex alertmanager.# The CLI flags prefix for this block config is: ruler[configdb:\u0026lt;configstore_config\u0026gt;]azure:# Azure Cloud environment. Supported values are: AzureGlobal,# AzureChinaCloud, AzureGermanCloud, AzureUSGovernment.# CLI flag: -ruler.storage.azure.environment[environment:\u0026lt;string\u0026gt;|default=\u0026#34;AzureGlobal\u0026#34;]# Name of the blob container used to store chunks. This container must be# created before running cortex.# CLI flag: -ruler.storage.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# The Microsoft Azure account name to be used# CLI flag: -ruler.storage.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The Microsoft Azure account key to use.# CLI flag: -ruler.storage.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Preallocated buffer size for downloads.# CLI flag: -ruler.storage.azure.download-buffer-size[download_buffer_size:\u0026lt;int\u0026gt;|default=512000]# Preallocated buffer size for uploads.# CLI flag: -ruler.storage.azure.upload-buffer-size[upload_buffer_size:\u0026lt;int\u0026gt;|default=256000]# Number of buffers used to used to upload a chunk.# CLI flag: -ruler.storage.azure.download-buffer-count[upload_buffer_count:\u0026lt;int\u0026gt;|default=1]# Timeout for requests made against azure blob storage.# CLI flag: -ruler.storage.azure.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=30s]# Number of retries for a request which times out.# CLI flag: -ruler.storage.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=5]# Minimum time to wait before retrying a request.# CLI flag: -ruler.storage.azure.min-retry-delay[min_retry_delay:\u0026lt;duration\u0026gt;|default=10ms]# Maximum time to wait before retrying a request.# CLI flag: -ruler.storage.azure.max-retry-delay[max_retry_delay:\u0026lt;duration\u0026gt;|default=500ms]gcs:# Name of GCS bucket. Please refer to# https://cloud.google.com/docs/authentication/production for more# information about how to configure authentication.# CLI flag: -ruler.storage.gcs.bucketname[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The size of the buffer that GCS client for each PUT request. 0 to disable# buffering.# CLI flag: -ruler.storage.gcs.chunk-buffer-size[chunk_buffer_size:\u0026lt;int\u0026gt;|default=0]# The duration after which the requests to GCS should be timed out.# CLI flag: -ruler.storage.gcs.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=0s]s3:# S3 endpoint URL with escaped Key and Secret encoded. If only region is# specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;bucket-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -ruler.storage.s3.url[s3:\u0026lt;url\u0026gt;|default=]# Set this to `true` to force the request to use path-style addressing.# CLI flag: -ruler.storage.s3.force-path-style[s3forcepathstyle:\u0026lt;boolean\u0026gt;|default=false]# Comma separated list of bucket names to evenly distribute chunks over.# Overrides any buckets specified in s3.url flag# CLI flag: -ruler.storage.s3.buckets[bucketnames:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 Endpoint to connect to.# CLI flag: -ruler.storage.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS region to use.# CLI flag: -ruler.storage.s3.region[region:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Access Key ID# CLI flag: -ruler.storage.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Secret Access Key# CLI flag: -ruler.storage.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Disable https on s3 connection.# CLI flag: -ruler.storage.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]# Enable AES256 AWS Server Side Encryption# CLI flag: -ruler.storage.s3.sse-encryption[sse_encryption:\u0026lt;boolean\u0026gt;|default=false]http_config:# The maximum amount of time an idle connection will be held open.# CLI flag: -ruler.storage.s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# If non-zero, specifies the amount of time to wait for a server\u0026#39;s# response headers after fully writing the request.# CLI flag: -ruler.storage.s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=0s]# Set to false to skip verifying the certificate chain and hostname.# CLI flag: -ruler.storage.s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]swift:# Openstack authentication URL.# CLI flag: -ruler.storage.swift.auth-url[auth_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack username for the api.# CLI flag: -ruler.storage.swift.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -ruler.storage.swift.user-domain-name[user_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -ruler.storage.swift.user-domain-id[user_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack userid for the api.# CLI flag: -ruler.storage.swift.user-id[user_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack api key.# CLI flag: -ruler.storage.swift.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -ruler.storage.swift.domain-id[domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -ruler.storage.swift.domain-name[domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project id (v2,v3 auth only).# CLI flag: -ruler.storage.swift.project-id[project_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project name (v2,v3 auth only).# CLI flag: -ruler.storage.swift.project-name[project_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Id of the project\u0026#39;s domain (v3 auth only), only needed if it differs the# from user domain.# CLI flag: -ruler.storage.swift.project-domain-id[project_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the project\u0026#39;s domain (v3 auth only), only needed if it differs# from the user domain.# CLI flag: -ruler.storage.swift.project-domain-name[project_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack Region to use eg LON, ORD - default is use first region (v2,v3# auth only)# CLI flag: -ruler.storage.swift.region-name[region_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the Swift container to put chunks in.# CLI flag: -ruler.storage.swift.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]local:# Directory to scan for rules# CLI flag: -ruler.storage.local.directory[directory:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# file path to store temporary rule files for the prometheus rule managers# CLI flag: -ruler.rule-path[rule_path:\u0026lt;string\u0026gt;|default=\u0026#34;/rules\u0026#34;]# Comma-separated list of URL(s) of the Alertmanager(s) to send notifications# to. Each Alertmanager URL is treated as a separate group in the configuration.# Multiple Alertmanagers in HA per group can be supported by using DNS# resolution via -ruler.alertmanager-discovery.# CLI flag: -ruler.alertmanager-url[alertmanager_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Use DNS SRV records to discover Alertmanager hosts.# CLI flag: -ruler.alertmanager-discovery[enable_alertmanager_discovery:\u0026lt;boolean\u0026gt;|default=false]# How long to wait between refreshing DNS resolutions of Alertmanager hosts.# CLI flag: -ruler.alertmanager-refresh-interval[alertmanager_refresh_interval:\u0026lt;duration\u0026gt;|default=1m]# If enabled requests to Alertmanager will utilize the V2 API.# CLI flag: -ruler.alertmanager-use-v2[enable_alertmanager_v2:\u0026lt;boolean\u0026gt;|default=false]# Capacity of the queue for notifications to be sent to the Alertmanager.# CLI flag: -ruler.notification-queue-capacity[notification_queue_capacity:\u0026lt;int\u0026gt;|default=10000]# HTTP timeout duration when sending notifications to the Alertmanager.# CLI flag: -ruler.notification-timeout[notification_timeout:\u0026lt;duration\u0026gt;|default=10s]# Max time to tolerate outage for restoring \u0026#34;for\u0026#34; state of alert.# CLI flag: -ruler.for-outage-tolerance[for_outage_tolerance:\u0026lt;duration\u0026gt;|default=1h]# Minimum duration between alert and restored \u0026#34;for\u0026#34; state. This is maintained# only for alerts with configured \u0026#34;for\u0026#34; time greater than grace period.# CLI flag: -ruler.for-grace-period[for_grace_period:\u0026lt;duration\u0026gt;|default=10m]# Minimum amount of time to wait before resending an alert to Alertmanager.# CLI flag: -ruler.resend-delay[resend_delay:\u0026lt;duration\u0026gt;|default=1m]# Distribute rule evaluation using ring backend# CLI flag: -ruler.enable-sharding[enable_sharding:\u0026lt;boolean\u0026gt;|default=false]# The sharding strategy to use. Supported values are: default, shuffle-sharding.# CLI flag: -ruler.sharding-strategy[sharding_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;default\u0026#34;]# Time to spend searching for a pending ruler when shutting down.# CLI flag: -ruler.search-pending-for[search_pending_for:\u0026lt;duration\u0026gt;|default=5m]ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -ruler.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -ruler.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;rulers/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: ruler.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: ruler.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -ruler.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -ruler.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -ruler.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -ruler.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -ruler.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which rulers are considered unhealthy within the# ring.# CLI flag: -ruler.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -ruler.ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]# Number of tokens for each ingester.# CLI flag: -ruler.ring.num-tokens[num_tokens:\u0026lt;int\u0026gt;|default=128]# Period with which to attempt to flush rule groups.# CLI flag: -ruler.flush-period[flush_period:\u0026lt;duration\u0026gt;|default=1m]# Enable the ruler api# CLI flag: -experimental.ruler.enable-api[enable_api:\u0026lt;boolean\u0026gt;|default=false]alertmanager_config The alertmanager_config configures the Cortex alertmanager.\n# Base path for data storage.# CLI flag: -alertmanager.storage.path[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;data/\u0026#34;]# How long to keep data for.# CLI flag: -alertmanager.storage.retention[retention:\u0026lt;duration\u0026gt;|default=120h]# The URL under which Alertmanager is externally reachable (for example, if# Alertmanager is served via a reverse proxy). Used for generating relative and# absolute links back to Alertmanager itself. If the URL has a path portion, it# will be used to prefix all HTTP endpoints served by Alertmanager. If omitted,# relevant URL components will be derived automatically.# CLI flag: -alertmanager.web.external-url[external_url:\u0026lt;url\u0026gt;|default=]# How frequently to poll Cortex configs# CLI flag: -alertmanager.configs.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=15s]# Listen address for cluster.# CLI flag: -cluster.listen-address[cluster_bind_address:\u0026lt;string\u0026gt;|default=\u0026#34;0.0.0.0:9094\u0026#34;]# Explicit address to advertise in cluster.# CLI flag: -cluster.advertise-address[cluster_advertise_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Initial peers (may be repeated).# CLI flag: -cluster.peer[peers:\u0026lt;listofstring\u0026gt;|default=[]]# Time to wait between peers to send notifications.# CLI flag: -cluster.peer-timeout[peer_timeout:\u0026lt;duration\u0026gt;|default=15s]# Filename of fallback config to use if none specified for instance.# CLI flag: -alertmanager.configs.fallback[fallback_config_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Root of URL to generate if config is http://internal.monitor# CLI flag: -alertmanager.configs.auto-webhook-root[auto_webhook_root:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]storage:# Type of backend to use to store alertmanager configs. Supported values are:# \u0026#34;configdb\u0026#34;, \u0026#34;gcs\u0026#34;, \u0026#34;s3\u0026#34;, \u0026#34;local\u0026#34;.# CLI flag: -alertmanager.storage.type[type:\u0026lt;string\u0026gt;|default=\u0026#34;configdb\u0026#34;]# The configstore_config configures the config database storing rules and# alerts, and is used by the Cortex alertmanager.# The CLI flags prefix for this block config is: alertmanager[configdb:\u0026lt;configstore_config\u0026gt;]local:# Path at which alertmanager configurations are stored.# CLI flag: -alertmanager.storage.local.path[path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]gcs:# Name of GCS bucket. Please refer to# https://cloud.google.com/docs/authentication/production for more# information about how to configure authentication.# CLI flag: -alertmanager.storage.gcs.bucketname[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The size of the buffer that GCS client for each PUT request. 0 to disable# buffering.# CLI flag: -alertmanager.storage.gcs.chunk-buffer-size[chunk_buffer_size:\u0026lt;int\u0026gt;|default=0]# The duration after which the requests to GCS should be timed out.# CLI flag: -alertmanager.storage.gcs.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=0s]s3:# S3 endpoint URL with escaped Key and Secret encoded. If only region is# specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;bucket-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -alertmanager.storage.s3.url[s3:\u0026lt;url\u0026gt;|default=]# Set this to `true` to force the request to use path-style addressing.# CLI flag: -alertmanager.storage.s3.force-path-style[s3forcepathstyle:\u0026lt;boolean\u0026gt;|default=false]# Comma separated list of bucket names to evenly distribute chunks over.# Overrides any buckets specified in s3.url flag# CLI flag: -alertmanager.storage.s3.buckets[bucketnames:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 Endpoint to connect to.# CLI flag: -alertmanager.storage.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS region to use.# CLI flag: -alertmanager.storage.s3.region[region:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Access Key ID# CLI flag: -alertmanager.storage.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Secret Access Key# CLI flag: -alertmanager.storage.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Disable https on s3 connection.# CLI flag: -alertmanager.storage.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]# Enable AES256 AWS Server Side Encryption# CLI flag: -alertmanager.storage.s3.sse-encryption[sse_encryption:\u0026lt;boolean\u0026gt;|default=false]http_config:# The maximum amount of time an idle connection will be held open.# CLI flag: -alertmanager.storage.s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# If non-zero, specifies the amount of time to wait for a server\u0026#39;s# response headers after fully writing the request.# CLI flag: -alertmanager.storage.s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=0s]# Set to false to skip verifying the certificate chain and hostname.# CLI flag: -alertmanager.storage.s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]# Enable the experimental alertmanager config api.# CLI flag: -experimental.alertmanager.enable-api[enable_api:\u0026lt;boolean\u0026gt;|default=false]table_manager_config The table_manager_config configures the Cortex table-manager.\n# If true, disable all changes to DB capacity# CLI flag: -table-manager.throughput-updates-disabled[throughput_updates_disabled:\u0026lt;boolean\u0026gt;|default=false]# If true, enables retention deletes of DB tables# CLI flag: -table-manager.retention-deletes-enabled[retention_deletes_enabled:\u0026lt;boolean\u0026gt;|default=false]# Tables older than this retention period are deleted. Note: This setting is# destructive to data!(default: 0, which disables deletion)# CLI flag: -table-manager.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=0s]# How frequently to poll backend to learn our capacity.# CLI flag: -table-manager.poll-interval[poll_interval:\u0026lt;duration\u0026gt;|default=2m]# Periodic tables grace period (duration which table will be created/deleted# before/after it\u0026#39;s needed).# CLI flag: -table-manager.periodic-table.grace-period[creation_grace_period:\u0026lt;duration\u0026gt;|default=10m]index_tables_provisioning:# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.index-table.enable-ondemand-throughput-mode[enable_ondemand_throughput_mode:\u0026lt;boolean\u0026gt;|default=false]# Table default write throughput. Supported by DynamoDB# CLI flag: -table-manager.index-table.write-throughput[provisioned_write_throughput:\u0026lt;int\u0026gt;|default=1000]# Table default read throughput. Supported by DynamoDB# CLI flag: -table-manager.index-table.read-throughput[provisioned_read_throughput:\u0026lt;int\u0026gt;|default=300]write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.index-table.inactive-enable-ondemand-throughput-mode[enable_inactive_throughput_on_demand_mode:\u0026lt;boolean\u0026gt;|default=false]# Table write throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.index-table.inactive-write-throughput[inactive_write_throughput:\u0026lt;int\u0026gt;|default=1]# Table read throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.index-table.inactive-read-throughput[inactive_read_throughput:\u0026lt;int\u0026gt;|default=300]inactive_write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable write autoscale.# CLI flag: -table-manager.index-table.inactive-write-throughput.scale-last-n[inactive_write_scale_lastn:\u0026lt;int\u0026gt;|default=4]# Number of last inactive tables to enable read autoscale.# CLI flag: -table-manager.index-table.inactive-read-throughput.scale-last-n[inactive_read_scale_lastn:\u0026lt;int\u0026gt;|default=4]chunk_tables_provisioning:# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.chunk-table.enable-ondemand-throughput-mode[enable_ondemand_throughput_mode:\u0026lt;boolean\u0026gt;|default=false]# Table default write throughput. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.write-throughput[provisioned_write_throughput:\u0026lt;int\u0026gt;|default=1000]# Table default read throughput. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.read-throughput[provisioned_read_throughput:\u0026lt;int\u0026gt;|default=300]write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -table-manager.chunk-table.inactive-enable-ondemand-throughput-mode[enable_inactive_throughput_on_demand_mode:\u0026lt;boolean\u0026gt;|default=false]# Table write throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.inactive-write-throughput[inactive_write_throughput:\u0026lt;int\u0026gt;|default=1]# Table read throughput for inactive tables. Supported by DynamoDB# CLI flag: -table-manager.chunk-table.inactive-read-throughput[inactive_read_throughput:\u0026lt;int\u0026gt;|default=300]inactive_write_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]inactive_read_scale:# Should we enable autoscale for the table.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Number of last inactive tables to enable write autoscale.# CLI flag: -table-manager.chunk-table.inactive-write-throughput.scale-last-n[inactive_write_scale_lastn:\u0026lt;int\u0026gt;|default=4]# Number of last inactive tables to enable read autoscale.# CLI flag: -table-manager.chunk-table.inactive-read-throughput.scale-last-n[inactive_read_scale_lastn:\u0026lt;int\u0026gt;|default=4]storage_config The storage_config configures where Cortex stores the data (chunks storage engine).\n# The storage engine to use: chunks or blocks.# CLI flag: -store.engine[engine:\u0026lt;string\u0026gt;|default=\u0026#34;chunks\u0026#34;]aws:dynamodb:# DynamoDB endpoint URL with escaped Key and Secret encoded. If only region# is specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;table-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -dynamodb.url[dynamodb_url:\u0026lt;url\u0026gt;|default=]# DynamoDB table management requests per second limit.# CLI flag: -dynamodb.api-limit[api_limit:\u0026lt;float\u0026gt;|default=2]# DynamoDB rate cap to back off when throttled.# CLI flag: -dynamodb.throttle-limit[throttle_limit:\u0026lt;float\u0026gt;|default=10]metrics:# Use metrics-based autoscaling, via this query URL# CLI flag: -metrics.url[url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Queue length above which we will scale up capacity# CLI flag: -metrics.target-queue-length[target_queue_length:\u0026lt;int\u0026gt;|default=100000]# Scale up capacity by this multiple# CLI flag: -metrics.scale-up-factor[scale_up_factor:\u0026lt;float\u0026gt;|default=1.3]# Ignore throttling below this level (rate per second)# CLI flag: -metrics.ignore-throttle-below[ignore_throttle_below:\u0026lt;float\u0026gt;|default=1]# query to fetch ingester queue length# CLI flag: -metrics.queue-length-query[queue_length_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;]# query to fetch throttle rates per table# CLI flag: -metrics.write-throttle-query[write_throttle_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;]# query to fetch write capacity usage per table# CLI flag: -metrics.usage-query[write_usage_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;]# query to fetch read capacity usage per table# CLI flag: -metrics.read-usage-query[read_usage_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;]# query to fetch read errors per table# CLI flag: -metrics.read-error-query[read_error_query:\u0026lt;string\u0026gt;|default=\u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;]# Number of chunks to group together to parallelise fetches (zero to# disable)# CLI flag: -dynamodb.chunk-gang-size[chunk_gang_size:\u0026lt;int\u0026gt;|default=10]# Max number of chunk-get operations to start in parallel# CLI flag: -dynamodb.chunk.get-max-parallelism[chunk_get_max_parallelism:\u0026lt;int\u0026gt;|default=32]backoff_config:# Minimum backoff time# CLI flag: -dynamodb.min-backoff[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum backoff time# CLI flag: -dynamodb.max-backoff[max_period:\u0026lt;duration\u0026gt;|default=50s]# Maximum number of times to retry an operation# CLI flag: -dynamodb.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]# S3 endpoint URL with escaped Key and Secret encoded. If only region is# specified as a host, proper endpoint will be deduced. Use# inmemory:///\u0026lt;bucket-name\u0026gt; to use a mock in-memory implementation.# CLI flag: -s3.url[s3:\u0026lt;url\u0026gt;|default=]# Set this to `true` to force the request to use path-style addressing.# CLI flag: -s3.force-path-style[s3forcepathstyle:\u0026lt;boolean\u0026gt;|default=false]# Comma separated list of bucket names to evenly distribute chunks over.# Overrides any buckets specified in s3.url flag# CLI flag: -s3.buckets[bucketnames:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 Endpoint to connect to.# CLI flag: -s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS region to use.# CLI flag: -s3.region[region:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Access Key ID# CLI flag: -s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# AWS Secret Access Key# CLI flag: -s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Disable https on s3 connection.# CLI flag: -s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]# Enable AES256 AWS Server Side Encryption# CLI flag: -s3.sse-encryption[sse_encryption:\u0026lt;boolean\u0026gt;|default=false]http_config:# The maximum amount of time an idle connection will be held open.# CLI flag: -s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# If non-zero, specifies the amount of time to wait for a server\u0026#39;s response# headers after fully writing the request.# CLI flag: -s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=0s]# Set to false to skip verifying the certificate chain and hostname.# CLI flag: -s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]azure:# Azure Cloud environment. Supported values are: AzureGlobal, AzureChinaCloud,# AzureGermanCloud, AzureUSGovernment.# CLI flag: -azure.environment[environment:\u0026lt;string\u0026gt;|default=\u0026#34;AzureGlobal\u0026#34;]# Name of the blob container used to store chunks. This container must be# created before running cortex.# CLI flag: -azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# The Microsoft Azure account name to be used# CLI flag: -azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The Microsoft Azure account key to use.# CLI flag: -azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Preallocated buffer size for downloads.# CLI flag: -azure.download-buffer-size[download_buffer_size:\u0026lt;int\u0026gt;|default=512000]# Preallocated buffer size for uploads.# CLI flag: -azure.upload-buffer-size[upload_buffer_size:\u0026lt;int\u0026gt;|default=256000]# Number of buffers used to used to upload a chunk.# CLI flag: -azure.download-buffer-count[upload_buffer_count:\u0026lt;int\u0026gt;|default=1]# Timeout for requests made against azure blob storage.# CLI flag: -azure.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=30s]# Number of retries for a request which times out.# CLI flag: -azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=5]# Minimum time to wait before retrying a request.# CLI flag: -azure.min-retry-delay[min_retry_delay:\u0026lt;duration\u0026gt;|default=10ms]# Maximum time to wait before retrying a request.# CLI flag: -azure.max-retry-delay[max_retry_delay:\u0026lt;duration\u0026gt;|default=500ms]bigtable:# Bigtable project ID.# CLI flag: -bigtable.project[project:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Bigtable instance ID. Please refer to# https://cloud.google.com/docs/authentication/production for more information# about how to configure authentication.# CLI flag: -bigtable.instance[instance:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]grpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -bigtable.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -bigtable.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Deprecated: Use gzip compression when sending messages. If true,# overrides grpc-compression flag.# CLI flag: -bigtable.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Use compression when sending messages. Supported values are: \u0026#39;gzip\u0026#39;,# \u0026#39;snappy\u0026#39; and \u0026#39;\u0026#39; (disable compression)# CLI flag: -bigtable.grpc-compression[grpc_compression:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -bigtable.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -bigtable.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -bigtable.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -bigtable.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -bigtable.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -bigtable.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10]# If enabled, once a tables info is fetched, it is cached.# CLI flag: -bigtable.table-cache.enabled[table_cache_enabled:\u0026lt;boolean\u0026gt;|default=true]# Duration to cache tables before checking again.# CLI flag: -bigtable.table-cache.expiration[table_cache_expiration:\u0026lt;duration\u0026gt;|default=30m]gcs:# Name of GCS bucket. Please refer to# https://cloud.google.com/docs/authentication/production for more information# about how to configure authentication.# CLI flag: -gcs.bucketname[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The size of the buffer that GCS client for each PUT request. 0 to disable# buffering.# CLI flag: -gcs.chunk-buffer-size[chunk_buffer_size:\u0026lt;int\u0026gt;|default=0]# The duration after which the requests to GCS should be timed out.# CLI flag: -gcs.request-timeout[request_timeout:\u0026lt;duration\u0026gt;|default=0s]cassandra:# Comma-separated hostnames or IPs of Cassandra instances.# CLI flag: -cassandra.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Port that Cassandra is running on# CLI flag: -cassandra.port[port:\u0026lt;int\u0026gt;|default=9042]# Keyspace to use in Cassandra.# CLI flag: -cassandra.keyspace[keyspace:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Consistency level for Cassandra.# CLI flag: -cassandra.consistency[consistency:\u0026lt;string\u0026gt;|default=\u0026#34;QUORUM\u0026#34;]# Replication factor to use in Cassandra.# CLI flag: -cassandra.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# Instruct the cassandra driver to not attempt to get host info from the# system.peers table.# CLI flag: -cassandra.disable-initial-host-lookup[disable_initial_host_lookup:\u0026lt;boolean\u0026gt;|default=false]# Use SSL when connecting to cassandra instances.# CLI flag: -cassandra.ssl[SSL:\u0026lt;boolean\u0026gt;|default=false]# Require SSL certificate validation.# CLI flag: -cassandra.host-verification[host_verification:\u0026lt;boolean\u0026gt;|default=true]# Path to certificate file to verify the peer.# CLI flag: -cassandra.ca-path[CA_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Enable password authentication when connecting to cassandra.# CLI flag: -cassandra.auth[auth:\u0026lt;boolean\u0026gt;|default=false]# Username to use when connecting to cassandra.# CLI flag: -cassandra.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Password to use when connecting to cassandra.# CLI flag: -cassandra.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# File containing password to use when connecting to cassandra.# CLI flag: -cassandra.password-file[password_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If set, when authenticating with cassandra a custom authenticator will be# expected during the handshake. This flag can be set multiple times.# CLI flag: -cassandra.custom-authenticator[custom_authenticators:\u0026lt;listofstring\u0026gt;|default=[]]# Timeout when connecting to cassandra.# CLI flag: -cassandra.timeout[timeout:\u0026lt;duration\u0026gt;|default=2s]# Initial connection timeout, used during initial dial to server.# CLI flag: -cassandra.connect-timeout[connect_timeout:\u0026lt;duration\u0026gt;|default=5s]# Interval to retry connecting to cassandra nodes marked as DOWN.# CLI flag: -cassandra.reconnent-interval[reconnect_interval:\u0026lt;duration\u0026gt;|default=1s]# Number of retries to perform on a request. Set to 0 to disable retries.# CLI flag: -cassandra.max-retries[max_retries:\u0026lt;int\u0026gt;|default=0]# Maximum time to wait before retrying a failed request.# CLI flag: -cassandra.retry-max-backoff[retry_max_backoff:\u0026lt;duration\u0026gt;|default=10s]# Minimum time to wait before retrying a failed request.# CLI flag: -cassandra.retry-min-backoff[retry_min_backoff:\u0026lt;duration\u0026gt;|default=100ms]# Limit number of concurrent queries to Cassandra. Set to 0 to disable the# limit.# CLI flag: -cassandra.query-concurrency[query_concurrency:\u0026lt;int\u0026gt;|default=0]# Number of TCP connections per host.# CLI flag: -cassandra.num-connections[num_connections:\u0026lt;int\u0026gt;|default=2]# Convict hosts of being down on failure.# CLI flag: -cassandra.convict-hosts-on-failure[convict_hosts_on_failure:\u0026lt;boolean\u0026gt;|default=true]# Table options used to create index or chunk tables. This value is used as# plain text in the table `WITH` like this, \u0026#34;CREATE TABLE# \u0026lt;generated_by_cortex\u0026gt; (...) WITH \u0026lt;cassandra.table-options\u0026gt;\u0026#34;. For details,# see https://cortexmetrics.io/docs/production/cassandra. By default it will# use the default table options of your Cassandra cluster.# CLI flag: -cassandra.table-options[table_options:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]boltdb:# Location of BoltDB index files.# CLI flag: -boltdb.dir[directory:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]filesystem:# Directory to store chunks in.# CLI flag: -local.chunk-directory[directory:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]swift:# Openstack authentication URL.# CLI flag: -swift.auth-url[auth_url:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack username for the api.# CLI flag: -swift.username[username:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -swift.user-domain-name[user_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -swift.user-domain-id[user_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack userid for the api.# CLI flag: -swift.user-id[user_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack api key.# CLI flag: -swift.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain id.# CLI flag: -swift.domain-id[domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack user\u0026#39;s domain name.# CLI flag: -swift.domain-name[domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project id (v2,v3 auth only).# CLI flag: -swift.project-id[project_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack project name (v2,v3 auth only).# CLI flag: -swift.project-name[project_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Id of the project\u0026#39;s domain (v3 auth only), only needed if it differs the# from user domain.# CLI flag: -swift.project-domain-id[project_domain_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the project\u0026#39;s domain (v3 auth only), only needed if it differs from# the user domain.# CLI flag: -swift.project-domain-name[project_domain_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Openstack Region to use eg LON, ORD - default is use first region (v2,v3# auth only)# CLI flag: -swift.region-name[region_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the Swift container to put chunks in.# CLI flag: -swift.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;cortex\u0026#34;]# Cache validity for active index entries. Should be no higher than# -ingester.max-chunk-idle.# CLI flag: -store.index-cache-validity[index_cache_validity:\u0026lt;duration\u0026gt;|default=5m]index_queries_cache_config:# Cache config for index entry reading. Enable in-memory cache.# CLI flag: -store.index-cache-read.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for index entry reading. The default validity of entries for# caches unless overridden.# CLI flag: -store.index-cache-read.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for index entry reading. At what concurrency to write back to# cache.# CLI flag: -store.index-cache-read.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for index entry reading. How many key batches to buffer for# background write-back.# CLI flag: -store.index-cache-read.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.index-cache-read[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.index-cache-read[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.index-cache-read[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.index-cache-read[fifocache:\u0026lt;fifo_cache_config\u0026gt;]delete_store:# Store for keeping delete request# CLI flag: -deletes.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Name of the table which stores delete requests# CLI flag: -deletes.requests-table-name[requests_table_name:\u0026lt;string\u0026gt;|default=\u0026#34;delete_requests\u0026#34;]table_provisioning:# Enables on demand throughput provisioning for the storage provider (if# supported). Applies only to tables which are not autoscaled. Supported by# DynamoDB# CLI flag: -deletes.table.enable-ondemand-throughput-mode[enable_ondemand_throughput_mode:\u0026lt;boolean\u0026gt;|default=false]# Table default write throughput. Supported by DynamoDB# CLI flag: -deletes.table.write-throughput[provisioned_write_throughput:\u0026lt;int\u0026gt;|default=1]# Table default read throughput. Supported by DynamoDB# CLI flag: -deletes.table.read-throughput[provisioned_read_throughput:\u0026lt;int\u0026gt;|default=300]write_scale:# Should we enable autoscale for the table.# CLI flag: -deletes.table.write-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -deletes.table.write-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -deletes.table.write-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -deletes.table.write-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -deletes.table.write-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -deletes.table.write-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -deletes.table.write-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]read_scale:# Should we enable autoscale for the table.# CLI flag: -deletes.table.read-throughput.scale.enabled[enabled:\u0026lt;boolean\u0026gt;|default=false]# AWS AutoScaling role ARN# CLI flag: -deletes.table.read-throughput.scale.role-arn[role_arn:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# DynamoDB minimum provision capacity.# CLI flag: -deletes.table.read-throughput.scale.min-capacity[min_capacity:\u0026lt;int\u0026gt;|default=3000]# DynamoDB maximum provision capacity.# CLI flag: -deletes.table.read-throughput.scale.max-capacity[max_capacity:\u0026lt;int\u0026gt;|default=6000]# DynamoDB minimum seconds between each autoscale up.# CLI flag: -deletes.table.read-throughput.scale.out-cooldown[out_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB minimum seconds between each autoscale down.# CLI flag: -deletes.table.read-throughput.scale.in-cooldown[in_cooldown:\u0026lt;int\u0026gt;|default=1800]# DynamoDB target ratio of consumed capacity to provisioned capacity.# CLI flag: -deletes.table.read-throughput.scale.target-value[target:\u0026lt;float\u0026gt;|default=80]# Tag (of the form key=value) to be added to the tables. Supported by# DynamoDB# CLI flag: -deletes.table.tags[tags:\u0026lt;mapofstringtostring\u0026gt;|default=]grpc_store:# Hostname or IP of the gRPC store instance.# CLI flag: -grpc-store.server-address[server_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]flusher_config The flusher_config configures the WAL flusher target, used to manually run one-time flushes when scaling down ingesters.\n# Directory to read WAL from (chunks storage engine only).# CLI flag: -flusher.wal-dir[wal_dir:\u0026lt;string\u0026gt;|default=\u0026#34;wal\u0026#34;]# Number of concurrent goroutines flushing to storage (chunks storage engine# only).# CLI flag: -flusher.concurrent-flushes[concurrent_flushes:\u0026lt;int\u0026gt;|default=50]# Timeout for individual flush operations (chunks storage engine only).# CLI flag: -flusher.flush-op-timeout[flush_op_timeout:\u0026lt;duration\u0026gt;|default=2m]# Stop Cortex after flush has finished. If false, Cortex process will keep# running, doing nothing.# CLI flag: -flusher.exit-after-flush[exit_after_flush:\u0026lt;boolean\u0026gt;|default=true]chunk_store_config The chunk_store_config configures how Cortex stores the data (chunks storage engine).\nchunk_cache_config:# Cache config for chunks. Enable in-memory cache.# CLI flag: -store.chunks-cache.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for chunks. The default validity of entries for caches unless# overridden.# CLI flag: -store.chunks-cache.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for chunks. At what concurrency to write back to cache.# CLI flag: -store.chunks-cache.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for chunks. How many key batches to buffer for background# write-back.# CLI flag: -store.chunks-cache.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.chunks-cache[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.chunks-cache[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.chunks-cache[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.chunks-cache[fifocache:\u0026lt;fifo_cache_config\u0026gt;]write_dedupe_cache_config:# Cache config for index entry writing. Enable in-memory cache.# CLI flag: -store.index-cache-write.cache.enable-fifocache[enable_fifocache:\u0026lt;boolean\u0026gt;|default=false]# Cache config for index entry writing. The default validity of entries for# caches unless overridden.# CLI flag: -store.index-cache-write.default-validity[default_validity:\u0026lt;duration\u0026gt;|default=0s]background:# Cache config for index entry writing. At what concurrency to write back to# cache.# CLI flag: -store.index-cache-write.background.write-back-concurrency[writeback_goroutines:\u0026lt;int\u0026gt;|default=10]# Cache config for index entry writing. How many key batches to buffer for# background write-back.# CLI flag: -store.index-cache-write.background.write-back-buffer[writeback_buffer:\u0026lt;int\u0026gt;|default=10000]# The memcached_config block configures how data is stored in Memcached (ie.# expiration).# The CLI flags prefix for this block config is: store.index-cache-write[memcached:\u0026lt;memcached_config\u0026gt;]# The memcached_client_config configures the client used to connect to# Memcached.# The CLI flags prefix for this block config is: store.index-cache-write[memcached_client:\u0026lt;memcached_client_config\u0026gt;]# The redis_config configures the Redis backend cache.# The CLI flags prefix for this block config is: store.index-cache-write[redis:\u0026lt;redis_config\u0026gt;]# The fifo_cache_config configures the local in-memory cache.# The CLI flags prefix for this block config is: store.index-cache-write[fifocache:\u0026lt;fifo_cache_config\u0026gt;]# Cache index entries older than this period. 0 to disable.# CLI flag: -store.cache-lookups-older-than[cache_lookups_older_than:\u0026lt;duration\u0026gt;|default=0s]# Limit how long back data can be queried# CLI flag: -store.max-look-back-period[max_look_back_period:\u0026lt;duration\u0026gt;|default=0s]ingester_client_config The ingester_client_config configures how the Cortex distributors connect to the ingesters.\ngrpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -ingester.client.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -ingester.client.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Deprecated: Use gzip compression when sending messages. If true, overrides# grpc-compression flag.# CLI flag: -ingester.client.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Use compression when sending messages. Supported values are: \u0026#39;gzip\u0026#39;,# \u0026#39;snappy\u0026#39; and \u0026#39;\u0026#39; (disable compression)# CLI flag: -ingester.client.grpc-compression[grpc_compression:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -ingester.client.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -ingester.client.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -ingester.client.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -ingester.client.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -ingester.client.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -ingester.client.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10]# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -ingester.client.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -ingester.client.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against. If# not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -ingester.client.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -ingester.client.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]frontend_worker_config The frontend_worker_config configures the worker - running within the Cortex querier - picking up and executing queries enqueued by the query-frontend.\n# Address of query frontend service, in host:port format.# CLI flag: -querier.frontend-address[frontend_address:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of simultaneous queries to process per query frontend.# CLI flag: -querier.worker-parallelism[parallelism:\u0026lt;int\u0026gt;|default=10]# Force worker concurrency to match the -querier.max-concurrent option.# Overrides querier.worker-parallelism.# CLI flag: -querier.worker-match-max-concurrent[match_max_concurrent:\u0026lt;boolean\u0026gt;|default=false]# How often to query DNS.# CLI flag: -querier.dns-lookup-period[dns_lookup_duration:\u0026lt;duration\u0026gt;|default=10s]# Querier ID, sent to frontend service to identify requests from the same# querier. Defaults to hostname.# CLI flag: -querier.id[id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]grpc_client_config:# gRPC client max receive message size (bytes).# CLI flag: -querier.frontend-client.grpc-max-recv-msg-size[max_recv_msg_size:\u0026lt;int\u0026gt;|default=104857600]# gRPC client max send message size (bytes).# CLI flag: -querier.frontend-client.grpc-max-send-msg-size[max_send_msg_size:\u0026lt;int\u0026gt;|default=16777216]# Deprecated: Use gzip compression when sending messages. If true, overrides# grpc-compression flag.# CLI flag: -querier.frontend-client.grpc-use-gzip-compression[use_gzip_compression:\u0026lt;boolean\u0026gt;|default=false]# Use compression when sending messages. Supported values are: \u0026#39;gzip\u0026#39;,# \u0026#39;snappy\u0026#39; and \u0026#39;\u0026#39; (disable compression)# CLI flag: -querier.frontend-client.grpc-compression[grpc_compression:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Rate limit for gRPC client; 0 means disabled.# CLI flag: -querier.frontend-client.grpc-client-rate-limit[rate_limit:\u0026lt;float\u0026gt;|default=0]# Rate limit burst for gRPC client.# CLI flag: -querier.frontend-client.grpc-client-rate-limit-burst[rate_limit_burst:\u0026lt;int\u0026gt;|default=0]# Enable backoff and retry when we hit ratelimits.# CLI flag: -querier.frontend-client.backoff-on-ratelimits[backoff_on_ratelimits:\u0026lt;boolean\u0026gt;|default=false]backoff_config:# Minimum delay when backing off.# CLI flag: -querier.frontend-client.backoff-min-period[min_period:\u0026lt;duration\u0026gt;|default=100ms]# Maximum delay when backing off.# CLI flag: -querier.frontend-client.backoff-max-period[max_period:\u0026lt;duration\u0026gt;|default=10s]# Number of times to backoff and retry before failing.# CLI flag: -querier.frontend-client.backoff-retries[max_retries:\u0026lt;int\u0026gt;|default=10]# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -querier.frontend-client.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -querier.frontend-client.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against. If# not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -querier.frontend-client.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -querier.frontend-client.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]etcd_config The etcd_config configures the etcd client. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n no prefix compactor.ring distributor.ha-tracker distributor.ring ruler.ring store-gateway.sharding-ring  # The etcd endpoints to connect to.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.endpoints[endpoints:\u0026lt;listofstring\u0026gt;|default=[]]# The dial timeout for the etcd connection.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.dial-timeout[dial_timeout:\u0026lt;duration\u0026gt;|default=10s]# The maximum number of retries to do for failed ops.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.max-retries[max_retries:\u0026lt;int\u0026gt;|default=10]# Enable TLS.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.tls-enabled[tls_enabled:\u0026lt;boolean\u0026gt;|default=false]# The TLS certificate file path.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The TLS private key file path.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The trusted CA file path.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -\u0026lt;prefix\u0026gt;.etcd.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]consul_config The consul_config configures the consul client. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n no prefix compactor.ring distributor.ha-tracker distributor.ring ruler.ring store-gateway.sharding-ring  # Hostname and port of Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.hostname[host:\u0026lt;string\u0026gt;|default=\u0026#34;localhost:8500\u0026#34;]# ACL Token used to interact with Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acl-token[acl_token:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# HTTP timeout when talking to Consul# CLI flag: -\u0026lt;prefix\u0026gt;.consul.client-timeout[http_client_timeout:\u0026lt;duration\u0026gt;|default=20s]# Enable consistent reads to Consul.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.consistent-reads[consistent_reads:\u0026lt;boolean\u0026gt;|default=false]# Rate limit when watching key or prefix in Consul, in requests per second. 0# disables the rate limit.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit[watch_rate_limit:\u0026lt;float\u0026gt;|default=1]# Burst size used in rate limit. Values less than 1 are treated as 1.# CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-burst-size[watch_burst_size:\u0026lt;int\u0026gt;|default=1]memberlist_config The memberlist_config configures the Gossip memberlist.\n# Name of the node in memberlist cluster. Defaults to hostname.# CLI flag: -memberlist.nodename[node_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Add random suffix to the node name.# CLI flag: -memberlist.randomize-node-name[randomize_node_name:\u0026lt;boolean\u0026gt;|default=true]# The timeout for establishing a connection with a remote node, and for# read/write operations. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.stream-timeout[stream_timeout:\u0026lt;duration\u0026gt;|default=0s]# Multiplication factor used when sending out messages (factor * log(N+1)).# CLI flag: -memberlist.retransmit-factor[retransmit_factor:\u0026lt;int\u0026gt;|default=0]# How often to use pull/push sync. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.pullpush-interval[pull_push_interval:\u0026lt;duration\u0026gt;|default=0s]# How often to gossip. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-interval[gossip_interval:\u0026lt;duration\u0026gt;|default=0s]# How many nodes to gossip to. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-nodes[gossip_nodes:\u0026lt;int\u0026gt;|default=0]# How long to keep gossiping to dead nodes, to give them chance to refute their# death. Uses memberlist LAN defaults if 0.# CLI flag: -memberlist.gossip-to-dead-nodes-time[gossip_to_dead_nodes_time:\u0026lt;duration\u0026gt;|default=0s]# How soon can dead node\u0026#39;s name be reclaimed with new address. Defaults to 0,# which is disabled.# CLI flag: -memberlist.dead-node-reclaim-time[dead_node_reclaim_time:\u0026lt;duration\u0026gt;|default=0s]# Other cluster members to join. Can be specified multiple times. It can be an# IP, hostname or an entry specified in the DNS Service Discovery format (see# https://cortexmetrics.io/docs/configuration/arguments/#dns-service-discovery# for more details).# CLI flag: -memberlist.join[join_members:\u0026lt;listofstring\u0026gt;|default=[]]# Min backoff duration to join other cluster members.# CLI flag: -memberlist.min-join-backoff[min_join_backoff:\u0026lt;duration\u0026gt;|default=1s]# Max backoff duration to join other cluster members.# CLI flag: -memberlist.max-join-backoff[max_join_backoff:\u0026lt;duration\u0026gt;|default=1m]# Max number of retries to join other cluster members.# CLI flag: -memberlist.max-join-retries[max_join_retries:\u0026lt;int\u0026gt;|default=10]# If this node fails to join memberlist cluster, abort.# CLI flag: -memberlist.abort-if-join-fails[abort_if_cluster_join_fails:\u0026lt;boolean\u0026gt;|default=true]# If not 0, how often to rejoin the cluster. Occasional rejoin can help to fix# the cluster split issue, and is harmless otherwise. For example when using# only few components as a seed nodes (via -memberlist.join), then it\u0026#39;s# recommended to use rejoin. If -memberlist.join points to dynamic service that# resolves to all gossiping nodes (eg. Kubernetes headless service), then rejoin# is not needed.# CLI flag: -memberlist.rejoin-interval[rejoin_interval:\u0026lt;duration\u0026gt;|default=0s]# How long to keep LEFT ingesters in the ring.# CLI flag: -memberlist.left-ingesters-timeout[left_ingesters_timeout:\u0026lt;duration\u0026gt;|default=5m]# Timeout for leaving memberlist cluster.# CLI flag: -memberlist.leave-timeout[leave_timeout:\u0026lt;duration\u0026gt;|default=5s]# IP address to listen on for gossip messages. Multiple addresses may be# specified. Defaults to 0.0.0.0# CLI flag: -memberlist.bind-addr[bind_addr:\u0026lt;listofstring\u0026gt;|default=[]]# Port to listen on for gossip messages.# CLI flag: -memberlist.bind-port[bind_port:\u0026lt;int\u0026gt;|default=7946]# Timeout used when connecting to other nodes to send packet.# CLI flag: -memberlist.packet-dial-timeout[packet_dial_timeout:\u0026lt;duration\u0026gt;|default=5s]# Timeout for writing \u0026#39;packet\u0026#39; data.# CLI flag: -memberlist.packet-write-timeout[packet_write_timeout:\u0026lt;duration\u0026gt;|default=5s]limits_config The limits_config configures default and per-tenant limits imposed by Cortex services (ie. distributor, ingester, \u0026hellip;).\n# Per-user ingestion rate limit in samples per second.# CLI flag: -distributor.ingestion-rate-limit[ingestion_rate:\u0026lt;float\u0026gt;|default=25000]# Whether the ingestion rate limit should be applied individually to each# distributor instance (local), or evenly shared across the cluster (global).# CLI flag: -distributor.ingestion-rate-limit-strategy[ingestion_rate_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;local\u0026#34;]# Per-user allowed ingestion burst size (in number of samples).# CLI flag: -distributor.ingestion-burst-size[ingestion_burst_size:\u0026lt;int\u0026gt;|default=50000]# Flag to enable, for all users, handling of samples with external labels# identifying replicas in an HA Prometheus setup.# CLI flag: -distributor.ha-tracker.enable-for-all-users[accept_ha_samples:\u0026lt;boolean\u0026gt;|default=false]# Prometheus label to look for in samples to identify a Prometheus HA cluster.# CLI flag: -distributor.ha-tracker.cluster[ha_cluster_label:\u0026lt;string\u0026gt;|default=\u0026#34;cluster\u0026#34;]# Prometheus label to look for in samples to identify a Prometheus HA replica.# CLI flag: -distributor.ha-tracker.replica[ha_replica_label:\u0026lt;string\u0026gt;|default=\u0026#34;__replica__\u0026#34;]# This flag can be used to specify label names that to drop during sample# ingestion within the distributor and can be repeated in order to drop multiple# labels.# CLI flag: -distributor.drop-label[drop_labels:\u0026lt;listofstring\u0026gt;|default=[]]# Maximum length accepted for label names# CLI flag: -validation.max-length-label-name[max_label_name_length:\u0026lt;int\u0026gt;|default=1024]# Maximum length accepted for label value. This setting also applies to the# metric name# CLI flag: -validation.max-length-label-value[max_label_value_length:\u0026lt;int\u0026gt;|default=2048]# Maximum number of label names per series.# CLI flag: -validation.max-label-names-per-series[max_label_names_per_series:\u0026lt;int\u0026gt;|default=30]# Maximum length accepted for metric metadata. Metadata refers to Metric Name,# HELP and UNIT.# CLI flag: -validation.max-metadata-length[max_metadata_length:\u0026lt;int\u0026gt;|default=1024]# Reject old samples.# CLI flag: -validation.reject-old-samples[reject_old_samples:\u0026lt;boolean\u0026gt;|default=false]# Maximum accepted sample age before rejecting.# CLI flag: -validation.reject-old-samples.max-age[reject_old_samples_max_age:\u0026lt;duration\u0026gt;|default=336h]# Duration which table will be created/deleted before/after it\u0026#39;s needed; we# won\u0026#39;t accept sample from before this time.# CLI flag: -validation.create-grace-period[creation_grace_period:\u0026lt;duration\u0026gt;|default=10m]# Enforce every metadata has a metric name.# CLI flag: -validation.enforce-metadata-metric-name[enforce_metadata_metric_name:\u0026lt;boolean\u0026gt;|default=true]# Enforce every sample has a metric name.# CLI flag: -validation.enforce-metric-name[enforce_metric_name:\u0026lt;boolean\u0026gt;|default=true]# The default tenant\u0026#39;s shard size when the shuffle-sharding strategy is used.# Must be set both on ingesters and distributors. When this setting is specified# in the per-tenant overrides, a value of 0 disables shuffle sharding for the# tenant.# CLI flag: -distributor.ingestion-tenant-shard-size[ingestion_tenant_shard_size:\u0026lt;int\u0026gt;|default=0]# The maximum number of series for which a query can fetch samples from each# ingester. This limit is enforced only in the ingesters (when querying samples# not flushed to the storage yet) and it\u0026#39;s a per-instance limit. This limit is# ignored when running the Cortex blocks storage.# CLI flag: -ingester.max-series-per-query[max_series_per_query:\u0026lt;int\u0026gt;|default=100000]# The maximum number of samples that a query can return. This limit only applies# when running the Cortex chunks storage with -querier.ingester-streaming=false.# CLI flag: -ingester.max-samples-per-query[max_samples_per_query:\u0026lt;int\u0026gt;|default=1000000]# The maximum number of active series per user, per ingester. 0 to disable.# CLI flag: -ingester.max-series-per-user[max_series_per_user:\u0026lt;int\u0026gt;|default=5000000]# The maximum number of active series per metric name, per ingester. 0 to# disable.# CLI flag: -ingester.max-series-per-metric[max_series_per_metric:\u0026lt;int\u0026gt;|default=50000]# The maximum number of active series per user, across the cluster. 0 to# disable. Supported only if -distributor.shard-by-all-labels is true.# CLI flag: -ingester.max-global-series-per-user[max_global_series_per_user:\u0026lt;int\u0026gt;|default=0]# The maximum number of active series per metric name, across the cluster. 0 to# disable.# CLI flag: -ingester.max-global-series-per-metric[max_global_series_per_metric:\u0026lt;int\u0026gt;|default=0]# Minimum number of samples in an idle chunk to flush it to the store. Use with# care, if chunks are less than this size they will be discarded. This option is# ignored when running the Cortex blocks storage. 0 to disable.# CLI flag: -ingester.min-chunk-length[min_chunk_length:\u0026lt;int\u0026gt;|default=0]# The maximum number of active metrics with metadata per user, per ingester. 0# to disable.# CLI flag: -ingester.max-metadata-per-user[max_metadata_per_user:\u0026lt;int\u0026gt;|default=8000]# The maximum number of metadata per metric, per ingester. 0 to disable.# CLI flag: -ingester.max-metadata-per-metric[max_metadata_per_metric:\u0026lt;int\u0026gt;|default=10]# The maximum number of active metrics with metadata per user, across the# cluster. 0 to disable. Supported only if -distributor.shard-by-all-labels is# true.# CLI flag: -ingester.max-global-metadata-per-user[max_global_metadata_per_user:\u0026lt;int\u0026gt;|default=0]# The maximum number of metadata per metric, across the cluster. 0 to disable.# CLI flag: -ingester.max-global-metadata-per-metric[max_global_metadata_per_metric:\u0026lt;int\u0026gt;|default=0]# Maximum number of chunks that can be fetched in a single query. This limit is# enforced when fetching chunks from the long-term storage. When running the# Cortex chunks storage, this limit is enforced in the querier, while when# running the Cortex blocks storage this limit is both enforced in the querier# and store-gateway. 0 to disable.# CLI flag: -store.query-chunk-limit[max_chunks_per_query:\u0026lt;int\u0026gt;|default=2000000]# Limit the query time range (end - start time). This limit is enforced in the# query-frontend (on the received query), in the querier (on the query possibly# split by the query-frontend) and in the chunks storage. 0 to disable.# CLI flag: -store.max-query-length[max_query_length:\u0026lt;duration\u0026gt;|default=0s]# Maximum number of queries will be scheduled in parallel by the frontend.# CLI flag: -querier.max-query-parallelism[max_query_parallelism:\u0026lt;int\u0026gt;|default=14]# Cardinality limit for index queries. This limit is ignored when running the# Cortex blocks storage. 0 to disable.# CLI flag: -store.cardinality-limit[cardinality_limit:\u0026lt;int\u0026gt;|default=100000]# Most recent allowed cacheable result per-tenant, to prevent caching very# recent results that might still be in flux.# CLI flag: -frontend.max-cache-freshness[max_cache_freshness:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of queriers that can handle requests for a single tenant. If# set to 0 or value higher than number of available queriers, *all* queriers# will handle requests for the tenant. Each frontend will select the same set of# queriers for the same tenant (given that all queriers are connected to all# frontends). This option only works with queriers connecting to the# query-frontend, not when using downstream URL.# CLI flag: -frontend.max-queriers-per-tenant[max_queriers_per_tenant:\u0026lt;int\u0026gt;|default=0]# Duration to delay the evaluation of rules to ensure the underlying metrics# have been pushed to Cortex.# CLI flag: -ruler.evaluation-delay-duration[ruler_evaluation_delay_duration:\u0026lt;duration\u0026gt;|default=0s]# The default tenant\u0026#39;s shard size when the shuffle-sharding strategy is used by# ruler. When this setting is specified in the per-tenant overrides, a value of# 0 disables shuffle sharding for the tenant.# CLI flag: -ruler.tenant-shard-size[ruler_tenant_shard_size:\u0026lt;int\u0026gt;|default=0]# The default tenant\u0026#39;s shard size when the shuffle-sharding strategy is used.# Must be set when the store-gateway sharding is enabled with the# shuffle-sharding strategy. When this setting is specified in the per-tenant# overrides, a value of 0 disables shuffle sharding for the tenant.# CLI flag: -store-gateway.tenant-shard-size[store_gateway_tenant_shard_size:\u0026lt;int\u0026gt;|default=0]# File name of per-user overrides. [deprecated, use -runtime-config.file# instead]# CLI flag: -limits.per-user-override-config[per_tenant_override_config:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Period with which to reload the overrides. [deprecated, use# -runtime-config.reload-period instead]# CLI flag: -limits.per-user-override-period[per_tenant_override_period:\u0026lt;duration\u0026gt;|default=10s]redis_config The redis_config configures the Redis backend cache. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write  # Redis Server endpoint to use for caching. A comma-separated list of endpoints# for Redis Cluster or Redis Sentinel. If empty, no redis will be used.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Redis Sentinel master name. An empty string for Redis Server or Redis Cluster.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.master-name[master_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum time to wait before giving up on redis requests.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.timeout[timeout:\u0026lt;duration\u0026gt;|default=500ms]# How long keys stay in the redis.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.expiration[expiration:\u0026lt;duration\u0026gt;|default=0s]# Database index.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.db[db:\u0026lt;int\u0026gt;|default=0]# Maximum number of connections in the pool.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.pool-size[pool_size:\u0026lt;int\u0026gt;|default=0]# Password to use when connecting to redis.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.password[password:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Enable connecting to redis with TLS.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.tls-enabled[tls_enabled:\u0026lt;boolean\u0026gt;|default=false]# Skip validating server certificate.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]# Close connections after remaining idle for this duration. If the value is# zero, then idle connections are not closed.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.idle-timeout[idle_timeout:\u0026lt;duration\u0026gt;|default=0s]# Close connections older than this duration. If the value is zero, then the# pool does not close connections based on age.# CLI flag: -\u0026lt;prefix\u0026gt;.redis.max-connection-age[max_connection_age:\u0026lt;duration\u0026gt;|default=0s]memcached_config The memcached_config block configures how data is stored in Memcached (ie. expiration). The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write  # How long keys stay in the memcache.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.expiration[expiration:\u0026lt;duration\u0026gt;|default=0s]# How many keys to fetch in each batch.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.batchsize[batch_size:\u0026lt;int\u0026gt;|default=1024]# Maximum active requests to memcache.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.parallelism[parallelism:\u0026lt;int\u0026gt;|default=100]memcached_client_config The memcached_client_config configures the client used to connect to Memcached. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write  # Hostname for memcached service to use. If empty and if addresses is unset, no# memcached will be used.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.hostname[host:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# SRV service used to discover memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.service[service:\u0026lt;string\u0026gt;|default=\u0026#34;memcached\u0026#34;]# EXPERIMENTAL: Comma separated addresses list in DNS Service Discovery format:# https://cortexmetrics.io/docs/configuration/arguments/#dns-service-discovery# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum time to wait before giving up on memcached requests.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# Maximum number of idle connections in pool.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.max-idle-conns[max_idle_conns:\u0026lt;int\u0026gt;|default=16]# Period with which to poll DNS for memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.update-interval[update_interval:\u0026lt;duration\u0026gt;|default=1m]# Use consistent hashing to distribute to memcache servers.# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.consistent-hash[consistent_hash:\u0026lt;boolean\u0026gt;|default=true]# Trip circuit-breaker after this number of consecutive dial failures (if zero# then circuit-breaker is disabled).# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.circuit-breaker-consecutive-failures[circuit_breaker_consecutive_failures:\u0026lt;int\u0026gt;|default=10]# Duration circuit-breaker remains open after tripping (if zero then 60 seconds# is used).# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.circuit-breaker-timeout[circuit_breaker_timeout:\u0026lt;duration\u0026gt;|default=10s]# Reset circuit-breaker counts after this long (if zero then never reset).# CLI flag: -\u0026lt;prefix\u0026gt;.memcached.circuit-breaker-interval[circuit_breaker_interval:\u0026lt;duration\u0026gt;|default=10s]fifo_cache_config The fifo_cache_config configures the local in-memory cache. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n frontend store.chunks-cache store.index-cache-read store.index-cache-write  # Maximum memory size of the cache in bytes. A unit suffix (KB, MB, GB) may be# applied.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes[max_size_bytes:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Maximum number of entries in the cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.max-size-items[max_size_items:\u0026lt;int\u0026gt;|default=0]# The expiry duration for the cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.duration[validity:\u0026lt;duration\u0026gt;|default=0s]# Deprecated (use max-size-items or max-size-bytes instead): The number of# entries to cache.# CLI flag: -\u0026lt;prefix\u0026gt;.fifocache.size[size:\u0026lt;int\u0026gt;|default=0]configs_config The configs_config configures the Cortex Configs DB and API.\ndatabase:# URI where the database can be found (for dev you can use memory://)# CLI flag: -configs.database.uri[uri:\u0026lt;string\u0026gt;|default=\u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;]# Path where the database migration files can be found# CLI flag: -configs.database.migrations-dir[migrations_dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# File containing password (username goes in URI)# CLI flag: -configs.database.password-file[password_file:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]api:notifications:# Disable Email notifications for Alertmanager.# CLI flag: -configs.notifications.disable-email[disable_email:\u0026lt;boolean\u0026gt;|default=false]# Disable WebHook notifications for Alertmanager.# CLI flag: -configs.notifications.disable-webhook[disable_webhook:\u0026lt;boolean\u0026gt;|default=false]configstore_config The configstore_config configures the config database storing rules and alerts, and is used by the Cortex alertmanager. The supported CLI flags \u0026lt;prefix\u0026gt; used to reference this config block are:\n alertmanager ruler  # URL of configs API server.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.url[configs_api_url:\u0026lt;url\u0026gt;|default=]# Timeout for requests to Weave Cloud configs service.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.client-timeout[client_timeout:\u0026lt;duration\u0026gt;|default=5s]# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against. If# not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -\u0026lt;prefix\u0026gt;.configs.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]blocks_storage_config The blocks_storage_config configures the blocks storage.\n# Backend storage to use. Supported backends are: s3, gcs, azure, filesystem.# CLI flag: -blocks-storage.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;s3\u0026#34;]s3:# The S3 bucket endpoint. It could be an AWS S3 endpoint listed at# https://docs.aws.amazon.com/general/latest/gr/s3.html or the address of an# S3-compatible service in hostname:port format.# CLI flag: -blocks-storage.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 bucket name# CLI flag: -blocks-storage.s3.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 secret access key# CLI flag: -blocks-storage.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 access key ID# CLI flag: -blocks-storage.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If enabled, use http:// for the S3 endpoint instead of https://. This could# be useful in local dev/test environments while using an S3-compatible# backend storage, like Minio.# CLI flag: -blocks-storage.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]http:# The time an idle connection will remain idle before closing.# CLI flag: -blocks-storage.s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# The amount of time the client will wait for a servers response headers.# CLI flag: -blocks-storage.s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=2m]# If the client connects to S3 via HTTPS and this option is enabled, the# client will accept any certificate and hostname.# CLI flag: -blocks-storage.s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]gcs:# GCS bucket name# CLI flag: -blocks-storage.gcs.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# JSON representing either a Google Developers Console client_credentials.json# file or a Google Developers service account key file. If empty, fallback to# Google default logic.# CLI flag: -blocks-storage.gcs.service-account[service_account:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]azure:# Azure storage account name# CLI flag: -blocks-storage.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage account key# CLI flag: -blocks-storage.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage container name# CLI flag: -blocks-storage.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage endpoint suffix without schema. The account name will be# prefixed to this value to create the FQDN# CLI flag: -blocks-storage.azure.endpoint-suffix[endpoint_suffix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of retries for recoverable errors# CLI flag: -blocks-storage.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]filesystem:# Local filesystem storage directory.# CLI flag: -blocks-storage.filesystem.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# This configures how the store-gateway synchronizes blocks stored in the# bucket.bucket_store:# Directory to store synchronized TSDB index headers.# CLI flag: -blocks-storage.bucket-store.sync-dir[sync_dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb-sync\u0026#34;]# How frequently scan the bucket to look for changes (new blocks shipped by# ingesters and blocks removed by retention or compaction). 0 disables it.# CLI flag: -blocks-storage.bucket-store.sync-interval[sync_interval:\u0026lt;duration\u0026gt;|default=5m]# Max size - in bytes - of a per-tenant chunk pool, used to reduce memory# allocations.# CLI flag: -blocks-storage.bucket-store.max-chunk-pool-bytes[max_chunk_pool_bytes:\u0026lt;int\u0026gt;|default=2147483648]# Max number of concurrent queries to execute against the long-term storage.# The limit is shared across all tenants.# CLI flag: -blocks-storage.bucket-store.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=100]# Maximum number of concurrent tenants synching blocks.# CLI flag: -blocks-storage.bucket-store.tenant-sync-concurrency[tenant_sync_concurrency:\u0026lt;int\u0026gt;|default=10]# Maximum number of concurrent blocks synching per tenant.# CLI flag: -blocks-storage.bucket-store.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from object# storage per tenant.# CLI flag: -blocks-storage.bucket-store.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of a block before it\u0026#39;s being read. Set it to safe value (e.g# 30m) if your object storage is eventually consistent. GCS and S3 are# (roughly) strongly consistent.# CLI flag: -blocks-storage.bucket-store.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]index_cache:# The index cache backend type. Supported values: inmemory, memcached.# CLI flag: -blocks-storage.bucket-store.index-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;inmemory\u0026#34;]inmemory:# Maximum size in bytes of in-memory index cache used to speed up blocks# index lookups (shared between all tenants).# CLI flag: -blocks-storage.bucket-store.index-cache.inmemory.max-size-bytes[max_size_bytes:\u0026lt;int\u0026gt;|default=1073741824]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV query,# dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup made after# that).# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations. If# set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should run.# If more keys are specified, internally keys are splitted into multiple# batches and fetched concurrently, honoring the max concurrency. If set# to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Compress postings before storing them to postings cache.# CLI flag: -blocks-storage.bucket-store.index-cache.postings-compression-enabled[postings_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]chunks_cache:# Backend for chunks cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.chunks-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV query,# dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup made after# that).# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations. If# set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should run.# If more keys are specified, internally keys are splitted into multiple# batches and fetched concurrently, honoring the max concurrency. If set# to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Size of each subrange that bucket object is split into for better caching.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-size[subrange_size:\u0026lt;int\u0026gt;|default=16000]# Maximum number of sub-GetRange requests that a single GetRange request can# be split into when fetching chunks. Zero or negative value = unlimited# number of sub-requests.# CLI flag: -blocks-storage.bucket-store.chunks-cache.max-get-range-requests[max_get_range_requests:\u0026lt;int\u0026gt;|default=3]# TTL for caching object attributes for chunks.# CLI flag: -blocks-storage.bucket-store.chunks-cache.attributes-ttl[attributes_ttl:\u0026lt;duration\u0026gt;|default=24h]# TTL for caching individual chunks subranges.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-ttl[subrange_ttl:\u0026lt;duration\u0026gt;|default=24h]metadata_cache:# Backend for metadata cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.metadata-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV query,# dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup made after# that).# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations. If# set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should run.# If more keys are specified, internally keys are splitted into multiple# batches and fetched concurrently, honoring the max concurrency. If set# to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# How long to cache list of tenants in the bucket.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenants-list-ttl[tenants_list_ttl:\u0026lt;duration\u0026gt;|default=15m]# How long to cache list of blocks for each tenant.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenant-blocks-list-ttl[tenant_blocks_list_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache list of chunks for a block.# CLI flag: -blocks-storage.bucket-store.metadata-cache.chunks-list-ttl[chunks_list_ttl:\u0026lt;duration\u0026gt;|default=24h]# How long to cache information that block metafile exists.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-exists-ttl[metafile_exists_ttl:\u0026lt;duration\u0026gt;|default=2h]# How long to cache information that block metafile doesn\u0026#39;t exist.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-doesnt-exist-ttl[metafile_doesnt_exist_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache content of the metafile.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-content-ttl[metafile_content_ttl:\u0026lt;duration\u0026gt;|default=24h]# Maximum size of metafile content to cache in bytes.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-max-size-bytes[metafile_max_size_bytes:\u0026lt;int\u0026gt;|default=1048576]# Duration after which the blocks marked for deletion will be filtered out# while fetching blocks. The idea of ignore-deletion-marks-delay is to ignore# blocks that are marked for deletion with some delay. This ensures store can# still serve blocks that are meant to be deleted but do not have a# replacement yet. Default is 6h, half of the default value for# -compactor.deletion-delay.# CLI flag: -blocks-storage.bucket-store.ignore-deletion-marks-delay[ignore_deletion_mark_delay:\u0026lt;duration\u0026gt;|default=6h]tsdb:# Local directory to store TSDBs in the ingesters.# CLI flag: -blocks-storage.tsdb.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb\u0026#34;]# TSDB blocks range period.# CLI flag: -blocks-storage.tsdb.block-ranges-period[block_ranges_period:\u0026lt;listofduration\u0026gt;|default=2h0m0s]# TSDB blocks retention in the ingester before a block is removed. This should# be larger than the block_ranges_period and large enough to give# store-gateways and queriers enough time to discover newly uploaded blocks.# CLI flag: -blocks-storage.tsdb.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=6h]# How frequently the TSDB blocks are scanned and new ones are shipped to the# storage. 0 means shipping is disabled.# CLI flag: -blocks-storage.tsdb.ship-interval[ship_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently shipping blocks to the storage.# CLI flag: -blocks-storage.tsdb.ship-concurrency[ship_concurrency:\u0026lt;int\u0026gt;|default=10]# How frequently does Cortex try to compact TSDB head. Block is only created# if data covers smallest block range. Must be greater than 0 and max 5# minutes.# CLI flag: -blocks-storage.tsdb.head-compaction-interval[head_compaction_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently compacting TSDB head into a new block# CLI flag: -blocks-storage.tsdb.head-compaction-concurrency[head_compaction_concurrency:\u0026lt;int\u0026gt;|default=5]# If TSDB head is idle for this duration, it is compacted. 0 means disabled.# CLI flag: -blocks-storage.tsdb.head-compaction-idle-timeout[head_compaction_idle_timeout:\u0026lt;duration\u0026gt;|default=1h]# The number of shards of series to use in TSDB (must be a power of 2).# Reducing this will decrease memory footprint, but can negatively impact# performance.# CLI flag: -blocks-storage.tsdb.stripe-size[stripe_size:\u0026lt;int\u0026gt;|default=16384]# True to enable TSDB WAL compression.# CLI flag: -blocks-storage.tsdb.wal-compression-enabled[wal_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]# True to flush blocks to storage on shutdown. If false, incomplete blocks# will be reused after restart.# CLI flag: -blocks-storage.tsdb.flush-blocks-on-shutdown[flush_blocks_on_shutdown:\u0026lt;boolean\u0026gt;|default=false]# limit the number of concurrently opening TSDB\u0026#39;s on startup# CLI flag: -blocks-storage.tsdb.max-tsdb-opening-concurrency-on-startup[max_tsdb_opening_concurrency_on_startup:\u0026lt;int\u0026gt;|default=10]compactor_config The compactor_config configures the compactor for the blocks storage.\n# List of compaction time ranges.# CLI flag: -compactor.block-ranges[block_ranges:\u0026lt;listofduration\u0026gt;|default=2h0m0s,12h0m0s,24h0m0s]# Number of Go routines to use when syncing block index and chunks files from# the long term storage.# CLI flag: -compactor.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from the long term# storage.# CLI flag: -compactor.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of fresh (non-compacted) blocks before they are being processed.# Malformed blocks older than the maximum of consistency-delay and 48h0m0s will# be removed.# CLI flag: -compactor.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]# Data directory in which to cache blocks and process compactions# CLI flag: -compactor.data-dir[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./data\u0026#34;]# The frequency at which the compaction runs# CLI flag: -compactor.compaction-interval[compaction_interval:\u0026lt;duration\u0026gt;|default=1h]# How many times to retry a failed compaction during a single compaction# interval# CLI flag: -compactor.compaction-retries[compaction_retries:\u0026lt;int\u0026gt;|default=3]# Max number of concurrent compactions running.# CLI flag: -compactor.compaction-concurrency[compaction_concurrency:\u0026lt;int\u0026gt;|default=1]# Time before a block marked for deletion is deleted from bucket. If not 0,# blocks will be marked for deletion and compactor component will delete blocks# marked for deletion from the bucket. If delete-delay is 0, blocks will be# deleted straight away. Note that deleting blocks immediately can cause query# failures, if store gateway still has the block loaded, or compactor is# ignoring the deletion because it\u0026#39;s compacting the block at the same time.# CLI flag: -compactor.deletion-delay[deletion_delay:\u0026lt;duration\u0026gt;|default=12h]# Shard tenants across multiple compactor instances. Sharding is required if you# run multiple compactor instances, in order to coordinate compactions and avoid# race conditions leading to the same tenant blocks simultaneously compacted by# different instances.# CLI flag: -compactor.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]sharding_ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -compactor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -compactor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: compactor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: compactor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -compactor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -compactor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -compactor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which compactors are considered unhealthy within# the ring.# CLI flag: -compactor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -compactor.ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]store_gateway_config The store_gateway_config configures the store-gateway service used by the blocks storage.\n# Shard blocks across multiple store gateway instances. This option needs be set# both on the store-gateway and querier when running in microservices mode.# CLI flag: -store-gateway.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]# The hash ring configuration. This option is required only if blocks sharding# is enabled.sharding_ring:# The key-value store used to share the hash ring across multiple instances.# This option needs be set both on the store-gateway and querier when running# in microservices mode.kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -store-gateway.sharding-ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -store-gateway.sharding-ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: store-gateway.sharding-ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: store-gateway.sharding-ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -store-gateway.sharding-ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -store-gateway.sharding-ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -store-gateway.sharding-ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -store-gateway.sharding-ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -store-gateway.sharding-ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=15s]# The heartbeat timeout after which store gateways are considered unhealthy# within the ring. This option needs be set both on the store-gateway and# querier when running in microservices mode.# CLI flag: -store-gateway.sharding-ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The replication factor to use when sharding blocks. This option needs be set# both on the store-gateway and querier when running in microservices mode.# CLI flag: -store-gateway.sharding-ring.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -store-gateway.sharding-ring.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# True to enable zone-awareness and replicate blocks across different# availability zones.# CLI flag: -store-gateway.sharding-ring.zone-awareness-enabled[zone_awareness_enabled:\u0026lt;boolean\u0026gt;|default=false]# Name of network interface to read address from.# CLI flag: -store-gateway.sharding-ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]# The availability zone where this instance is running. Required if# zone-awareness is enabled.# CLI flag: -store-gateway.sharding-ring.instance-availability-zone[instance_availability_zone:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The sharding strategy to use. Supported values are: default, shuffle-sharding.# CLI flag: -store-gateway.sharding-strategy[sharding_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;default\u0026#34;]purger_config The purger_config configures the purger which takes care of delete requests\n# Enable purger to allow deletion of series. Be aware that Delete series feature# is still experimental# CLI flag: -purger.enable[enable:\u0026lt;boolean\u0026gt;|default=false]# Number of workers executing delete plans in parallel# CLI flag: -purger.num-workers[num_workers:\u0026lt;int\u0026gt;|default=2]# Name of the object store to use for storing delete plans# CLI flag: -purger.object-store-type[object_store_type:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Allow cancellation of delete request until duration after they are created.# Data would be deleted only after delete requests have been older than this# duration. Ideally this should be set to at least 24h.# CLI flag: -purger.delete-request-cancel-period[delete_request_cancel_period:\u0026lt;duration\u0026gt;|default=24h]","excerpt":"Cortex can be configured using a YAML file - specified using the -config.file flag - or CLI flags. …","ref":"/docs/configuration/configuration-file/","title":"Configuration file"},{"body":" \nCortex provides horizontally scalable, highly available, multi-tenant, long term storage for Prometheus.\n Horizontally scalable: Cortex can run across multiple machines in a cluster, exceeding the throughput and storage of a single machine. This enables you to send the metrics from multiple Prometheus servers to a single Cortex cluster and run \u0026ldquo;globally aggregated\u0026rdquo; queries across all data in a single place. Highly available: When run in a cluster, Cortex can replicate data between machines. This allows you to survive machine failure without gaps in your graphs. Multi-tenant: Cortex can isolate data and queries from multiple different independent Prometheus sources in a single cluster, allowing untrusted parties to share the same cluster. Long term storage: Cortex supports Amazon DynamoDB, Google Bigtable, Cassandra, S3 and GCS for long term storage of metric data. This allows you to durably store data for longer than the lifetime of any single machine, and use this data for long term capacity planning. Cortex is a CNCF incubation project used in several production systems including Weave Cloud and Grafana Cloud. Cortex is primarily used as a remote write destination for Prometheus, exposing a Prometheus-compatible query API.\nDocumentation Read the getting started guide if you\u0026rsquo;re new to the project. Before deploying Cortex with a permanent storage backend you should read:\n An overview of Cortex\u0026rsquo;s architecture A guide to running Cortex Information regarding configuring Cortex For a guide to contributing to Cortex, see the contributor guidelines.\nFurther reading To learn more about Cortex, consult the following documents \u0026amp; talks:\n May 2019 KubeCon talks; \u0026ldquo;Cortex: Intro\u0026rdquo; (video, slides, blog post) and \u0026ldquo;Cortex: Deep Dive\u0026rdquo; (video, slides) Feb 2019 blog post \u0026amp; podcast; \u0026ldquo;Prometheus Scalability with Bryan Boreham\u0026rdquo; (podcast) Feb 2019 blog post; \u0026ldquo;How Aspen Mesh Runs Cortex in Production\u0026rdquo; Dec 2018 KubeCon talk; \u0026ldquo;Cortex: Infinitely Scalable Prometheus\u0026rdquo; (video, slides) Dec 2018 CNCF blog post; \u0026ldquo;Cortex: a multi-tenant, horizontally scalable Prometheus-as-a-Service\u0026rdquo; Nov 2018 CloudNative London meetup talk; \u0026ldquo;Cortex: Horizontally Scalable, Highly Available Prometheus\u0026rdquo; (slides) Nov 2018 CNCF TOC Presentation; \u0026ldquo;Horizontally Scalable, Multi-tenant Prometheus\u0026rdquo; (slides) Sept 2018 blog post; \u0026ldquo;What is Cortex?\u0026rdquo; Aug 2018 PromCon panel; \u0026ldquo;Prometheus Long-Term Storage Approaches\u0026rdquo; (video) Jul 2018 design doc; \u0026ldquo;Cortex Query Optimisations\u0026rdquo; Aug 2017 PromCon talk; \u0026ldquo;Cortex: Prometheus as a Service, One Year On\u0026rdquo; (videos, slides, write up part 1, part 2, part 3) Jun 2017 Prometheus London meetup talk; \u0026ldquo;Cortex: open-source, horizontally-scalable, distributed Prometheus\u0026rdquo; (video) Dec 2016 KubeCon talk; \u0026ldquo;Weave Cortex: Multi-tenant, horizontally scalable Prometheus as a Service\u0026rdquo; (video, slides) Aug 2016 PromCon talk; \u0026ldquo;Project Frankenstein: Multitenant, Scale-Out Prometheus\u0026rdquo;: (video, slides) Jun 2016 design document; \u0026ldquo;Project Frankenstein: A Multi Tenant, Scale Out Prometheus\u0026rdquo; Getting Help If you have any questions about Cortex:\n Ask a question on the Cortex Slack channel. To invite yourself to the CNCF Slack, visit http://slack.cncf.io/. File an issue. Send an email to cortex-users@lists.cncf.io Your feedback is always welcome.\nHosted Cortex (Prometheus as a service) There are several commercial services where you can use Cortex on-demand:\nWeave Cloud Weave Cloud from Weaveworks lets you deploy, manage, and monitor container-based applications. Sign up at https://cloud.weave.works and follow the instructions there. Additional help can also be found in the Weave Cloud documentation.\nInstrumenting Your App: Best Practices\nGrafana Cloud To use Cortex as part of Grafana Cloud, sign up for Grafana Cloud by clicking \u0026ldquo;Log In\u0026rdquo; in the top right and then \u0026ldquo;Sign Up Now\u0026rdquo;. Cortex is included as part of the Starter and Basic Hosted Grafana plans.\n","excerpt":"Cortex provides horizontally scalable, highly available, multi-tenant, long term storage for …","ref":"/docs/","title":"Documentation"},{"body":" Author: Jay Batra Date: March 2020 Status: proposal Problem In Cortex, currently, we are missing versioning of documentation. The idea is to have version documentation just like Prometheus.Prometheus. Documentation is the main source of information for current contributors and first-timers. A properly versioned documentation will help everyone to have a proper place to look for answers before flagging it in the community.\nIn this proposal, we want to solve this. In particular, we want to:\n Version specific pages of the documentation Include links to change version (the version must be in the URL) Include the master version and last 3 minor releases. Documentation defaults to the last minor release. Proposed solution Currently, the documentation is residing under the docs/ folder of cortexproject/cortex. It is built by Hugo using the theme docsy. It will have a proper drop-down menu which will enable proper versioning. It has a section params.version in config.toml which will allow us to map URLs with proper versions. We will have to change all the occurrences of older doc links with new links. We will keep master version with 3 latest release versions. Each release is a minor version expressed as 1.x. The document would default to latest minor version.\nFrom the current doc, the following paths (and all their subpages) should be versioned for now:\n https://cortexmetrics.io/docs/apis/ https://cortexmetrics.io/docs/configuration/ (moving v1.x Guarantees outside of the tree, because these shouldn\u0026rsquo;t be versioned) The above should be versioned under a single URL path (/docs/running-cortex/ in the following example, but final prefix is still to be decided).\nExample: For master version we would be able to use the above links via the following path\n/docs/running-cortex/master/configuration/ /docs/running-cortex/master/api/ And for a minor version like 1.x:\n/docs/running-cortex/1.0/configuration/ /docs/running-cortex/1.0/apis/ we\u0026rsquo;ll have versioned documentation only under the /docs/running-cortex/ prefix and, as a starting point, all versioned pages should go there.\n","excerpt":"Author: Jay Batra Date: March 2020 Status: proposal Problem In Cortex, currently, we are missing …","ref":"/docs/proposals/documentation-versioning/","title":"Documentation Versioning"},{"body":" Author: @annanay25 Reviewers: @jtlisi, @pstibrany, @cyriltovena, @pracucci Date: April 2020 Status: Accepted Overview Cortex uses modules to start and operate services with dependencies. Inter-service dependencies are specified in a map and passed to a module manager which ensures that they are initialised in the right order of dependencies. While this works really well, the implementation is tied in specifically to the Cortex struct and is not flexible for use with other projects like Loki, which also require similar forms of dependency management.\nWe would like to extend modules in cortex to a generic dependency management framework, that can be used by any project with no ties to cortex.\nSpecific goals Framework should allow for reusing cortex modules and allow us to: Add new modules Overwrite the implementation of a current module Manage dependencies Framework should allow for building an application from scratch using the modules package, with no dependencies on Cortex. For ex: Remove code from Loki that was copied from pkg/cortex/cortex.go. Proposed Design Modules package To make the modules package extensible, we need to abstract away any Cortex specific details from the module manager. The proposed design is to:\n Make a new component Manager, which is envisioned to be a central manager for all modules of the application. It stores modules \u0026amp; dependencies, and will be housed under a new package pkg/util/modules. Manager has the following methods for interaction: func (m *Manager) RegisterModule(name string, initFn func() (Service, error)) func (m *Manager) AddDependency(name string, dependsOn... string) error func (m *Manager) InitModuleServices(target string) (map[string]services.Service, error) Modules can be created by the application and registered with modules.Manager using RegisterModule. The parameters are:\n name: Name of the module initFn: A function that will be used to start the module. If it returns nil, and other modules depend on it, InitModuleServices will return an error. Dependencies between modules can be added using AddDependency. The parameters to the function are:\n name: Name of the module dependsOn: A variadic list of modules that the module depends on. These need to be added before the call to InitModuleServices.\n The application can be initialized by running initFn's of all the modules in the right order of dependencies by invoking InitModuleServices with the target module name.\n Changes to pkg/cortex: WrappedService present in the current module design will be deprecated. All initFn's will be wrapped into WrappedService by default.\n While the process of loading modules into modules.Manager should be remain as part of the Cortex.New() function, InitModuleServices should be part of Cortex.Run() and to enable this, modules.Manager would be made a member of the Cortex struct.\n Usage Following these changes, the Modules package will be a generic dependency management framework that can be used by any project.\nTo use the modules framework: Import the pkg/util/modules package, and initialize a new instance of the Manager using modules.NewManager() Create components in the system that implement the services interface (present in pkg/util/services). Register each of these components as a module using Manager.RegisterModule() by passing name of the module and initFn for the module. To add dependencies between modules, use Manager.AddDependency() Once all modules are added into modules.Manager, initialize the application by calling Manager.InitModuleServices() which initializes modules in the right order of dependencies. Future work Extend the module manager to allow specifying multiple targets as opposed to a single target name supported currently. Factor out Run() method to make it independent of Cortex. This will help reduce replicated code in the Loki project as well as help manage modules.Manager outside of the Cortex struct. ","excerpt":"Author: @annanay25 Reviewers: @jtlisi, @pstibrany, @cyriltovena, @pracucci Date: April 2020 Status: …","ref":"/docs/proposals/generalize-modules/","title":"Generalize Modules Service to make it extensible"},{"body":"","excerpt":"","ref":"/docs/getting-started/","title":"Getting Started"},{"body":"Gojek launched in 2010 as a call center for booking motorcycle taxi rides in Indonesia. Today, the startup is a decacorn serving millions of users across Southeast Asia with its mobile wallet, GoPay, and 20+ products on its super app. Want to order dinner? Book a massage? Buy movie tickets? You can do all of that with the Gojek app.\nThe company’s mission is to solve everyday challenges with technology innovation. To achieve that across multiple markets the systems team at Gojek focused on building an infrastructure for speed, reliability, and scale. By 2019, the team realized it needed a new monitoring system that could keep up with Gojek’s ever-growing technology organization, which led them to Cortex, the horizontally scalable Prometheus implementation.\n“We were using InfluxDB for metrics storage. Developers configured alerts by committing kapacitor scripts in git repos. To achieve high availability, we had a relay setup with two InfluxDBs. Since we could not horizontally scale Influx unless we paid for an enterprise license, we ended up having many InfluxDB clusters with relay setup,” says Product Engineer Ankit Goel.\nThough the team had introduced automation for setup, managing all those Influx instances became a pain point for operations. Additionally, some of the Gojek engineering teams needed far greater scale. “Some of our teams generate more than a million active time series,” says Goel. Another common requirement from customers was long-term storage of metrics. With InfluxDB, Gojek only had 2 weeks’ retention, and increasing it would mean provisioning bigger instances.\nGojek was in search of a better monitoring solution that would meet the following requirements:\n Kubernetes native. Horizontally scalable. Highly available out of the box. High reliability. Low operations overhead so a small team can manage it. Cortex met all of these requirements, and also had the following features that the Gojek team could leverage:\n Multi-tenancy. Customizable and modifiable, so it could be integrated with Gojek’s existing tooling. Support for remote_write. Because it supports remote_write, Cortex enabled one of Gojek’s key needs: the ability to offer monitoring as a service. “With Thanos, we would have had to deploy a Thanos sidecar on every Prometheus that would have been deployed,” says Goel. “So essentially, there would be a substantial part of infrastructure on the client side that we would need to manage. We preferred Cortex because people could simply push their metrics to us, and we would have all the metrics in a single place.”\nThe implementation started in January 2019. The team developed a few tools: a simple service for token-based authentication, and another for storing team information, such as notification channels and PagerDuty policies. Once all this was done, they leveraged InfluxData Telegraf’s remote_write plugin to write to Cortex. This allowed them to have all the metrics being sent to InfluxDB to be sent to Cortex as well. “So moving from InfluxDB to tenants would not be that complicated. Because Cortex was multi-tenant, we could directly map each of our InfluxDB servers to our tenants,” says Goel. They’ve developed an internal helm chart to deploy and manage Cortex. After the customizations were completed in about two months, “we had our setup up and running, and we onboarded one team on Cortex,” he says.\nIn the initial version, GitOps was the only interface for developers to apply alerts and create dashboards. The team built tools like grafonnet-playground to make it easy for developers to create dashboards. Developers are also allowed to create dashboards using the UI, since Grafana maintains version history for dashboards.\n“We needed metrics like ‘the number of alerts triggered for each team,’ ‘how long did it take to resolve these alerts,’ ‘how many were actionable and how many were ignored,’ etc.,” says Goel. “For measuring these metrics, the team only had to create a simple dashboard, since the ruler component exposes the per-tenant alert metrics. Both business and developers have found these metrics to be very useful.”\nThe team built a CLI tool to improve user experience for applying alerts without having to dig into PromQL. “You can write a command and say lens attach alert, and you tell it what kind of alert you want to attach, such as a CPU alert or Postgres alerts, and then you give it a service name,” says Goel. “There are some challenges to this approach for applying alerts, but we would like to move to such a model in the future.”\nOne of the challenges the team faces is developer education. But “we always knew if we are going to move to either Thanos or Cortex, developers would have to learn PromQL,” Goel says. The monitoring team paired with developers to help them understand PromQL and migrate their graphs and alerts.\nThe monitoring team has faced issues with Cortex from time to time, but “we always reached out to the Cortex community with our issues through the Cortex slack channel,” says Goel, and “active members of the Cortex community have always helped us with our problems.”\nToday, Gojek’s Lens monitoring system has 40+ tenants, for which Cortex handles about 1.2 million samples per second. Adoption is growing organically by word of mouth. Gojek is currently migrating to Kubernetes, and the teams that moved to Kubernetes have found Prometheus to be a better fit than InfluxDB. Seeing that success, other teams on Kubernetes have onboarded themselves to Lens.\nUltimately, Goel says, “where Cortex has really helped us is to integrate the monitoring system with our existing tools. We have a lot of internal tooling, and in certain places, we needed really tight integrations with the monitoring system. So the goal is to make sure that whenever a new service or team is created, they automatically get onboarded to the monitoring platform. After developers deploy, some of their system metrics and all the other standard metrics that are available for a service are automatically sent to the platform.” The team plans to spend the next six months bringing everyone over to Lens.\nLooking ahead, Goel and his team have the long-term vision of growing from a monitoring team to a full-fledged observability team. “We also want to take care of logging and tracing in Gojek,” he says. “Loki would be easy to fit with Cortex, so in the future we want to explore Loki for logging.”\n","excerpt":"Gojek launched in 2010 as a call center for booking motorcycle taxi rides in Indonesia. Today, the …","ref":"/docs/case-studies/gojek/","title":"How Gojek Is Leveraging Cortex to Keep Up with Its Ever-Growing Scale"},{"body":" Author: @jtlisi Reviewers: @pracucci, @pstibrany, @khaines, @gouthamve Date: March 2020 Status: Accepted Overview The purpose of this design document is to propose a set of standards that should be the basis of the Cortex HTTP API. This document will outline the current state of the Cortex http api and describe limitations that result from the current approach. It will also outline a set of paradigms on how http routes should be created within Cortex.\nCurrent Design As things currently stand, the majority of HTTP API calls exist under the /api/prom path prefix. This prefix is configurable. However, since this prefix is shared between all the modules which leads to conflicts if the Alertmanager is attempted to be run as as part of the single binary (#1722).\nProposed Design Module-Based Routing Cortex incorporates three separate APIs: Alertmanager, Prometheus, and Cortex. Each of these APIs should use a separate route prefix that accurately describes the API. Currently, all of the api calls in Cortex reside under the configured http prefix. Instead the following routing tree is proposed:\n/prometheus/* Under this path prefix, Cortex will act as a Prometheus web server. It will host all of the required Prometheus api endpoints. For example to query cortex the endpoint /prometheus/api/v1/query_range will be used.\n/alertmanager/* Under this path prefix, Cortex will act as a Alertmanager web server. In this case, it will forward requests to the alertmanager and support the alertmanager API. This means for a user to access their Alertmanager UI, they will use the /alertmanager path of cortex.\n/api/v1/* \u0026ndash; The cortex API will exist under this path prefix. /push /chunks /rules/* Current Proposed /api/prom/push /api/v1/push /api/prom/chunks /api/v1/chunks /api/prom/rules/* /api/v1/rules/* Service Endpoints A number of endpoints currently exist that are not under the /api/prom prefix that provide basic web interfaces and trigger operations for cortex services. These endpoints will all be placed under a url with their service name as a prefix if it is applicable.\n Current Proposed /status /multitenant-alertmanager/status /config /config /ring /ingester/ring /ruler_ring /ruler/ring /compactor/ring /compactor/ring /store-gateway/ring /store-gateway/ring /ha-tracker /distributor/ha_tracker /all_user_stats /distributor/all_user_stats /user_stats /distributor/user_stats /flush /ingester/flush /shutdown /ingester/shutdown Path Versioning Cortex will utilize path based versioning similar to both Prometheus and Alertmanager. This will allow future versions of the API to be released with changes over time.\nBackwards-Compatibility The new API endpoints and the current http prefix endpoints can be maintained concurrently. The flag to configure these endpoints will be maintained as http.prefix. This will allow us to roll out the new API without disrupting the current routing schema. The original http prefix endpoints can maintained indefinitely or be phased out over time. Deprecation warnings can be added to the current API either when initialized or utilized. This can be accomplished by injecting a middleware that logs a warning whenever a legacy API endpoint is used.\nIn cases where Cortex is run as a single binary, the Alertmanager module will only be accesible using the new API.\nImplementation This will be implemented by adding an API module to the Cortex service. This module will handle setting up all the required HTTP routes with Cortex. It will be designed around a set of interfaces required to fulfill the API. This is similar to how the v1 Prometheus API is implemented.\nStyle All new paths will utilize _ instead of - for their url to conform with Prometheus and its use of the underscore in the query_range endpoint. This applies to all operations endpoints. Component names in the path can still contain dashes. For example: /store-gateway/ring. ","excerpt":"Author: @jtlisi Reviewers: @pracucci, @pstibrany, @khaines, @gouthamve Date: March 2020 Status: …","ref":"/docs/proposals/http-api-design/","title":"HTTP API Design"},{"body":" Author: @pstibrany Reviewers: Date: June 2020 Status: Replaced with migration guide. Warning Suggestions from this proposal were implemented, but general procedure outlined here doesn\u0026rsquo;t quite work in Kubernetes environment. Please see chunks to blocks migration guide instead.\nIntroduction This short document describes the first step in full migration of the Cortex cluster from using chunks storage to using blocks storage, specifically switching ingesters to using blocks, and modification of queriers to query both chunks and blocks storage.\nIngesters When switching ingesters from chunks to blocks, we need to consider the following:\n Ingesting of new data, and querying should work during the switch. Ingesters are rolled out with new configuration over time. There is overlap: ingesters of both kinds (chunks, blocks) are running at the same time. Ingesters using WAL don’t flush in-memory chunks to storage on shutdown. Rollout should be as automated as possible. How do we handle ingesters with WAL (non-WAL ingesters are discussed below)? There are several possibilities, but the simplest option seems to be adding a new flag to ingesters to flush chunks on shutdown. This is trivial change to ingester, and allows us to do automated migration by:\n Enabling this flag on each ingester (first rollout). Turn off chunks, enable TSDB (second rollout). During the second rollout, as the ingester shuts down, it will flush all chunks in memory, and when it restarts, it will start using TSDB. Benefit of this approach is that it is trivial to add the flag, and then rollout in both steps can be fully automated. In this scenario, we will reconfigure existing statefulset of ingesters to use blocks in step 2.\nNotice that querier can ask only ingesters for most recent data and not consult the store, but during the rollout (and some time after), ingesters that are already using blocks will not have the most recent chunks in memory. To make sure queries work correctly, -querier.query-store-after needs to be set to 0, in order for queriers to not rely on ingesters only for most recent data. After couple of hours after rollout, this value can be increased again, depending on how much data ingesters keep. (-experimental.blocks-storage.tsdb.retention-period for blocks, -ingester.retain-period for chunks) During the rollout, chunks and blocks ingesters share the ring and use the same statefulset.\nOther alternatives considered for flushing chunks / handling WAL:\n Replay chunks-WAL into TSDB head on restart. In this scenario, chunks-ingester shuts down, and block ingester starts. It can detect existing chunks WAL, and replay it into TSDB head (and then delete old WAL). Issue here is that current chunks-WAL is quite specific to ingester code, and would require some refactoring to make this happen. Deployment is trivial: just reconfigure ingesters to start using blocks, and replay chunks WAL if found. Required change seems like a couple of days of coding work, but it is essentially only used once (for each cluster). Doesn\u0026rsquo;t seem like good time investment. Shutdown single chunks-ingester, run flusher in its place, and when done start new blocks ingester. This is similar to the procedure we did during the introduction of WAL. Flusher can be run via initContainer support in pods. This still requires two-step deployment: 1) enable flusher and reconfigure ingesters to use blocks, 2) remove flusher. When not using WAL, ingesters using chunks cannot transfer those chunks to new ingesters that start with blocks support, so old ingesters need to be configured to disable transfers (using -ingester.max-transfer-retries=0), and to flush chunks on shutdown instead. As ingesters without WAL are typically deployed using Kubernetes deployment, while blocks ingesters need to use statefulset, and there is no chunks transfer happening, it is possible to configure and start blocks-ingesters and then stop old deployment.\nAfter all ingesters are converted to blocks, we can set cut-off time for querying chunks storage on queriers.\nFor rollback from blocks to chunks, we need to be able to flush data from ingesters to the blocks storage, and then switch ingesters back to chunks. Ingesters are currently not able to flush blocks to storage, but adding flush-on-shutdown option, support for /shutdown endpoint and support in flusher component similar to chunks is doable, and should be part of this work.\nWith this ability, rollback would follow the same process, just in reverse: 1) redeploy with flush flag enabled, 2a) redeploy with config change from blocks to chunks (when using WAL) or 2b) scale down statefulset with blocks-ingesters, and start deployment with chunk-ingesters again. Note that this isn\u0026rsquo;t a full rollback to chunks-only solution, as generated blocks still need to be queried after the rollback, otherwise samples pushed to blocks would be missing. This means running store-gateways and queriers that can query both chunks and blocks store.\nAlternative plan could be to use a separate Cortex cluster configured to use blocks, and redirect incoming traffic to both chunks and blocks cluster. When one is confident about the blocks cluster running correctly, old chunks cluster can be shutdown. In this plan, there is an overlap where both clusters are ingesting same data. Blocks cluster needs to be configured to be able to query chunks storage as well, with cut-off time based on when clusters were configured (at latest, to minimize amount of duplicated samples that need to be processed during queries.)\nQuerying To be able to query both old and new data, querier needs to be modified to be able to query both blocks (on object store only) and chunks store (NoSQL + object store) at the same time, and merge results from both.\nFor querying chunks storage, we have two options:\n Always query the chunks store – useful during ingesters switch, or after rollback from blocks to chunks. Query chunk store only for queries that ask for data after specific cut-off time. This is useful after all ingesters have switched, and we know the timestamp since ingesters are only writing blocks. Querier needs to support both modes of querying chunks store. Which one of these two modes is used depends on single timestamp flag passed to the querier. If timestamp is configured, chunks store is only used for queries that ask for data older than timestamp. If timestamp is not configured, chunks store is always queried.\nFor blocks, we don\u0026rsquo;t need to use the timestamp flag. Queriers can always query blocks – each querier knows about existing blocks and their timeranges, so it can quickly determine whether there are any blocks with relevant data. Always querying blocks is also useful when there is some background process converting chunks to blocks. As new blocks with old data appear on the store as a result of conversion, they get queried if necessary.\nWhile we could use runtime-config for on-the-fly switch without restarts, queriers restart quickly and so switching via configuration or command line option seems enough.\nWork to do Ingester: Add flags for always flushing on shutdown, even when using WAL or blocks. Querier: Add support for querying both chunk store and blocks at the same time and test the support for querying both chunks and blocks from ingesters works correctly Querier: Add cut-off time support to querier to query chunk the store only if needed, based on query time. ","excerpt":"Author: @pstibrany Reviewers: Date: June 2020 Status: Replaced with migration guide. Warning …","ref":"/docs/proposals/ingesters-migration/","title":"Migrating ingesters from chunks to blocks and back."},{"body":"This document builds on the getting started guide and specifies the steps needed to get Cortex into production. Ensure you have completed all the steps in the getting started guide and read about the Cortex architecture before you start this one.\n1. Pick a storage backend The getting started guide uses local chunk storage. Local chunk storage is experimental and shouldn’t be used in production.\nCortex requires a scalable storage back-end for production systems. It is recommended you use chunk storage with one of the following back-ends:\n DynamoDB/S3 (see Cortex on AWS) BigTable/GCS Cassandra (see Cortex on Cassandra) Commercial cloud options are DynamoDB/S3 and Bigtable/GCS: the advantage is you don\u0026rsquo;t have to know how to manage them, but the downside is they have specific costs.\nAlternatively you can choose Apache Cassandra, which you will have to install and manage. Cassandra support can also be used with commecial Cassandra-compatible services such as Azure Cosmos DB.\nCortex has an alternative to chunk storage: block storage. Block storage is not ready for production usage at this time.\n2. Deploy Query Frontend The Query Frontend is the Cortex component which parallelizes the execution of and caches the results of queries. The Query Frontend is also responsible for retries and multi-tenant QoS.\nFor the multi-tenant QoS algorithms to work, you should not run more than two Query Frontends. The Query Frontend should be deployed behind a load balancer, and should only be sent queries \u0026ndash; writes should go straight to the Distributor component, or to the single-process Cortex.\nThe Querier component (or single-process Cortex) “pulls” queries from the queues in the Query Frontend. Queriers discover the Query Frontend via DNS. The Queriers should not use the load balancer to access the Query Frontend. In Kubernetes, you should use a separate headless service.\nTo configure the Queries to use the Query Frontend, set the following flag:\n-querier.frontend-address string Address of query frontend service. There are other flag you can use to control the behaviour of the frontend - concurrency, retries, etc. See Query Frontend configuration for more information.\nThe Query Frontend can run using an in-process cache, but should be configured with an external Memcached for production workloads. The next section has more details.\n3. Setup Caching Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many opportunities for using caching to accelerate queries and reduce cost.\nFor more information, see the Caching in Cortex documentation.\n4. Monitoring and Alerting Cortex exports metrics in the Prometheus format. We recommend you install and configure Prometheus server to monitor your Cortex cluster.\nWe publish a set of Prometheus alerts and Grafana dashboards as the cortex-mixin. We recommend you use these for any production Cortex cluster.\n5. Authentication \u0026amp; Multitenancy If you want to run Cortex as a multi-tenant system, you need to give each tenant a unique ID - this can be any string. Managing tenants and allocating IDs must be done outside of Cortex. See Authentication and Authorisation for more information.\n6. Handling HA Prometheus Pairs You should use a pair of Prometheus servers to monitor your targets and send metrics to Cortex. This allows your monitoring system to survive the failure of one of these Prometheus instances. Cortex support deduping the samples on ingestion. For more information on how to configure Cortex and Prometheus to HA pairs, see Config for sending HA Pairs data to Cortex.\n","excerpt":"This document builds on the getting started guide and specifies the steps needed to get Cortex into …","ref":"/docs/production/running-in-production/","title":"Running Cortex in Production"},{"body":" Author: Joe Elliott Date: April 2020 Status: Proposed Overview This document aims to describe the role that the Cortex Query Frontend plays in running multitenant Cortex at scale. It also describes the challenges of horizontally scaling the query frontend component and includes several recommendations and options for creating a reliably scalable query-frontend. Finally, we conclude with a discussion of the overall philosophy of the changes and propose an alternative.\nFor the original design behind the query frontend, you should read Cortex Query Optimisations design doc from 2018-07.\nReasoning Query frontend scaling is becoming increasingly important for two primary reasons.\nThe Cortex team is working toward a scalable single binary solution. Recently the query-frontend was added to the Cortex single binary mode and, therefore, needs to seamlessly scale. Technically, nothing immediately breaks when scaling the query-frontend, but there are a number of concerns detailed in Challenges And Proposals.\nAs the query-frontend continues to support additional features it will start to become a bottleneck of the system. Current wisdom is to run very few query-frontends in order to maximize Tenancy Fairness but as more features are added scaling horizontally will become necessary.\nQuery Frontend Role Load Shedding The query frontend maintains a queue per tenant of configurable length (default 100) in which it stores a series of requests from that tenant. If this queue fills up then the frontend will return 429’s thus load shedding the rest of the system.\nThis is particularly effective due to the “pull” based model in which queriers pull requests from query frontends.\nQuery Retries The query frontend is capable of retrying a query on another querier if the first should fail due to OOM or network issues.\nSharding/Parallelization The query frontend shards requests by interval and other factors to concurrently run a single query across multiple queriers.\nQuery Alignment/Caching Queries are aligned to their own step and then stored/retrieved from cache.\nTenancy Fairness By maintaining one queue per tenant, a low demand tenant will have the same opportunity to have a query serviced as a high demand tenant. See Dilutes Tenant Fairness for additional discussion.\nFor clarity, tenancy fairness only comes into play when queries are actually being queued in the query frontend. Currently this rarely occurs, but as query sharding becomes more aggressive this may become the norm.\nChallenges And Proposals Dynamic Querier Concurrency Challenge For every query frontend the querier adds a configurable number of goroutines which are each capable of executing a query. Therefore, scaling the query frontend impacts the amount of work each individual querier is attempting to do at any given time.\nScaling up may cause a querier to attempt more work than they are configured for due to restrictions such as memory and cpu limits. Additionally, the promql engine itself is limited in the number of queries it can do as configured by the -querier.max-concurrent parameter. Attempting more queries concurrently than this value causes the queries to queue up in the querier itself.\nFor similar reasons scaling down the query frontend may cause a querier to not use its allocated memory and cpu effectively. This will lower effective resource utilization. Also, because individual queriers will be doing less work, this may cause increased queueing in the query frontends.\nProposal Currently queriers are configured to have a max parallelism per query frontend. An additional “total max concurrency” flag should be added.\nTotal Max Concurrency would then be evenly divided amongst all available query frontends. This would decouple the amount of work a querier is attempting to do with the number of query frontends that happen to exist at this moment. Consequently this would allow allocated resources (e.g. k8s cpu/memory limits) to remain balanced with the work the querier was attempting as the query frontend is scaled up or down.\nA PR has already been merged to address this.\nOverwhelming PromQL Concurrency Challenge If #frontends \u0026gt; promql concurrency then the queriers are incapable of devoting even a single worker to each query frontend without risking queueing in the querier. Queuing in the querier is a highly undesirable state and one of the primary reasons the query frontend was originally created.\nProposal When #frontends \u0026gt; promql concurrency then each querier will maintain exactly one connection to every frontend. As the query frontend is currently coded it will attempt to use every open GRPC connection to execute a query in the attached queriers. Therefore, in this situation where #frontends \u0026gt; promql concurrency, the querier is exposing itself to more work then it is actually configured to perform.\nTo prevent this we will add “flow control” information to the ProcessResponse message that is used to return query results from the querier to the query frontend. In an active system this message is passed multiple times per second from the queriers to the query frontends and would be a reliable way for the frontends to track the state of queriers and balance load.\nThere are a lot of options for an exact implementation of this idea. An effective solution should be determined and chosen by modeling a set of alternatives. The details of this would be included in another design doc. A simple implementation would look something like the following:\nAdd two new fields to ProcessResponse:\nmessage ProcessResponse { httpgrpc.HTTPResponse httpResponse = 1; currentConcurrency int = 2; desiredConcurrency int = 3;}currentConcurrency - The current number of queries being executed by the querier.\ndesiredConcurrency - The total number of queries that a querier is capable of executing.\nAdd a short backoff to the main frontend processing loop. This would cause the frontend to briefly back off of any querier that was overloaded but continue to send queries to those that were capable of doing work.\nif current \u0026gt; desired { zzz := (current - desired) * backoffDuration zzz *= 1 + rand.Float64() * .1 // jitter time.Sleep(zzz) } Passing flow control information from the querier to the frontend would also open up additional future work for more sophisticated load balancing across queriers. For example by simply comparing and choosing the least congested of two queriers we could dramatically improve how well work is distributed.\nIncreased Time To Failure Challenge Scaling the query frontend also increases the per tenant queue length by creating more queues. This could result in increased latencies where failing fast (429) would have been preferred.\nThe operator could reduce the queue length per query frontend in response to scaling out, but then they would run the risk of unnecessarily failing a request due to unbalanced distribution across query frontends. Also, shorter queues run the risk of failing to properly service heavily sharded queries.\nAnother concern is that a system with more queues will take longer to recover from an production event as it will have queued up more work.\nProposal Currently we are not proposing any changes to alleviate this concern. We believe this is solvable operationally. This can be revisited as more information is gathered.\nQuerier Discovery Lag Challenge Queriers have a configurable parameter that controls how often they refresh their query frontend list. The default value is 10 seconds. After a new query frontend is added the average querier will take 5 seconds (after DNS is updated) to become aware of it and begin requesting queries from it.\nProposal It is recommended to add a readiness/health check to the query frontend to prevent it from receiving queries while it is waiting for queriers to connect. HTTP health checks are supported by envoy, k8s, nginx, and basically any commodity load balancer. The query frontend would not indicate healthy on its health check until at least one querier had connected.\nIn a k8s environment this will require two services. One service for discovery with publishNotReadyAddresses set to true and one service for load balancing which honors the healthcheck/readiness probe. After a new query-frontend instance is created the \u0026ldquo;discovery service\u0026rdquo; would immediately have the ip of the new instance which would allow queriers to discover and attach to it. After queriers had connected it would then raise its readiness probe and appear on the \u0026ldquo;load balancing\u0026rdquo; service and begin receiving traffic.\nDilutes Tenant Fairness Challenge Given f query frontends, n tenants and an average of q queries in the frontend per tenant. The following assumes that queries are perfectly distributed across query frontends. The number of tenants per instance would be:\nThe chance that a query by a tenant with Q queries in the frontend is serviced next is:\nNote that fewer query frontends caps the impact of the number of active queries per tenant. If there is only one query frontend then the equation reduces to:\nand every tenant has an equal chance of being serviced regardless of the number of queued queries.\nAdding more query frontends favors high volume tenants by giving them more slots to be picked up by the next available querier. Fewer query frontends allows for an even playing field regardless of the number of active queries.\nFor clarity, it should be noted that tenant fairness is only impacted if queries are being queued in the frontend. Under normal operations this is currently not occurring although this may change with increased sharding.\nProposal Tenancy fairness is complex and is currently not impacting our system. Therefore we are proposing a very simple improvement to the query frontend. If/when frontend queuing becomes more common this can be revisited as we will understand the problem better.\nCurrently the query frontend picks a random tenant to service when a querier requests a new query. This can increase long tail latency if a tenant gets “unlucky” and is also exacerbated for low volume tenants by scaling the query frontend. Instead the query frontend could use a round robin approach to choose the next tenant to service. Round robin is a commonly used algorithm to increase fairness in scheduling.\nThis would be a very minor improvement, but would give some guarantees to low volume tenants that their queries would be serviced. This has been proposed in this issue.\nPros: Requires local knowledge only. Easier to implement than weighted round robin.\nCons: Improvement is minor.\nAlternatives to Round Robin\nDo Nothing\nAs is noted above tenancy fairness only comes into play when queries start queueing up in the query frontend. Internal Metrics for multi-tenant Cortex at Grafana show that this has only happened 5 times in the past week significantly enough to have been caught by Prometheus.\nRight now doing nothing is a viable option that will, almost always, fairly serve our tenants. There is, however, some concern that as sharding becomes more commonplace queueing will become more common and QOS will suffer due to reasons outlined in Dilutes Tenant Fairness.\nPros: Easy!\nCons: Nothing happens!\nWeighted Round Robin\nThe query frontends could maintain a local record of throughput or work per tenant. Tenants could then be sorted in QOS bands. In its simplest form there would be two QOS bands. The band of low volume tenants would be serviced twice for every one time the band of high volume tenants would be serviced. The full details of this approach would require a separate proposal.\nThis solution would also open up interesting future work. For instance, we could allow operators to manually configure tenants into QOS bands.\nPros: Requires local knowledge only. Can be extended later to allow tenants to be manually sorted into QOS tiers.\nCons: Improvement is better than Round Robin only. Relies on even distribution of queries across frontends. Increased complexity and difficulty in reasoning about edge cases.\nWeighted Round Robin With Gossiped Traffic\nThis approach would be equivalent to Weighted Round Robin proposed above but with tenant traffic volume gossiped between query frontends.\nPros: Benefits of Weighted Round Robin without the requirement of even query distribution. Even though it requires distributed information a failure in gossip means it gracefully degrades to Weighted Round Robin.\nCons: Requires cross instance communication. Increased complexity and difficulty in reasoning about edge cases.\nAlternative The proposals in this document have preferred augmenting existing components to make decisions with local knowledge. The unstated goal of these proposals is to build a distributed queue across a scaled query frontend that reliably and fairly serves our tenants.\nOverall, these proposals will create a robust system that is resistant to network partitions and failures of individual pieces. However, it will also create a complex system that could be difficult to reason about, contain hard to ascertain edge cases and nuanced failure modes.\nThe alternative is, instead of building a distributed queue, to add a new cortex queueing service that sits in between the frontends and the queriers. This queueing service would pull from the frontends and distribute to the queriers. It would decouple the stateful queue from the stateless elements of the query frontend and allow us to easily scale the query frontend while keeping the queue itself a singleton. In a single binary HA mode one (or few) of the replicas would be leader elected to serve this role.\nHaving a singleton queue is attractive because it is simple to reason about and gives us a single place to make fair cross tenant queueing decisions. It does, however, create a single point of failure and add another network hop to the query path.\nConclusion In this document we reviewed the reasons the frontend exists, challenges and proposals to scaling the frontend and an alternative architecture that avoids most problems but comes with its own challenges.\n Challenge Proposal Status Dynamic Querier Concurrency Add Max Total Concurrency in Querier Pull Request Overwhelming PromQL Concurrency Queriers Coordinate Concurrency with Frontends Proposed Increased Time to Failure Operational/Configuration Issue. No Changes Proposed. N/A Querier Discovery Lag Query Frontend HTTP Health Checks Pull Request Dilutes Tenant Fairness Round Robin with additional alternatives proposed Pull Request ","excerpt":"Author: Joe Elliott Date: April 2020 Status: Proposed Overview This document aims to describe the …","ref":"/docs/proposals/scalable-query-frontend/","title":"Scalable Query Frontend"},{"body":" Author: @pracucci, @tomwilkie, @pstibrany Reviewers: Date: August 2020 Status: Proposed, implemented in PR #3090 Shuffle sharding and zone awareness Background Cortex shards the received series across all available ingesters. In a multi-tenant cluster, each tenant series are sharded across all ingesters. This allows to horizontally scale the series across the pool of ingesters but also suffers some issues:\n Given every tenant writes series to all ingesters, there’s no isolation between tenants - a single misbehaving tenant can affect the whole cluster. Each ingester needs an open TSDB per tenant per ingester - which has significant memory overhead. The larger the number of tenants, the higher the TSDB memory overhead, regardless of the number of series stored in each TSDB. Similarly, the number of uploaded blocks to the storage every 2 hours is a function of the number of TSDBs open for each ingester. A cluster with a large number of small tenants will upload a very large number of blocks to the storage, each block being very small, increasing the number of API calls against the storage bucket. Cortex currently supports sharding a tenant to a subset of the ingesters on the write path PR, using a feature called “subring”. However, the current subring implementation suffers two issues:\n No zone awareness: it doesn’t guarantee selected instances are balanced across availability zones No shuffling: the implementation is based on the hash ring and it selects N consecutive instances in the ring. This means that, instead of minimizing the likelihood that two tenants share the same instances, it emphasises it. In order to provide a good isolation between tenants, we want to minimize the chances that two tenants share the same instances. Goal The goal of this work is to fix “shuffling” and “zone-awareness” when building the subring for a given tenant, honoring the following properties:\n Stability: given the same ring, the algorithm always generates the same subring for a given tenant, even across different machines Consistency: when the ring is resized, only n/m series are remapped on average (where n is the number of series and m is the number of replicas). Shuffling: probabilistically and for a large enough cluster, ensure every tenant gets a different set of instances, with a reduced number of overlapping instances between two tenants to improve failure isolation. Zone-awareness (balanced): the subring built for each tenant contains a balanced number of instances for each availability zone. Selecting the same number of instances in each zone is an important property because we want to preserve the balance of in-memory series across ingesters. Having less replicas in one zone will mean more load per node in this zone, which is something we want to avoid. Proposal This proposal is based on Amazon’s Shuffle Sharding article and the algorithm has been inspired by shuffle sharding implementation in the AWS Route53 infima library.\nGiven a tenant and a shard size S (number of instances to which tenant data/workload should be sharded to), we build a subring selecting N instances from each zone, where N = ceil(S / num of zones). The shard size S is required to be a multiple of the number of zones, in order to select an equal number of instances from each zone.\nTo do it, we treat each zone as a separate ring and select N unique instances from each zone. The instances selection process works as follow:\n Generate a seed based on the tenant ID Initialise a pseudo random number generator with the tenant’s seed. The random generator must guarantee predictable numbers given the same input seed. Generate a sequence of N random numbers, where N is the number of instances to select from the zone. Each random number is used as a “token” to look up instances in the ring. For each random number: Lookup the instance holding that token in the ring If the instance has not been previously selected, then pick it If the instance was previously selected (we call this a “collision”), then continue walking the ring clockwise until we find an instance which has not been selected yet Guaranteed properties Stability The same tenant ID always generates the same seed. Given the same seed, the pseudo number random generator always generates the same sequence of numbers.\nThis guarantees that, given the same ring, we generate the same exact subring for a given tenant.\nConsistency The consistency property is honored by two aspects of the algorithm:\n The quantity of random numbers generated is always equal to the shard size S, even in case of “collisions”. A collision is when the instance holding the random token has already been picked and we need to select a different instance which has not been picked yet. In case of collisions, we select the “next” instance continuing walking the ring instead of generating another random number Example adding an instance to the ring Let’s consider an initial ring with 3 instances and 1 zone (for simplicity):\n I1 - Tokens: 1, 8, 15 I2 - Tokens: 5, 11, 19 I3 - Tokens: 7, 13, 21 With a replication factor = 2, the random sequence looks up:\n 3 (I2) 6 (I1) Then we add a new instance and the updated ring is:\n I1 - Tokens: 1, 8, 15 I2 - Tokens: 5, 11, 19 I3 - Tokens: 7, 13, 21 I4 - Tokens: 4, 7, 17 Now, let’s compare two different algorithms to solve collisions:\n Using the random generator:\nRandom sequence = 3 (I4), 6 (I4 - collision), 12 (I3)\nall instances are different (I4, I3) Walking the ring:\nRandom sequence = 3 (I4), 6 (I4 - collision, next is I1)\nonly 1 instance is different (I4, I1) Shuffling Unless when resolving collisions, the algorithm doesn’t walk the ring to find the next instances, but uses a sequence of random numbers. This guarantees instances are shuffled, between different tenants, when building the subring.\nZone-awareness We treat each zone as a separate ring and select an equal number of instances from each zone. This guarantees a fair balance of instances between zones.\nProof of concept We’ve built a reference implementation of the proposed algorithm, to test the properties described above.\nIn particular, we’ve observed that the actual distribution of matching instances between different tenants is very close to the theoretical one, as well as consistency and stability properties are both honored.\n","excerpt":"Author: @pracucci, @tomwilkie, @pstibrany Reviewers: Date: August 2020 Status: Proposed, implemented …","ref":"/docs/proposals/shuffle-sharding-and-zone-awareness/","title":"Shuffle sharding and zone awareness"},{"body":" Author: @pracucci, @tomwilkie, @pstibrany Reviewers: Date: August 2020 Status: Proposed, partially implemented Background Cortex currently supports sharding of tenants to a subset of the ingesters on the write path PR.\nThis feature is called “subring”, because it computes a subset of nodes registered to the hash ring. The aim of this feature is to improve isolation between tenants and reduce the number of tenants impacted by an outage.\nThis approach is similar to the techniques described in Amazon’s Shuffle Sharding article, but currently suffers from a non random selection of nodes (proposed solution below).\nCortex can be configured with a default subring size, and then it can be customized on a per-tenant basis. The per-tenant configuration is live reloaded during runtime and applied without restarting the Cortex process.\nThe subring sharding currently supports only the write-path. The read-path is not shuffle sharding aware. For example, an outage of more than one ingester with RF=3 will affect all tenants, or a particularly noisy tenant wrt queries has the ability to affect all tenants.\nGoals The Cortex read path should support shuffle sharding to isolate the impact of an outage in the cluster. The shard size must be dynamically configurable on a per-tenant basis during runtime.\nThis deliverable involves introducing shuffle sharding in:\n Query-frontend → Querier (for queries sharding) PR #3113 Querier → Store-gateway (for blocks sharding) PR #3069 Querier→ Ingesters (for queries on recent data) Ruler (for rule and alert evaluation) Prerequisite: fix subring shuffling The solution is implemented in https://github.com/cortexproject/cortex/pull/3090.\nThe problem The subring is a subset of nodes that should be used for a specific tenant.\nThe current subring implementation doesn’t shuffle tenants across nodes. Given a tenant ID, it finds the first node owning the hash(tenant ID) token and then it picks N distinct consecutive nodes walking the ring clockwise.\nFor example, in a cluster with 6 nodes (numbered 1-6) and a replication factor of 3, three tenants (A, B, C) could have the following shards:\n Tenant ID Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 A x x x B x x x C x x x Proposal We propose to build the subring picking N distinct and random nodes registered in the ring, using the following algorithm:\n SID = tenant ID SID = hash(SID) Look for the node owning the token range containing FNV-1a(SID) Loop to (2) until we’ve found N distinct nodes (where N is the shard size) hash() function to be decided. The required property is to be strong enough to not generate loops across multiple subsequent hashing of the previous hash.\nQuery-frontend → Queriers shuffle sharding Implemented in https://github.com/cortexproject/cortex/pull/3113.\nHow querier runs query-frontend jobs Today each querier connects to each query-frontend instance, and calls a single “Process” method via gRPC.\n“Process” is a bi-directional streaming gRPC method – using the server-to-client stream for sending requests from query-frontend to the querier, and client-to-server stream for returning results from querier to the query-frontend. NB this is the opposite of what might be considered normal. Query-frontend scans all its queues with pending query requests, and picks a query to execute based on a fair schedule between tenants.\nThe query request is then sent to an idle querier worker over the stream opened in the Process method, and the query-frontend then waits for a response from querier. This loop repeats until querier disconnects.\nProposal To support shuffle sharding, Query-Frontends will keep a list of connected Queriers, and randomly (but consistently between query-frontends) choose N of them to distribute requests to. When Query-Frontend looks for the next request to send to a given querier, it will only consider tenants that “belong” to the Querier.\nTo choose N Queriers for a tenant, we propose to use a simple algorithm:\n Sort all Queriers by their ID SID = tenant ID SID = hash(SID) Pick the querier from the list of sorted queries with:\nindex = FNV-1a(SID) % number of Queriers Loop to (3) until we’ve found N distinct queriers (where N is the shard size) and stop early if there aren’t enough queriers hash() function to be decided. The required property is to be strong enough to not generate loops across multiple subsequent hashing of the previous hash.\nProperties Stability: this will produce the same result on all query-frontends as long as all queriers are connected to all query-frontends. Simplicity: no external dependencies. No consistent hashing: adding/removing queriers will cause “resharding” of tenants between queriers. While in general that’s not desirable property, queriers are stateless so it doesn’t seem to matter in this case. Implementation notes Caching: once this list of queriers to use for a tenant is computed in the query-frontend, it is cached in memory until queriers are added or removed. Per-tenant cache entries will have a TTL to discard tenants not “seen” since a while. Querier ID: Query-frontends currently don’t have any identity for queriers. We need to introduce sending of a unique ID (eg. hostname) by querier to query-frontend when it calls “Process” method. Backward-compatibility: when querier shuffle sharding is enabled, the system expects that both query-frontend and querier will run a compatible version. Cluster version upgrade will require to rollout new query-frontends and queriers first, and then enable shuffle sharding. UI: we propose to expose the current state of the query-frontend through a new endpoint which should display: Which querier are connected to the query-frontend Are there any “old” queriers, that are receiving requests from all tenants? Mapping of tenants to queriers. Note that this mapping may only be available for tenants with pending requests on given query-frontend, and therefore be very dynamic. Configuration Shard size will be configurable on a per-tenant basis via existing “runtime-configuration” mechanism (limits overrides). Changing a value for a tenant needs to invalidate cached per-tenant queriers. Queriers shard size will be a different setting than then one used for writes. Evaluated alternatives Use the subring An alternative option would be using the subring. This implies having queriers registering to the hash ring and query-frontend instances using the ring client to find the queriers subring for each tenant.\nThis solution looks adding more complexity without any actual benefit.\nChange query-frontend → querier architecture Completely different approach would be to introduce a place where starting queriers would register (eg. DNS-based service discovery), and let query-frontends discover queriers from this central registry.\nPossible benefit would be that queriers don’t need to initiate connection to all query-frontends, but query-frontends would only connect to queriers for which they have actual pending requests. However this would be a significant redesign of how query-frontend / querier communication works.\nQuerier → Store-gateway shuffle sharding Implemented in https://github.com/cortexproject/cortex/pull/3069.\nIntroduction As of today, the store-gateway supports blocks sharding with customizable replication factor (defaults to 3). Blocks of a single tenant are sharded across all store-gateway instances and so to execute a query the querier may touch any store-gateway in the cluster.\nThe current sharding implementation is based on a hash ring formed by store-gateway instances.\nProposal The proposed solution to add shuffle sharding support to the store-gateway is to leverage on the existing hash ring to build a per-tenant subring, which is then used both by the querier and store-gateway to know to which store-gateway a block belongs to.\nConfiguration Shuffle sharding can be enabled in the store-gateway configuration. It supports a default sharding factor, which is overridable on a per-tenant basis and live reloaded during runtime (using the existing limits config). The querier already requires the store-gateway configuration when the blocks sharding is enabled. Similarly, when shuffle sharding is enabled the querier will require the store-gateway shuffle sharding configuration as well. Implementation notes When shuffle sharding is enabled:\n The store-gateway syncUsersBlocks() will build a tenant’s subring for each tenant found scanning the bucket and will skip any tenant not belonging to its shard.\nLikewise, ShardingMetadataFilter will first build a tenant’s subring and then will use the existing logic to filter out blocks not belonging to store-gateway instance itself. The tenant ID can be read from the block’s meta.json. The querier blocksStoreReplicationSet.GetClientsFor() will first build a tenant’s subring and then will use the existing logic to find out to which store-gateway instance each requested block belongs to. Evaluated alternatives Given the store-gateways already form a ring and building the shuffle sharding based on the ring (like in the write path) doesn’t introduce extra operational complexity, we haven’t discussed alternatives.\nQuerier→ Ingesters shuffle sharding We’re currently discussing/evaluating different options.\nProblem Cortex must guarantee query correctness; transiently incorrect results may be cached and returned forever. The main problem to solve when introducing ingesters shuffle sharding on the read path is to make sure that a querier fetch data from all ingesters having at least 1 sample for a given tenant.\nThe problem to solve is: how can a querier efficiently find which ingesters have data for a given tenant? Each option must consider the changing of the set of ingesters and the changing of each tenant’s subring size.\nProposal: use only the information contained in the ring. This section describes an alternative approach. Discussion is still on-going.\nThe idea is for the queries to be able to deduce what ingesters could possibly hold data for a given tenant by just consulting the ring (and the per-tenant sub ring sizes). We posit that this is possible with only a single piece of extra information: a single timestamp per ingester saying when the ingester first joined the ring.\nScenario: ingester scale up When a new ingester is added to the ring, there will be a set of user subrings that see a change: an ingester being removed, and a new one being added. We need to guarantee that for some time period (the block flush interval), the ingester removed is also consulted for queries.\nTo do this, during the subring selection if we encounters an ingester added within the time period, we will add this to the subring but continue node selection as before - in effect, selecting an extra ingester:\nvar ( subringSize int selectedNodes []Node deadline = time.Now().Add(-flushWindow) ) for len(selectedNodes) \u0026lt; subringSize { token := random.Next() node := getNodeByToken(token) for { if node in selectedNodes { node = node.Next() continue } if node.Added.After(deadline) { subringSize++ selectedNodes.Add(node) node = node.Next() continue ) selectedNodes.Add(node) break ) } Scenario: ingester scale down When an ingester is permanently removed from the ring it will flush its data to the object store and the subrings containing the removed ingester will gain a “new” ingester. Queries consult the store and merge the results with those from the ingesters, so no data will be missed.\nQueriers and store-gateways will discover newly flushed blocks on next sync (-blocks-storage.bucket-store.sync-interval, default 5 minutes). Multiple ingesters should not be scaled-down within this interval.\nTo improve read-performance, queriers and rulers are usually configured with non-zero value of -querier.query-store-after option. This option makes queriers and rulers to consult only ingesters when running queries within specified time window (eg. 12h). During scale-down this needs to be lowered in order to let queriers and rulers use flushed blocks from the storage.\nScenario: increase size of a tenant’s subring Node selection for subrings is stable - increasing the size of a subring is guaranteed to only add new nodes to it (and not remove any nodes). Hence, if a tenant’s subring is increase in size the queriers will notice the config change and start consulting the new ingester.\nScenario: decreasing size of a tenant’s subring If a tenant’s subring decreases in size, there is currently no way for the queriers to know how big the ring was previously, and hence they will potentially miss an ingester with data for that tenant.\nThis is deemed an infrequent operation that we considered banning, but have a proposal for how we might make it possible:\nThe proposal is to have separate read subring and write subring size in the config. The read subring will not be allowed to be smaller than the write subring. When reducing the size of a tenant’s subring, operators must first reduce the write subring, and then two hours later when the blocks have been flushed, the read subring. In the majority of cases the read subring will not need to be specified, as it will default to the write subring size.\nConsidered alternative #1: Ingesters expose list of tenants A possible solution could be keeping in the querier an in-memory data structure to map each ingester to the list of tenants for which it has some data. This data structure would be constructed at querier startup, and then periodically updated, interpolating two information:\n The current state of the ring The list of tenants directly exposed by each ingester (via a dedicated gRPC call) Scenario: new querier starts up When a querier starts up and before getting ready:\n It scans all ingesters (discovered via the ring) and fetches the list of tenants for which each ingester has some data For each found tenant (unique list of tenant IDs across all ingesters responses), the querier looks at the current state of the ring and adds to the map the list of ingesters currently assigned to the tenant shard, even if they don’t hold any data yet (because may start receiving series shortly) Then the querier watches the ingester ring and rebuilds the in-memory map whenever the ring topology changes.\nScenario: querier receives a query for an unknown tenant A new tenant starts remote writing to the cluster. The querier doesn’t know it in its in-memory map, so it adds the tenant on the fly to the map just looking at the current state of the ring.\nScenario: ingester scale up / down When a new ingester is added / removed to / from the ring, the ring topology changes and queriers will update the in-memory map.\nScenario: per-tenant shard size increases Queriers periodically (every 1m) reload the limits config file. When a tenant shard size change is detected, the querier updates the in-memory map for the affected tenant.\nIssue: some time series data may be missing in queries up to 1m.\nEdge case: queriers notice the ring topology change before distributors Consider the following scenario:\n Tenant A shard is composed by ingesters 1,2,3,4,5,6 Tenant A is remote writing 1 single series and gets replicated to ingester 1,2,3 The ring topology changes and tenant A shard is ingesters 1,2,3,7,8,9 Querier notices the ring topology change and updates the in-memory map. Given tenant A series were only on ingester 1,2,3, the querier maps tenant A to ingester 1,2,3 (because of what received from ingesters via gRPC) and 7,8,9 (because of the current state of the ring) Distributor hasn’t updated the ring state yet Tenant A remote writes 1 new series, which get replicated to 4,5,6 Distributor updates the ring state Race condition: querier will not know that ingesters 4,5,6 contains tenant A data until the next sync Considered alternative #2: streaming updates from ingesters to queriers This section describes an alternative approach.\nCurrent state As of today, queriers discover ingesters via the ring:\n Ingesters register (and update their heartbeat timestamp) to the ring and queriers watch the ring, keeping an in-memory copy of the latest ingesters ring state. Queriers use the in-memory ring state to discover all ingesters that should be queried at query time. Proposal The proposal is to expose a new gRPC endpoint on ingesters, which allows queriers to receive a stream of real time updates from ingesters about the tenants for which an ingester currently has time series data.\nFrom the querier side:\n At startup the querier discovers all existing ingesters. For each ingester, the querier calls the ingester’s gRPC endpoint WatchTenants() (to be created). As soon as the WatchTenants() rpc is called, the ingester sends the entire set of tenants to the querier and then will send incremental updates (tenant added or removed from ingester) while the WatchTenants() stream connection is alive. If the querier loses the connection to an ingester, it will automatically retry (with backoff) while the ingester is within the ring. The querier watches the ring to discover added/removed ingesters. When an ingester is added, the querier adds the ingester to the pool of ingesters whose state should be monitored via WatchTenants(). At query time, the querier looks for all ingesters within the ring. There are two options: The querier knows the state of the ingester: the ingester will be queried only if it contains data for the query’s tenant. The querier doesn’t know the state of the ingester (eg. because it was just registered to the ring and WatchTenants() hasn’t succeeded yet): the ingester will be queried anyway (correctness first). The querier will fine tune gRPC keepalive settings to ensure a lost connection between the querier and ingester will be early detected and retried. Trade-offs Pros:\n The querier logic, used to find ingesters for a tenant’s shard, does not require to watch the overrides config file (containing tenant shard size override). Watching the file in the querier is problematic because of introduced delays (ConfigMap update and Cortex file polling) which could lead to distributors apply changes before queriers. The querier never uses the current state of the ring as a source of information to detect which ingesters have data for a specific tenant. This information comes directly from the ingesters themselves, which makes the implementation less likely to be subject to race conditions. Cons:\n Each querier needs to open a gRPC connection to each ingester. Given gRPC supports multiplexing, the underlying TCP connection could be the same connection used to fetch samples from ingesters at query time, basically having 1 single TCP connection between a querier and an ingester. The “Edge case: queriers notice the ring topology change before distributors” described in attempt #1 can still happen in case of delays in the propagation of the state update from an ingester to queriers: Short delay: a short delay (few seconds) shouldn’t be a real problem. From the final user perspective, there’s no real difference between this edge case and a delay of few seconds in the ingestion path (eg. Prometheus remote write lagging behind few seconds). In the real case of Prometheus remote writing to Cortex, there’s no easy way to know if the latest samples are missing because has not been remote written yet by Prometheus or any delay in the propagation of this information between ingesters and queriers. Long delay: in case of networking issue propagating the state update from an ingester to the querier, the gRPC keepalive will trigger (because of failed ping-pong) and the querier will remove the failing ingesters in-memory data, so the ingester will be always tried by the querier for any query, until the state update will be re-established. Ruler sharding Introduction The ruler currently supports rule groups sharding across a pool of rulers. When sharding is enabled, rulers form a hash ring and each ruler uses the ring to check if it should evaluate a specific rule group.\nAt a polling interval (defaults to 1 minute), the ruler:\n List all the bucket objects to find all rule groups (listing is done specifying an empty delimiter so it return objects at any depth) For each discovered rule group, the ruler hashes the object key and checks if it belongs to the range of tokens assigned to the ruler itself. If not, the rule group is discarded, otherwise it’s kept for evaluation. Proposal We propose to introduce shuffle sharding in the ruler as well, leveraging on the already existing hash ring used by the current sharding implementation.\nThe configuration will be extended to allow to configure:\n Enable/disable shuffle sharding Default shard size Per-tenant overrides (reloaded at runtime) When shuffle sharding is enabled:\n The ruler lists (ListBucketV2) the tenants for which rule groups are stored in the bucket The ruler filters out tenants not belonging to its shard For each tenant belonging to its shard, the ruler does a ListBucketV2 call with the “/” prefix and with empty delimiter to find all the rule groups, which are then evaluated in the ruler The ruler re-syncs the rule groups from the bucket whenever one of the following conditions happen:\n Periodic interval (configurable) Ring topology changes The configured shard size of a tenant has changed Other notes The “subring” implementation is unoptimized. We will optimize it as part of this work to make sure no performance degradation is introduced when using the subring vs the normal ring. ","excerpt":"Author: @pracucci, @tomwilkie, @pstibrany Reviewers: Date: August 2020 Status: Proposed, partially …","ref":"/docs/proposals/shuffle-sharding-on-the-read-path/","title":"Shuffle sharding on the read path"},{"body":" Author: @gotjosh Reviewers: @gouthamve, @pracucci Date: March 2020 Status: Accepted Problem Statement Prometheus holds metric metadata alongside the contents of a scrape. This metadata (HELP, TYPE, UNIT and METRIC_NAME) enables some Prometheus API endpoints to output the metadata for integrations (e.g. Grafana) to consume it.\nAt the moment of writing, Cortex does not support the api/v1/metadata endpoint that Prometheus implements as metadata was never propagated via remote write. Recent work is done in Prometheus enables the propagation of metadata.\nWith this in place, remote write integrations such as Cortex can now receive this data and implement the API endpoint. This results in Cortex users being able to enjoy a tiny bit more insight on their metrics.\nPotential Solutions Before we delve into the solutions, let\u0026rsquo;s set a baseline about how the data is received. This applies almost equally for the two.\nMetadata from Prometheus is sent in the same WriteRequest proto message that the samples use. It is part of a different field (#3 given #2 is already used interally), the data is a set identified by the metric name - that means it is aggregated across targets, and is sent all at once. Implying, Cortex will receive a single WriteRequest containing a set of the metadata for that instance at an specified interval.\n. It is also important to note that this current process is an intermediary step. Eventually, metadata in a request will be sent alongside samples and only for those included. The solutions proposed, take this nuance into account to avoid coupling between the current and future state of Prometheus, and hopefully do something now that also works for the future.\nAs a reference, these are some key numbers regarding the size (and send timings) of the data at hand from our clusters at Grafana Labs:\n On average, metadata (a combination of HELP, TYPE, UNIT and METRIC_NAME) is ~55 bytes uncompressed. at GL, on an instance with about 2.6M active series, we hold ~1241 unique metrics in total. with that, we can assume that on a worst-case scenario the metadata set for that instance is ~68 kilobytes uncompressed. by default, this data is only propagated once every minute (aligning with the default scrape interval), but this can be adjusted. Finally, what this gives us is a baseline worst-case scenario formula for the data to store per tenant: ~68KB * Replication Factor * # of Instances. Keeping in mind that typically, there\u0026rsquo;s a very high overlap of metadata across instances, and we plan to deduplicate in the ingesters. Write Path Store the metadata directly from the distributors into a cache (e.g. Memcached) Since metadata is received all at once, we could directly store into an external cache using the tenant ID as a key, and still, avoid a read-modify-write. However, a very common use case of Cortex is to have multiple Prometheus sending data for the same tenant ID. This complicates things, as it adds a need to have an intermediary merging phase and thus making a read-modify-write inevitable.\nKeep metadata in memory within the ingesters Similarly to what we do with sample data, we can keep the metadata in-memory in the ingesters and apply similar semantics. I propose to use the tenant ID as a hash key, distribute it to the ingesters (taking into account the replication factor), using a hash map to keep a set of the metadata across all instances for a single tenant, and implement a configurable time-based purge process to deal with metadata churn. Given, we need to ensure fair-use we also propose implementing limits for both the number of metadata entries we can receive and the size of a single entry.\nRead Path In my eyes, the read path seems to only have one option. At the moment of writing, Cortex uses a DummyTargetRetriever as a way to signal that these API endpoints are not implemented. We\u0026rsquo;d need to modify the Prometheus interface to support a Context and extract the tenant ID from there. Then, use the tenant ID to query the ingesters for the data, deduplicate it and serve it.\nConclusions I conclude that solution #2 is ideal for this work on the write path. It allows us to use similar semantics to samples, thus reducing operational complexity, and lays a groundwork for when we start receiving metadata alongside samples.\nThere\u0026rsquo;s one last piece to address: Allowing metadata to survive rolling restarts. Option #1 handles this well, given the aim would be to use an external cache such as Memcached. Option #2 lacks this, as it does not include any plans to persist this data. Given Prometheus (by default) sends metadata every minute, and we don\u0026rsquo;t need a high level of consistency. We expect that an eventual consistency of up to 1 minute on the default case is deemed acceptable.\nReferences Prometheus Propagate metadata via Remote Write Design Doc Prometheus Propagate metadata via Remote Write Design Issue ","excerpt":"Author: @gotjosh Reviewers: @gouthamve, @pracucci Date: March 2020 Status: Accepted Problem …","ref":"/docs/proposals/support-metadata-api/","title":"Support metadata API"},{"body":"Cortex consists of multiple horizontally scalable microservices. Each microservice uses the most appropriate technique for horizontal scaling; most are stateless and can handle requests for any users while some (namely the ingesters) are semi-stateful and depend on consistent hashing. This document provides a basic overview of Cortex\u0026rsquo;s architecture.\nThe role of Prometheus Prometheus instances scrape samples from various targets and then push them to Cortex (using Prometheus\u0026rsquo; remote write API). That remote write API emits batched Snappy-compressed Protocol Buffer messages inside the body of an HTTP PUT request.\nCortex requires that each HTTP request bear a header specifying a tenant ID for the request. Request authentication and authorization are handled by an external reverse proxy.\nIncoming samples (writes from Prometheus) are handled by the distributor while incoming reads (PromQL queries) are handled by the querier or optionally by the query frontend.\nStorage Cortex currently supports two storage engines to store and query the time series:\n Chunks (default) Blocks The two engines mostly share the same Cortex architecture with few differences outlined in the rest of the document.\nChunks storage (default) The chunks storage stores each single time series into a separate object called Chunk. Each Chunk contains the samples for a given period (defaults to 12 hours). Chunks are then indexed by time range and labels, in order to provide a fast lookup across many (over millions) Chunks.\nFor this reason, the chunks storage consists of:\n An index for the Chunks. This index can be backed by: Amazon DynamoDB Google Bigtable Apache Cassandra An object store for the Chunk data itself, which can be: Amazon DynamoDB Google Bigtable Apache Cassandra Amazon S3 Google Cloud Storage Microsoft Azure Storage Internally, the access to the chunks storage relies on a unified interface called \u0026ldquo;chunks store\u0026rdquo;. Unlike other Cortex components, the chunk store is not a separate service, but rather a library embedded in the services that need to access the long-term storage: ingester, querier and ruler.\nThe chunk and index format are versioned, this allows Cortex operators to upgrade the cluster to take advantage of new features and improvements. This strategy enables changes in the storage format without requiring any downtime or complex procedures to rewrite the stored data. A set of schemas are used to map the version while reading and writing time series belonging to a specific period of time.\nThe current schema recommendation is the v9 schema for most use cases and v10 schema if you expect to have very high cardinality metrics (v11 is still experimental). For more information about the schema, please check out the Schema documentation.\nBlocks storage The blocks storage is based on Prometheus TSDB: it stores each tenant\u0026rsquo;s time series into their own TSDB which write out their series to a on-disk Block (defaults to 2h block range periods). Each Block is composed by few files storing the chunks and the block index.\nThe TSDB chunk files contain the samples for multiple series. The series inside the Chunks are then indexed by a per-block index, which indexes metric names and labels to time series in the chunk files.\nThe blocks storage doesn\u0026rsquo;t require a dedicated storage backend for the index. The only requirement is an object store for the Block files, which can be:\n Amazon S3 Google Cloud Storage Microsoft Azure Storage Local Filesystem (single node only) OpenStack Swift (experimental) For more information, please check out the Blocks storage documentation.\nServices Cortex has a service-based architecture, in which the overall system is split up into a variety of components that perform a specific task. These components run separately and in parallel. Cortex can alternatively run in a single process mode, where all components are executed within a single process. The single process mode is particularly handy for local testing and development.\nCortex is, for the most part, a shared-nothing system. Each layer of the system can run multiple instances of each component and they don\u0026rsquo;t coordinate or communicate with each other within that layer.\nThe Cortex services are:\n Distributor Ingester Querier Query frontend (optional) Ruler (optional) Alertmanager (optional) Configs API (optional) Distributor The distributor service is responsible for handling incoming samples from Prometheus. It\u0026rsquo;s the first stop in the write path for series samples. Once the distributor receives samples from Prometheus, each sample is validated for correctness and to ensure that it is within the configured tenant limits, falling back to default ones in case limits have not been overridden for the specific tenant. Valid samples are then split into batches and sent to multiple ingesters in parallel.\nThe validation done by the distributor includes:\n The metric labels name are formally correct The configured max number of labels per metric is respected The configured max length of a label name and value is respected The timestamp is not older/newer than the configured min/max time range Distributors are stateless and can be scaled up and down as needed.\nHigh Availability Tracker The distributor features a High Availability (HA) Tracker. When enabled, the distributor deduplicates incoming samples from redundant Prometheus servers. This allows you to have multiple HA replicas of the same Prometheus servers, writing the same series to Cortex and then deduplicate these series in the Cortex distributor.\nThe HA Tracker deduplicates incoming samples based on a cluster and replica label. The cluster label uniquely identifies the cluster of redundant Prometheus servers for a given tenant, while the replica label uniquely identifies the replica within the Prometheus cluster. Incoming samples are considered duplicated (and thus dropped) if received by any replica which is not the current primary within a cluster.\nThe HA Tracker requires a key-value (KV) store to coordinate which replica is currently elected. The distributor will only accept samples from the current leader. Samples with one or no labels (of the replica and cluster) are accepted by default and never deduplicated.\nThe supported KV stores for the HA tracker are:\n Consul Etcd Note: Memberlist is not supported. Memberlist-based KV store propagates updates using gossip, which is very slow for HA purposes: result is that different distributors may see different Prometheus server as elected HA replica, which is definitely not desirable.\nFor more information, please refer to config for sending HA pairs data to Cortex in the documentation.\nHashing Distributors use consistent hashing, in conjunction with a configurable replication factor, to determine which ingester instance(s) should receive a given series.\nCortex supports two hashing strategies:\n Hash the metric name and tenant ID (default) Hash the metric name, labels and tenant ID (enabled with -distributor.shard-by-all-labels=true) The trade-off associated with the latter is that writes are more balanced across ingesters but each query needs to talk to any ingester since a metric could be spread across multiple ingesters given different label sets.\nThe hash ring A hash ring (stored in a key-value store) is used to achieve consistent hashing for the series sharding and replication across the ingesters. All ingesters register themselves into the hash ring with a set of tokens they own; each token is a random unsigned 32-bit number. Each incoming series is hashed in the distributor and then pushed to the ingester owning the tokens range for the series hash number plus N-1 subsequent ingesters in the ring, where N is the replication factor.\nTo do the hash lookup, distributors find the smallest appropriate token whose value is larger than the hash of the series. When the replication factor is larger than 1, the next subsequent tokens (clockwise in the ring) that belong to different ingesters will also be included in the result.\nThe effect of this hash set up is that each token that an ingester owns is responsible for a range of hashes. If there are three tokens with values 0, 25, and 50, then a hash of 3 would be given to the ingester that owns the token 25; the ingester owning token 25 is responsible for the hash range of 1-25.\nThe supported KV stores for the hash ring are:\n Consul Etcd Gossip memberlist Quorum consistency Since all distributors share access to the same hash ring, write requests can be sent to any distributor and you can setup a stateless load balancer in front of it.\nTo ensure consistent query results, Cortex uses Dynamo-style quorum consistency on reads and writes. This means that the distributor will wait for a positive response of at least one half plus one of the ingesters to send the sample to before successfully responding to the Prometheus write request.\nLoad balancing across distributors We recommend randomly load balancing write requests across distributor instances. For example, if you\u0026rsquo;re running Cortex in a Kubernetes cluster, you could run the distributors as a Kubernetes Service.\nIngester The ingester service is responsible for writing incoming series to a long-term storage backend on the write path and returning in-memory series samples for queries on the read path.\nIncoming series are not immediately written to the storage but kept in memory and periodically flushed to the storage (by default, 12 hours for the chunks storage and 2 hours for the blocks storage). For this reason, the queriers may need to fetch samples both from ingesters and long-term storage while executing a query on the read path.\nIngesters contain a lifecycler which manages the lifecycle of an ingester and stores the ingester state in the hash ring. Each ingester could be in one of the following states:\n PENDING\nThe ingester has just started. While in this state, the ingester doesn\u0026rsquo;t receive neither write and read requests, and could be waiting for time series data transfer from another ingester if running the chunks storage and the hand-over is enabled. JOINING\nThe ingester is starting up and joining the ring. While in this state the ingester doesn\u0026rsquo;t receive neither write and read requests. The ingester will join the ring using tokens received by a leaving ingester as part of the hand-over process (if enabled), otherwise it could load tokens from disk (if -ingester.tokens-file-path is configured) or generate a set of new random ones. Finally, the ingester optionally observes the ring for tokens conflicts and then, once any conflict is resolved, will move to ACTIVE state. ACTIVE\nThe ingester is up and running. While in this state the ingester can receive both write and read requests. LEAVING\nThe ingester is shutting down and leaving the ring. While in this state the ingester doesn\u0026rsquo;t receive write requests, while it could receive read requests. UNHEALTHY\nThe ingester has failed to heartbeat to the ring\u0026rsquo;s KV Store. While in this state, distributors skip the ingester while building the replication set for incoming series and the ingester does not receive write or read requests. The ingester states are interally used for different purposes, including the series hand-over process supported by the chunks storage. For more information about it, please check out the Ingester hand-over documentation.\nIngesters are semi-stateful.\nIngesters failure and data loss If an ingester process crashes or exits abruptly, all the in-memory series that have not yet been flushed to the long-term storage will be lost. There are two main ways to mitigate this failure mode:\n Replication Write-ahead log (WAL) The replication is used to hold multiple (typically 3) replicas of each time series in the ingesters. If the Cortex cluster looses an ingester, the in-memory series hold by the lost ingester are also replicated at least to another ingester. In the event of a single ingester failure, no time series samples will be lost while, in the event of multiple ingesters failure, time series may be potentially lost if failure affects all the ingesters holding the replicas of a specific time series.\nThe write-ahead log (WAL) is used to write to a persistent disk all incoming series samples until they\u0026rsquo;re flushed to the long-term storage. In the event of an ingester failure, a subsequent process restart will replay the WAL and recover the in-memory series samples.\nContrary to the sole replication and given the persistent disk data is not lost, in the event of multiple ingesters failure each ingester will recover the in-memory series samples from WAL upon subsequent restart. The replication is still recommended in order to ensure no temporary failures on the read path in the event of a single ingester failure.\nThe WAL for the chunks storage is disabled by default, while it\u0026rsquo;s always enabled for the blocks storage.\nIngesters write de-amplification Ingesters store recently received samples in-memory in order to perform write de-amplification. If the ingesters would immediately write received samples to the long-term storage, the system would be very difficult to scale due to the very high pressure on the storage. For this reason, the ingesters batch and compress samples in-memory and periodically flush them out to the storage.\nWrite de-amplification is the main source of Cortex\u0026rsquo;s low total cost of ownership (TCO).\nQuerier The querier service handles queries using the PromQL query language.\nQueriers fetch series samples both from the ingesters and long-term storage: the ingesters hold the in-memory series which have not yet been flushed to the long-term storage. Because of the replication factor, it is possible that the querier may receive duplicated samples; to resolve this, for a given time series the querier internally deduplicates samples with the same exact timestamp.\nQueriers are stateless and can be scaled up and down as needed.\nQuery frontend The query frontend is an optional service providing the querier\u0026rsquo;s API endpoints and can be used to accelerate the read path. When the query frontend is in place, incoming query requests should be directed to the query frontend instead of the queriers. The querier service will be still required within the cluster, in order to execute the actual queries.\nThe query frontend internally performs some query adjustments and holds queries in an internal queue. In this setup, queriers act as workers which pull jobs from the queue, execute them, and return them to the query-frontend for aggregation. Queriers need to be configured with the query frontend address (via the -querier.frontend-address CLI flag) in order to allow them to connect to the query frontends.\nQuery frontends are stateless. However, due to how the internal queue works, it\u0026rsquo;s recommended to run a few query frontend replicas to reap the benefit of fair scheduling. Two replicas should suffice in most cases.\nQueueing The query frontend queuing mechanism is used to:\n Ensure that large queries, that could cause an out-of-memory (OOM) error in the querier, will be retried on failure. This allows administrators to under-provision memory for queries, or optimistically run more small queries in parallel, which helps to reduce the TCO. Prevent multiple large requests from being convoyed on a single querier by distributing them across all queriers using a first-in/first-out queue (FIFO). Prevent a single tenant from denial-of-service-ing (DOSing) other tenants by fairly scheduling queries between tenants. Splitting The query frontend splits multi-day queries into multiple single-day queries, executing these queries in parallel on downstream queriers and stitching the results back together again. This prevents large (multi-day) queries from causing out of memory issues in a single querier and helps to execute them faster.\nCaching The query frontend supports caching query results and reuses them on subsequent queries. If the cached results are incomplete, the query frontend calculates the required subqueries and executes them in parallel on downstream queriers. The query frontend can optionally align queries with their step parameter to improve the cacheability of the query results. The result cache is compatible with any cortex caching backend (currently memcached, redis, and an in-memory cache).\nRuler The ruler is an optional service executing PromQL queries for recording rules and alerts. The ruler requires a database storing the recording rules and alerts for each tenant.\nRuler is semi-stateful and can be scaled horizontally. Running rules internally have state, as well as the ring the rulers initiate. However, if the rulers all fail and restart, Prometheus alert rules have a feature where an alert is restored and returned to a firing state if it would have been active in its for period. However, there would be gaps in the series generated by the recording rules.\nAlertmanager The alertmanager is an optional service responsible for accepting alert notifications from the ruler, deduplicating and grouping them, and routing them to the correct notification channel, such as email, PagerDuty or OpsGenie.\nThe Cortex alertmanager is built on top of the Prometheus Alertmanager, adding multi-tenancy support. Like the ruler, the alertmanager requires a database storing the per-tenant configuration.\nAlertmanager is semi-stateful. The Alertmanager persists information about silences and active alerts to its disk. If all of the alertmanager nodes failed simultaneously there would be a loss of data.\nConfigs API The configs API is an optional service managing the configuration of Rulers and Alertmanagers. It provides APIs to get/set/update the ruler and alertmanager configurations and store them into backend. Current supported backend are PostgreSQL and in-memory.\nConfigs API is stateless.\n","excerpt":"Cortex consists of multiple horizontally scalable microservices. Each microservice uses the most …","ref":"/docs/architecture/","title":"Cortex Architecture"},{"body":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary mode is easier to deploy and is aimed mainly at users wanting to try out Cortex or develop on it. The microservices mode is intended for production usage, as it allows you to independently scale different services and isolate failures.\nThis document will focus on single-process Cortex with the blocks storage. See the architecture doc for more information about the microservices and blocks operation for more information about the blocks storage.\nSeparately from single process vs microservices decision, Cortex can be configured to use local storage or cloud storage (S3, GCS and Azure). Cortex can also make use of external Memcacheds and Redis for caching but this feature is not (yet) available using blocks storage.\nSingle instance, single process For simplicity and to get started, we\u0026rsquo;ll run it as a single process with no dependencies. You can reconfigure the config to use GCS, Azure storage or local storage as shown in the file\u0026rsquo;s comments.\n$ go build ./cmd/cortex $ ./cortex -config.file=./docs/configuration/single-process-config-blocks.yaml Unless reconfigured this starts a single Cortex node storing blocks to S3 in bucket cortex. It is not intended for production use.\nClone and build prometheus\n$ git clone https://github.com/prometheus/prometheus $ cd prometheus $ go build ./cmd/prometheus Add the following to your Prometheus config (documentation/examples/prometheus.yml in Prometheus repo):\nremote_write:- url:http://localhost:9009/api/prom/pushAnd start Prometheus with that config file:\n$ ./prometheus --config.file=./documentation/examples/prometheus.yml Your Prometheus instance will now start pushing data to Cortex. To query that data, start a Grafana instance:\n$ docker run --rm -d --name=grafana -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://host.docker.internal:9009/api/prom).\nTo clean up: press CTRL-C in both terminals (for Cortex and Promrtheus).\nHorizontally scale out Next we\u0026rsquo;re going to show how you can run a scale out Cortex cluster using Docker. We\u0026rsquo;ll need:\n A built Cortex image. A Docker network to put these containers on so they can resolve each other by name. A single node Consul instance to coordinate the Cortex cluster. $ make ./cmd/cortex/.uptodate $ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul Next we\u0026rsquo;ll run a couple of Cortex instances pointed at that Consul. You\u0026rsquo;ll note the Cortex configuration can be specified in either a config file or overridden on the command line. See the arguments documentation for more information about Cortex configuration options.\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 If you go to http://localhost:9001/ring (or http://localhost:9002/ring) you should see both Cortex nodes join the ring.\nTo demonstrate the correct operation of Cortex clustering, we\u0026rsquo;ll send samples to one of the instances and queries to another. In production, you\u0026rsquo;d want to load balance both pushes and queries evenly among all the nodes.\nPoint Prometheus at the first:\nremote_write:- url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml And Grafana at the second:\n$ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana In the Grafana UI (username/password admin/admin), add a Prometheus datasource for Cortex (http://cortex2:9009/api/prom).\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 consul grafana $ docker network remove cortex High availability with replication In this last demo we\u0026rsquo;ll show how Cortex can replicate data among three nodes, and demonstrate Cortex can tolerate a node failure without affecting reads and writes.\nFirst, create a network and run a new Consul and Grafana:\n$ docker network create cortex $ docker run -d --name=consul --network=cortex -e CONSUL_BIND_INTERFACE=eth0 consul $ docker run -d --name=grafana --network=cortex -p 3000:3000 grafana/grafana Then, launch 3 Cortex nodes with replication factor 3:\n$ docker run -d --name=cortex1 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9001:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex2 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9002:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 $ docker run -d --name=cortex3 --network=cortex \\ -v $(pwd)/docs/configuration/single-process-config-blocks.yaml:/etc/single-process-config-blocks.yaml \\ -p 9003:9009 \\ quay.io/cortexproject/cortex \\ -config.file=/etc/single-process-config-blocks.yaml \\ -ring.store=consul \\ -consul.hostname=consul:8500 \\ -distributor.replication-factor=3 Configure Prometheus to send data to the first replica:\nremote_write:- url:http://localhost:9001/api/prom/push$ ./prometheus --config.file=./documentation/examples/prometheus.yml In Grafana, add a datasource for the 3rd Cortex replica (http://cortex3:9009/api/prom) and verify the same data appears in both Prometheus and Cortex.\nTo show that Cortex can tolerate a node failure, hard kill one of the Cortex replicas:\n$ docker rm -f cortex2 You should see writes and queries continue to work without error.\nTo clean up: CTRL-C the Prometheus process and run:\n$ docker rm -f cortex1 cortex2 cortex3 consul grafana $ docker network remove cortex ","excerpt":"Cortex can be run as a single binary or as multiple independent microservices. The single-binary …","ref":"/docs/getting-started/getting-started-blocks-storage/","title":"Getting Started with Blocks Storage"},{"body":"General Notes Cortex has evolved over several years, and the command-line options sometimes reflect this heritage. In some cases the default value for options is not the recommended value, and in some cases names do not reflect the true meaning. We do intend to clean this up, but it requires a lot of care to avoid breaking existing installations. In the meantime we regret the inconvenience.\nDuration arguments should be specified with a unit like 5s or 3h. Valid time units are \u0026ldquo;ms\u0026rdquo;, \u0026ldquo;s\u0026rdquo;, \u0026ldquo;m\u0026rdquo;, \u0026ldquo;h\u0026rdquo;.\nQuerier -querier.max-concurrent\nThe maximum number of top-level PromQL queries that will execute at the same time, per querier process. If using the query frontend, this should be set to at least (-querier.worker-parallelism * number of query frontend replicas). Otherwise queries may queue in the queriers and not the frontend, which will affect QoS. Alternatively, consider using -querier.worker-match-max-concurrent to force worker parallelism to match -querier.max-concurrent.\n -querier.query-parallelism\nThis refers to database queries against the store (e.g. Bigtable or DynamoDB). This is the max subqueries run in parallel per higher-level query.\n -querier.timeout\nThe timeout for a top-level PromQL query.\n -querier.max-samples\nMaximum number of samples a single query can load into memory, to avoid blowing up on enormous queries.\n The next three options only apply when the querier is used together with the Query Frontend:\n -querier.frontend-address\nAddress of query frontend service, used by workers to find the frontend which will give them queries to execute.\n -querier.dns-lookup-period\nHow often the workers will query DNS to re-check where the frontend is.\n -querier.worker-parallelism\nNumber of simultaneous queries to process, per query frontend. See note on -querier.max-concurrent\n -querier.worker-match-max-concurrent\nForce worker concurrency to match the -querier.max-concurrent option. Overrides -querier.worker-parallelism. See note on -querier.max-concurrent\n Querier and Ruler The ingester query API was improved over time, but defaults to the old behaviour for backwards-compatibility. For best results both of these next two flags should be set to true:\n -querier.batch-iterators\nThis uses iterators to execute query, as opposed to fully materialising the series in memory, and fetches multiple results per loop.\n -querier.ingester-streaming\nUse streaming RPCs to query ingester, to reduce memory pressure in the ingester.\n -querier.iterators\nThis is similar to -querier.batch-iterators but less efficient. If both iterators and batch-iterators are true, batch-iterators will take precedence.\n -promql.lookback-delta\nTime since the last sample after which a time series is considered stale and ignored by expression evaluations.\n Query Frontend -querier.parallelise-shardable-queries\nIf set to true, will cause the query frontend to mutate incoming queries when possible by turning sum operations into sharded sum operations. This requires a shard-compatible schema (v10+). An abridged example: sum by (foo) (rate(bar{baz=”blip”}[1m])) -\u0026gt;\nsum by (foo) ( sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”0of16”}[1m])) or sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”1of16”}[1m])) or ... sum by (foo) (rate(bar{baz=”blip”,__cortex_shard__=”15of16”}[1m])) ) When enabled, the query-frontend requires a schema config to determine how/when to shard queries, either from a file or from flags (i.e. by the -schema-config-file CLI flag). This is the same schema config the queriers consume. It\u0026rsquo;s also advised to increase downstream concurrency controls as well to account for more queries of smaller sizes:\n querier.max-outstanding-requests-per-tenant querier.max-query-parallelism querier.max-concurrent server.grpc-max-concurrent-streams (for both query-frontends and queriers) Furthermore, both querier and query-frontend components require the querier.query-ingesters-within parameter to know when to start sharding requests (ingester queries are not sharded). It\u0026rsquo;s recommended to align this with ingester.max-chunk-age.\nInstrumentation (traces) also scale with the number of sharded queries and it\u0026rsquo;s suggested to account for increased throughput there as well (for instance via JAEGER_REPORTER_MAX_QUEUE_SIZE).\n -querier.align-querier-with-step\nIf set to true, will cause the query frontend to mutate incoming queries and align their start and end parameters to the step parameter of the query. This improves the cacheability of the query results.\n -querier.split-queries-by-day\nIf set to true, will cause the query frontend to split multi-day queries into multiple single-day queries and execute them in parallel.\n -querier.cache-results\nIf set to true, will cause the querier to cache query results. The cache will be used to answer future, overlapping queries. The query frontend calculates extra queries required to fill gaps in the cache.\n -frontend.max-cache-freshness\nWhen caching query results, it is desirable to prevent the caching of very recent results that might still be in flux. Use this parameter to configure the age of results that should be excluded.\n -frontend.memcached.{hostname, service, timeout}\nUse these flags to specify the location and timeout of the memcached cluster used to cache query results.\n -frontend.redis.{endpoint, timeout}\nUse these flags to specify the location and timeout of the Redis service used to cache query results.\n Distributor -distributor.shard-by-all-labels\nIn the original Cortex design, samples were sharded amongst distributors by the combination of (userid, metric name). Sharding by metric name was designed to reduce the number of ingesters you need to hit on the read path; the downside was that you could hotspot the write path.\nIn hindsight, this seems like the wrong choice: we do many orders of magnitude more writes than reads, and ingester reads are in-memory and cheap. It seems the right thing to do is to use all the labels to shard, improving load balancing and support for very high cardinality metrics.\nSet this flag to true for the new behaviour.\nImportant to note is that when setting this flag to true, it has to be set on both the distributor and the querier (called -distributor.shard-by-all-labels on Querier as well). If the flag is only set on the distributor and not on the querier, you will get incomplete query results because not all ingesters are queried.\nUpgrade notes: As this flag also makes all queries always read from all ingesters, the upgrade path is pretty trivial; just enable the flag. When you do enable it, you\u0026rsquo;ll see a spike in the number of active series as the writes are \u0026ldquo;reshuffled\u0026rdquo; amongst the ingesters, but over the next stale period all the old series will be flushed, and you should end up with much better load balancing. With this flag enabled in the queriers, reads will always catch all the data from all ingesters.\n -distributor.extra-query-delay This is used by a component with an embedded distributor (Querier and Ruler) to control how long to wait until sending more than the minimum amount of queries needed for a successful response.\n distributor.ha-tracker.enable-for-all-users Flag to enable, for all users, handling of samples with external labels identifying replicas in an HA Prometheus setup. This defaults to false, and is technically defined in the Distributor limits.\n distributor.ha-tracker.enable Enable the distributors HA tracker so that it can accept samples from Prometheus HA replicas gracefully (requires labels). Global (for distributors), this ensures that the necessary internal data structures for the HA handling are created. The option enable-for-all-users is still needed to enable ingestion of HA samples for all users.\n distributor.drop-label This flag can be used to specify label names that to drop during sample ingestion within the distributor and can be repeated in order to drop multiple labels.\n Ring/HA Tracker Store The KVStore client is used by both the Ring and HA Tracker (HA Tracker doesn\u0026rsquo;t support memberlist as KV store).\n {ring,distributor.ha-tracker}.prefix The prefix for the keys in the store. Should end with a /. For example with a prefix of foo/, the key bar would be stored under foo/bar. {ring,distributor.ha-tracker}.store Backend storage to use for the HA Tracker (consul, etcd, inmemory, multi). {ring,distributor.ring}.store Backend storage to use for the Ring (consul, etcd, inmemory, memberlist, multi). Consul By default these flags are used to configure Consul used for the ring. To configure Consul for the HA tracker, prefix these flags with distributor.ha-tracker.\n consul.hostname Hostname and port of Consul. consul.acl-token ACL token used to interact with Consul. consul.client-timeout HTTP timeout when talking to Consul. consul.consistent-reads Enable consistent reads to Consul. etcd By default these flags are used to configure etcd used for the ring. To configure etcd for the HA tracker, prefix these flags with distributor.ha-tracker.\n etcd.endpoints The etcd endpoints to connect to. etcd.dial-timeout The timeout for the etcd connection. etcd.max-retries The maximum number of retries to do for failed ops. etcd.tls-enabled Enable TLS. etcd.tls-cert-path The TLS certificate file path. etcd.tls-key-path The TLS private key file path. etcd.tls-ca-path The trusted CA file path. etcd.tls-insecure-skip-verify Skip validating server certificate. memberlist Warning: memberlist KV works only for the hash ring, not for the HA Tracker, because propagation of changes is too slow for HA Tracker purposes.\nWhen using memberlist-based KV store, each node maintains its own copy of the hash ring. Updates generated locally, and received from other nodes are merged together to form the current state of the ring on the node. Updates are also propagated to other nodes. All nodes run the following two loops:\n Every \u0026ldquo;gossip interval\u0026rdquo;, pick random \u0026ldquo;gossip nodes\u0026rdquo; number of nodes, and send recent ring updates to them. Every \u0026ldquo;push/pull sync interval\u0026rdquo;, choose random single node, and exchange full ring information with it (push/pull sync). After this operation, rings on both nodes are the same. When a node receives a ring update, node will merge it into its own ring state, and if that resulted in a change, node will add that update to the list of gossiped updates. Such update will be gossiped R * log(N+1) times by this node (R = retransmit multiplication factor, N = number of gossiping nodes in the cluster).\nIf you find the propagation to be too slow, there are some tuning possibilities (default values are memberlist settings for LAN networks):\n Decrease gossip interval (default: 200ms) Increase gossip nodes (default 3) Decrease push/pull sync interval (default 30s) Increase retransmit multiplication factor (default 4) To find propagation delay, you can use cortex_ring_oldest_member_timestamp{state=\u0026quot;ACTIVE\u0026quot;} metric.\nFlags for configuring KV store based on memberlist library:\n memberlist.nodename Name of the node in memberlist cluster. Defaults to hostname. memberlist.randomize-node-name This flag adds extra random suffix to the node name used by memberlist. Defaults to true. Using random suffix helps to prevent issues when running multiple memberlist nodes on the same machine, or when node names are reused (eg. in stateful sets). memberlist.retransmit-factor Multiplication factor used when sending out messages (factor * log(N+1)). If not set, default value is used. memberlist.join Other cluster members to join. Can be specified multiple times. memberlist.min-join-backoff, memberlist.max-join-backoff, memberlist.max-join-retries These flags control backoff settings when joining the cluster. memberlist.abort-if-join-fails If this node fails to join memberlist cluster, abort. memberlist.rejoin-interval How often to try to rejoin the memberlist cluster. Defaults to 0, no rejoining. Occasional rejoin may be useful in some configurations, and is otherwise harmless. memberlist.left-ingesters-timeout How long to keep LEFT ingesters in the ring. Note: this is only used for gossiping, LEFT ingesters are otherwise invisible. memberlist.leave-timeout Timeout for leaving memberlist cluster. memberlist.gossip-interval How often to gossip with other cluster members. Uses memberlist LAN defaults if 0. memberlist.gossip-nodes How many nodes to gossip with in each gossip interval. Uses memberlist LAN defaults if 0. memberlist.pullpush-interval How often to use pull/push sync. Uses memberlist LAN defaults if 0. memberlist.bind-addr IP address to listen on for gossip messages. Multiple addresses may be specified. Defaults to 0.0.0.0. memberlist.bind-port Port to listen on for gossip messages. Defaults to 7946. memberlist.packet-dial-timeout Timeout used when connecting to other nodes to send packet. memberlist.packet-write-timeout Timeout for writing \u0026lsquo;packet\u0026rsquo; data. memberlist.transport-debug Log debug transport messages. Note: global log.level must be at debug level as well. memberlist.gossip-to-dead-nodes-time How long to keep gossiping to the nodes that seem to be dead. After this time, dead node is removed from list of nodes. If \u0026ldquo;dead\u0026rdquo; node appears again, it will simply join the cluster again, if its name is not reused by other node in the meantime. If the name has been reused, such a reanimated node will be ignored by other members. memberlist.dead-node-reclaim-time How soon can dead\u0026rsquo;s node name be reused by a new node (using different IP). Disabled by default, name reclaim is not allowed until gossip-to-dead-nodes-time expires. This can be useful to set to low numbers when reusing node names, eg. in stateful sets. If memberlist library detects that new node is trying to reuse the name of previous node, it will log message like this: Conflicting address for ingester-6. Mine: 10.44.12.251:7946 Theirs: 10.44.12.54:7946 Old state: 2. Node states are: \u0026ldquo;alive\u0026rdquo; = 0, \u0026ldquo;suspect\u0026rdquo; = 1 (doesn\u0026rsquo;t respond, will be marked as dead if it doesn\u0026rsquo;t respond), \u0026ldquo;dead\u0026rdquo; = 2. Multi KV This is a special key-value implementation that uses two different KV stores (eg. consul, etcd or memberlist). One of them is always marked as primary, and all reads and writes go to primary store. Other one, secondary, is only used for writes. The idea is that operator can use multi KV store to migrate from primary to secondary store in runtime.\nFor example, migration from Consul to Etcd would look like this:\n Set ring.store to use multi store. Set -multi.primary=consul and -multi.secondary=etcd. All consul and etcd settings must still be specified. Start all Cortex microservices. They will still use Consul as primary KV, but they will also write share ring via etcd. Operator can now use \u0026ldquo;runtime config\u0026rdquo; mechanism to switch primary store to etcd. After all Cortex microservices have picked up new primary store, and everything looks correct, operator can now shut down Consul, and modify Cortex configuration to use -ring.store=etcd only. At this point, Consul can be shut down. Multi KV has following parameters:\n multi.primary - name of primary KV store. Same values as in ring.store are supported, except multi. multi.secondary - name of secondary KV store. multi.mirror-enabled - enable mirroring of values to secondary store, defaults to true multi.mirror-timeout - wait max this time to write to secondary store to finish. Default to 2 seconds. Errors writing to secondary store are not reported to caller, but are logged and also reported via cortex_multikv_mirror_write_errors_total metric. Multi KV also reacts on changes done via runtime configuration. It uses this section:\nmulti_kv_config:mirror-enabled:falseprimary:memberlistNote that runtime configuration values take precedence over command line options.\nHA Tracker HA tracking has two of its own flags:\n distributor.ha-tracker.cluster Prometheus label to look for in samples to identify a Prometheus HA cluster. (default \u0026ldquo;cluster\u0026rdquo;) distributor.ha-tracker.replica Prometheus label to look for in samples to identify a Prometheus HA replica. (default \u0026ldquo;__replica__\u0026rdquo;) It\u0026rsquo;s reasonable to assume people probably already have a cluster label, or something similar. If not, they should add one along with __replica__ via external labels in their Prometheus config. If you stick to these default values your Prometheus config could look like this (POD_NAME is an environment variable which must be set by you):\nglobal:external_labels:cluster:clustername__replica__:$POD_NAMEHA Tracking looks for the two labels (which can be overwritten per user)\nIt also talks to a KVStore and has it\u0026rsquo;s own copies of the same flags used by the Distributor to connect to for the ring.\n distributor.ha-tracker.failover-timeout If we don\u0026rsquo;t receive any samples from the accepted replica for a cluster in this amount of time we will failover to the next replica we receive a sample from. This value must be greater than the update timeout (default 30s) distributor.ha-tracker.store Backend storage to use for the ring (consul, etcd, inmemory, multi). Inmemory only works if there is a single distributor and ingester running in the same process (for testing purposes). (default \u0026ldquo;consul\u0026rdquo;) distributor.ha-tracker.update-timeout Update the timestamp in the KV store for a given cluster/replica only after this amount of time has passed since the current stored timestamp. (default 15s) Ingester -ingester.max-chunk-age\nThe maximum duration of a timeseries chunk in memory. If a timeseries runs for longer than this the current chunk will be flushed to the store and a new chunk created. (default 12h)\n -ingester.max-chunk-idle\nIf a series doesn\u0026rsquo;t receive a sample for this duration, it is flushed and removed from memory.\n -ingester.max-stale-chunk-idle\nIf a series receives a staleness marker, then we wait for this duration to get another sample before we close and flush this series, removing it from memory. You want it to be at least 2x the scrape interval as you don\u0026rsquo;t want a single failed scrape to cause a chunk flush.\n -ingester.chunk-age-jitter\nTo reduce load on the database exactly 12 hours after starting, the age limit is reduced by a varying amount up to this. Don\u0026rsquo;t enable this along with -ingester.spread-flushes (default 0m)\n -ingester.spread-flushes\nMakes the ingester flush each timeseries at a specific point in the max-chunk-age cycle. This means multiple replicas of a chunk are very likely to contain the same contents which cuts chunk storage space by up to 66%. Set -ingester.chunk-age-jitter to 0 when using this option. If a chunk cache is configured (via -store.chunks-cache.memcached.hostname) then duplicate chunk writes are skipped which cuts write IOPs.\n -ingester.join-after\nHow long to wait in PENDING state during the hand-over process (supported only by the chunks storage). (default 0s)\n -ingester.max-transfer-retries\nHow many times a LEAVING ingester tries to find a PENDING ingester during the hand-over process (supported only by the chunks storage). Negative value or zero disables hand-over process completely. (default 10)\n -ingester.normalise-tokens\nDeprecated. New ingesters always write \u0026ldquo;normalised\u0026rdquo; tokens to the ring. Normalised tokens consume less memory to encode and decode; as the ring is unmarshalled regularly, this significantly reduces memory usage of anything that watches the ring.\nCortex 0.4.0 is the last version that can write denormalised tokens. Cortex 0.5.0 and above always write normalised tokens.\nCortex 0.6.0 is the last version that can read denormalised tokens. Starting with Cortex 0.7.0 only normalised tokens are supported, and ingesters writing denormalised tokens to the ring (running Cortex 0.4.0 or earlier with -ingester.normalise-tokens=false) are ignored by distributors. Such ingesters should either switch to using normalised tokens, or be upgraded to Cortex 0.5.0 or later.\n -ingester.chunk-encoding\nPick one of the encoding formats for timeseries data, which have different performance characteristics. Bigchunk uses the Prometheus V2 code, and expands in memory to arbitrary length. Varbit, Delta and DoubleDelta use Prometheus V1 code, and are fixed at 1K per chunk. Defaults to Bigchunk starting version 0.7.0.\n -store.bigchunk-size-cap-bytes\nWhen using bigchunks, start a new bigchunk and flush the old one if the old one reaches this size. Use this setting to limit memory growth of ingesters with a lot of timeseries that last for days.\n -ingester-client.expected-timeseries\nWhen push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. This should match the max_samples_per_send in your queue_config for Prometheus.\n -ingester-client.expected-samples-per-series\nWhen push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. Under normal conditions, Prometheus scrapes should arrive with one sample per series.\n -ingester-client.expected-labels\nWhen push requests arrive, pre-allocate this many slots to decode them. Tune this setting to reduce memory allocations and garbage. The optimum value will depend on how many labels are sent with your timeseries samples.\n -store.chunk-cache.cache-stubs\nWhere you don\u0026rsquo;t want to cache every chunk written by ingesters, but you do want to take advantage of chunk write deduplication, this option will make ingesters write a placeholder to the cache for each chunk. Make sure you configure ingesters with a different cache to queriers, which need the whole value.\n WAL -ingester.wal-dir Directory where the WAL data should be stored and/or recovered from.\n -ingester.wal-enabled\nSetting this to true enables writing to WAL during ingestion.\n -ingester.checkpoint-duration This is the interval at which checkpoints should be created.\n -ingester.recover-from-wal Set this to true to recover data from an existing WAL. The data is recovered even if WAL is disabled and this is set to true. The WAL dir needs to be set for this.\n Flusher -flusher.wal-dir Directory where the WAL data should be recovered from.\n -flusher.concurrent-flushes Number of concurrent flushes.\n -flusher.flush-op-timeout Duration after which a flush should timeout.\n Runtime Configuration file Cortex has a concept of \u0026ldquo;runtime config\u0026rdquo; file, which is simply a file that is reloaded while Cortex is running. It is used by some Cortex components to allow operator to change some aspects of Cortex configuration without restarting it. File is specified by using -runtime-config.file=\u0026lt;filename\u0026gt; flag and reload period (which defaults to 10 seconds) can be changed by -runtime-config.reload-period=\u0026lt;duration\u0026gt; flag. Previously this mechanism was only used by limits overrides, and flags were called -limits.per-user-override-config=\u0026lt;filename\u0026gt; and -limits.per-user-override-period=10s respectively. These are still used, if -runtime-config.file=\u0026lt;filename\u0026gt; is not specified.\nAt the moment, two components use runtime configuration: limits and multi KV store.\nExample runtime configuration file:\noverrides:tenant1:ingestion_rate:10000max_series_per_metric:100000max_series_per_query:100000tenant2:max_samples_per_query:1000000max_series_per_metric:100000max_series_per_query:100000multi_kv_config:mirror-enabled:falseprimary:memberlistWhen running Cortex on Kubernetes, store this file in a config map and mount it in each services\u0026rsquo; containers. When changing the values there is no need to restart the services, unless otherwise specified.\nIngester, Distributor \u0026amp; Querier limits. Cortex implements various limits on the requests it can process, in order to prevent a single tenant overwhelming the cluster. There are various default global limits which apply to all tenants which can be set on the command line. These limits can also be overridden on a per-tenant basis by using overrides field of runtime configuration file.\nThe overrides field is a map of tenant ID (same values as passed in the X-Scope-OrgID header) to the various limits. An example could look like:\noverrides:tenant1:ingestion_rate:10000max_series_per_metric:100000max_series_per_query:100000tenant2:max_samples_per_query:1000000max_series_per_metric:100000max_series_per_query:100000Valid per-tenant limits are (with their corresponding flags for default values):\n ingestion_rate_strategy / -distributor.ingestion-rate-limit-strategy\n ingestion_rate / -distributor.ingestion-rate-limit\n ingestion_burst_size / -distributor.ingestion-burst-size\nThe per-tenant rate limit (and burst size), in samples per second. It supports two strategies: local (default) and global.\nThe local strategy enforces the limit on a per distributor basis, actual effective rate limit will be N times higher, where N is the number of distributor replicas.\nThe global strategy enforces the limit globally, configuring a per-distributor local rate limiter as ingestion_rate / N, where N is the number of distributor replicas (it\u0026rsquo;s automatically adjusted if the number of replicas change). The ingestion_burst_size refers to the per-distributor local rate limiter (even in the case of the global strategy) and should be set at least to the maximum number of samples expected in a single push request. For this reason, the global strategy requires that push requests are evenly distributed across the pool of distributors; if you use a load balancer in front of the distributors you should be already covered, while if you have a custom setup (ie. an authentication gateway in front) make sure traffic is evenly balanced across distributors.\nThe global strategy requires the distributors to form their own ring, which is used to keep track of the current number of healthy distributor replicas. The ring is configured by distributor: { ring: {}} / -distributor.ring.*.\n max_label_name_length / -validation.max-length-label-name\n max_label_value_length / -validation.max-length-label-value\n max_label_names_per_series / -validation.max-label-names-per-series\nAlso enforced by the distributor, limits on the on length of labels and their values, and the total number of labels allowed per series.\n reject_old_samples / -validation.reject-old-samples\n reject_old_samples_max_age / -validation.reject-old-samples.max-age\n creation_grace_period / -validation.create-grace-period\nAlso enforce by the distributor, limits on how far in the past (and future) timestamps that we accept can be.\n max_series_per_user / -ingester.max-series-per-user\n max_series_per_metric / -ingester.max-series-per-metric\nEnforced by the ingesters; limits the number of active series a user (or a given metric) can have. When running with -distributor.shard-by-all-labels=false (the default), this limit will enforce the maximum number of series a metric can have \u0026lsquo;globally\u0026rsquo;, as all series for a single metric will be sent to the same replication set of ingesters. This is not the case when running with -distributor.shard-by-all-labels=true, so the actual limit will be N/RF times higher, where N is number of ingester replicas and RF is configured replication factor.\nAn active series is a series to which a sample has been written in the last -ingester.max-chunk-idle duration, which defaults to 5 minutes.\n max_global_series_per_user / -ingester.max-global-series-per-user\n max_global_series_per_metric / -ingester.max-global-series-per-metric\nLike max_series_per_user and max_series_per_metric, but the limit is enforced across the cluster. Each ingester is configured with a local limit based on the replication factor, the -distributor.shard-by-all-labels setting and the current number of healthy ingesters, and is kept updated whenever the number of ingesters change.\nRequires -distributor.replication-factor and -distributor.shard-by-all-labels set for the ingesters too.\n max_series_per_query / -ingester.max-series-per-query\n max_samples_per_query / -ingester.max-samples-per-query\nLimits on the number of timeseries and samples returns by a single ingester during a query.\n Storage s3.force-path-style\nSet this to true to force the request to use path-style addressing (http://s3.amazonaws.com/BUCKET/KEY). By default, the S3 client will use virtual hosted bucket addressing when possible (http://BUCKET.s3.amazonaws.com/KEY).\n DNS Service Discovery Some clients in Cortex support service discovery via DNS to find addresses of backend servers to connect to (ie. caching servers). The clients supporting it are:\n Blocks storage\u0026rsquo;s memcached cache All caching memcached servers Memberlist KV store Supported discovery modes The DNS service discovery, inspired from Thanos DNS SD, supports different discovery modes. A discovery mode is selected adding a specific prefix to the address. The supported prefixes are:\n dns+\nThe domain name after the prefix is looked up as an A/AAAA query. For example: dns+memcached.local:11211 dnssrv+\nThe domain name after the prefix is looked up as a SRV query, and then each SRV record is resolved as an A/AAAA record. For example: dnssrv+_memcached._tcp.memcached.namespace.svc.cluster.local dnssrvnoa+\nThe domain name after the prefix is looked up as a SRV query, with no A/AAAA lookup made after that. For example: dnssrvnoa+_memcached._tcp.memcached.namespace.svc.cluster.local Logging of IP of reverse proxy If a reverse proxy is used in front of Cortex it might be diffult to troubleshoot errors. The following 3 settings can be used to log the IP address passed along by the reverse proxy in headers like X-Forwarded-For.\n -server.log_source_ips_enabled\nSet this to true to add logging of the IP when a Forwarded, X-Real-IP or X-Forwarded-For header is used. A field called sourceIPs will be added to error logs when data is pushed into Cortex.\n -server.log-source-ips-header\nHeader field storing the source IPs. It is only used if -server.log-source-ips-enabled is true and if -server.log-source-ips-regex is set. If not set the default Forwarded, X-Real-IP or X-Forwarded-For headers are searched.\n -server.log-source-ips-regex\nRegular expression for matching the source IPs. It should contain at least one capturing group the first of which will be returned. Only used if -server.log-source-ips-enabled is true and if -server.log-source-ips-header is set. If not set the default Forwarded, X-Real-IP or X-Forwarded-For headers are searched.\n ","excerpt":"General Notes Cortex has evolved over several years, and the command-line options sometimes reflect …","ref":"/docs/configuration/arguments/","title":"Cortex Arguments"},{"body":"Cortex adopts some design patterns and code conventions that we ask you to follow when contributing to the project. These conventions have been adopted based on the experience gained over the time and aim to enforce good coding practices and keep a consistent UX (ie. config).\nGo coding style Cortex follows the Go Code Review Comments styleguide and the Formatting and style section of Peter Bourgon\u0026rsquo;s Go: Best Practices for Production Environments.\nNo global variables Do not use global variables Prometheus metrics When registering a metric:\n Do not use a global variable for the metric Create and register the metric with promauto.With(reg) In any internal Cortex component, do not register the metric to the default prometheus registerer, but pick the registerer in input (ie. NewComponent(reg prometheus.Registerer)) Testing metrics:\n When writing using tests, test exported metrics using testutil.GatherAndCompare() Config file and CLI flags conventions Naming:\n Config file options should be lowercase with words _ (underscore) separated (ie. memcached_client) CLI flags should be lowercase with words - (dash) separated (ie. memcached-client) When adding a new config option, look if a similar one already exists within the config and keep the same naming (ie. addresses for a list of network endpoints) Documentation:\n A CLI flag mentioned in the documentation or changelog should be always prefixed with a single - (dash) ","excerpt":"Cortex adopts some design patterns and code conventions that we ask you to follow when contributing …","ref":"/docs/contributing/design-patterns-and-code-conventions/","title":"Design patterns and Code conventions"},{"body":"Cortex requires Key-Value (KV) store to store the ring. It can use traditional KV stores like Consul or Etcd, but it can also build its own KV store on top of memberlist library using a gossip algorithm.\nThis short guide shows how to start Cortex in single-binary mode with memberlist-based ring. To reduce number of required dependencies in this guide, it will use blocks storage with no shipping to external stores. Storage engine and external storage configuration are not dependant on the ring configuration.\nSingle-binary, two Cortex instances For simplicity and to get started, we\u0026rsquo;ll run it as a two instances of Cortex on local computer. We will use prepared configuration files (file 1, file 2), with no external dependencies.\nBuild Cortex first:\n$ go build ./cmd/cortex Run two instances of Cortex, each one with its own dedicated config file:\n$ ./cortex -config.file docs/configuration/single-process-config-blocks-gossip-1.yaml $ ./cortex -config.file docs/configuration/single-process-config-blocks-gossip-2.yaml Download Prometheus and configure it to use our first Cortex instance for remote writes.\nremote_write:- url:http://localhost:9109/api/prom/pushAfter starting Prometheus, it will now start pushing data to Cortex. Distributor component in Cortex will distribute incoming samples between the two instances.\nTo query that data, you can configure your Grafana instance to use http://localhost:9109/api/prom (first Cortex) as a Prometheus data source.\nHow it works The two instances we started earlier should be able to find each other via memberlist configuration (already present in the config files):\nmemberlist:# defaults to hostnamenode_name:\u0026#34;Ingester 1\u0026#34;bind_port:7946join_members:- localhost:7947abort_if_cluster_join_fails:falseThis tells memberlist to listen on port 7946, and connect to localhost:7947, which is the second instance. Port numbers are reversed in the second configuration file. We also need to configure node_name and also ingester ID (ingester.lifecycler.id field), because default to hostname, but we are running both Cortex instances on the same host.\nTo make sure that both ingesters generate unique tokens, we configure join_after and observe_period to 10 seconds. First option tells Cortex to wait 10 seconds before joining the ring. This option is normally used to tell Cortex ingester how long to wait for a potential tokens and data transfer from leaving ingester, but we also use it here to increase the chance of finding other gossip peers. When Cortex joins the ring, it generates tokens and writes them to the ring. If multiple Cortex instances do this at the same time, they can generate conflicting tokens. This can be a problem when using gossiped ring (instances may simply not see each other yet), so we use observe_period to watch the ring for token conflicts. If conflict is detected, new tokens are generated instead of conflicting tokens, and observe period is restarted. If no conflict is detected within the observe period, ingester switches to ACTIVE state.\nWe are able to observe ring state on http://localhost:9109/ring and http://localhost:9209/ring. The two instances may see slightly different views (eg. different timestamps), but should converge to a common state soon, with both instances being ACTIVE and ready to receive samples.\nHow to add another instance? To add another Cortex to the small cluster, copy docs/configuration/single-process-config-blocks-gossip-1.yaml to a new file, and make following modifications. We assume that third Cortex will run on the same machine again, so we change node name and ingester ID as well. Here is annotated diff:\n... server: + # These ports need to be unique. - http_listen_port: 9109 - grpc_listen_port: 9195 + http_listen_port: 9309 + grpc_listen_port: 9395 ... ingester: lifecycler: # Defaults to hostname, but we run both ingesters in this demonstration on the same machine. - id: \u0026#34;Ingester 1\u0026#34; + id: \u0026#34;Ingester 3\u0026#34; ... memberlist: # defaults to hostname - node_name: \u0026#34;Ingester 1\u0026#34; + node_name: \u0026#34;Ingester 3\u0026#34; # bind_port needs to be unique - bind_port: 7946 + bind_port: 7948 ... +# Directory names in the `blocks_storage` \u0026gt; `tsdb` config ending with `...1` to end with `...3`. This is to avoid different instances +# writing in-progress data to the same directories. blocks_storage: tsdb: - dir: /tmp/cortex/tsdb-ing1 + dir: /tmp/cortex/tsdb-ing3 bucket_store: - sync_dir: /tmp/cortex/tsdb-sync-querier1 + sync_dir: /tmp/cortex/tsdb-sync-querier3 ... We don\u0026rsquo;t need to change or add memberlist.join_members list. This new instance will simply join to the second one (listening on port 7947), and will discover other peers through it. When using kubernetes, suggested setup is to have a headless service pointing to all pods that want to be part of gossip cluster, and then point join_members to this headless service.\nWe also don\u0026rsquo;t need to change /tmp/cortex/storage directory in blocks_storage.filesystem.dir field. This is directory where all ingesters will \u0026ldquo;upload\u0026rdquo; finished blocks. This can also be an S3 or GCP storage, but for simplicity, we use local filesystem in this example.\nAfter these changes, we can start another Cortex instance using the modified configuration file. This instance will join the ring and will start receiving samples after it enters into ACTIVE state.\n","excerpt":"Cortex requires Key-Value (KV) store to store the ring. It can use traditional KV stores like Consul …","ref":"/docs/getting-started/getting-started-with-gossiped-ring/","title":"Getting Started with Gossiped Ring"},{"body":"New maintainers are proposed by an existing maintainer and are elected by majority vote. Once the vote passed, the following steps should be done to add a new member to the maintainers team:\n Submit a PR to add the new member to MAINTAINERS Invite to GitHub organization Invite to cortex-team group Invite to Quay.io repository Invite to Docker Hub organization Invite to CNCF cncf-cortex-maintainers mailing list (via CNCF Service Desk) Add to the Google Analytics property used for the website statistics ","excerpt":"New maintainers are proposed by an existing maintainer and are elected by majority vote. Once the …","ref":"/docs/governance/how-to-add-a-maintainer/","title":"How to add a maintainer"},{"body":"The querier service handles queries using the PromQL query language. The querier service is used both by the chunks and blocks storage, and the general architecture documentation applies to the blocks storage too, except for the differences described in this document.\nThe querier is stateless.\nHow it works At startup queriers iterate over the entire storage bucket to discover all tenants blocks and download the meta.json for each block. During this initial bucket scanning phase, a querier is not ready to handle incoming queries yet and its /ready readiness probe endpoint will fail.\nWhile running, queriers periodically iterate over the storage bucket to discover new tenants and recently uploaded blocks. Queriers do not download any content from blocks except a small meta.json file containing the block\u0026rsquo;s metadata (including the minimum and maximum timestamp of samples within the block).\nQueriers use the metadata to compute the list of blocks that need to be queried at query time and fetch matching series from the store-gateway instances holding the required blocks.\nAnatomy of a query request When a querier receives a query range request, it contains the following parameters:\n query: the PromQL query expression itself (e.g. rate(node_cpu_seconds_total[1m])) start: the start time end: the end time step: the query resolution (e.g. 30 to have 1 resulting data point every 30s) Given a query, the querier analyzes the start and end time range to compute a list of all known blocks containing at least 1 sample within this time range. Given the list of blocks, the querier then computes a list of store-gateway instances holding these blocks and sends a request to each matching store-gateway instance asking to fetch all the samples for the series matching the query within the start and end time range.\nThe request sent to each store-gateway contains the list of block IDs that are expected to be queried, and the response sent back by the store-gateway to the querier contains the list of block IDs that were actually queried. This list may be a subset of the requested blocks, for example due to recent blocks resharding event (ie. last few seconds). The querier runs a consistency check on responses received from the store-gateways to ensure all expected blocks have been queried; if not, the querier retries to fetch samples from missing blocks from different store-gateways (if the -store-gateway.sharding-ring.replication-factor is greater than 1) and if the consistency check fails after all retries, the query execution fails as well (correctness is always guaranteed).\nIf the query time range covers a period within -querier.query-ingesters-within duration, the querier also sends the request to all ingesters, in order to fetch samples that have not been uploaded to the long-term storage yet.\nOnce all samples have been fetched from both store-gateways and ingesters, the querier proceeds with running the PromQL engine to execute the query and send back the result to the client.\nHow queriers connect to store-gateway Queriers need to discover store-gateways in order to connect to them at query time. The service discovery mechanism used depends whether blocks sharding is enabled in the store-gateways.\nWhen blocks sharding is enabled, queriers need to access to the store-gateways hash ring and thus queriers need to be configured with the same -store-gateway.sharding-ring.* flags (or their respective YAML config options) store-gateways have been configured.\nWhen blocks sharding is disabled, queriers need the -querier.store-gateway-addresses CLI flag (or its respective YAML config option) being set to a comma separated list of store-gateway addresses in DNS Service Discovery format. Queriers will evenly balance the requests to query blocks across the resolved addresses.\nCaching The querier supports the following caches:\n Metadata cache Caching is optional, but highly recommended in a production environment. Please also check out the production tips for more information about configuring the cache.\nMetadata cache Store-gateway and querier can use memcached for caching bucket metadata:\n List of tenants List of blocks per tenant Block\u0026rsquo;s meta.json content Block\u0026rsquo;s deletion-mark.json existence and content Using the metadata cache can significantly reduce the number of API calls to object storage and protects from linearly scale the number of these API calls with the number of querier and store-gateway instances (because the bucket is periodically scanned and synched by each querier and store-gateway).\nTo enable metadata cache, please set -blocks-storage.bucket-store.metadata-cache.backend. Only memcached backend is supported currently. Memcached client has additional configuration available via flags with -blocks-storage.bucket-store.metadata-cache.memcached.* prefix.\nAdditional options for configuring metadata cache have -blocks-storage.bucket-store.metadata-cache.* prefix. By configuring TTL to zero or negative value, caching of given item type is disabled.\nThe same memcached backend cluster should be shared between store-gateways and queriers.\nQuerier configuration This section described the querier configuration. For the general Cortex configuration and references to common config blocks, please refer to the configuration documentation.\nquerier_config The querier_config configures the Cortex querier.\nquerier:# The maximum number of concurrent queries.# CLI flag: -querier.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=20]# The timeout for a query.# CLI flag: -querier.timeout[timeout:\u0026lt;duration\u0026gt;|default=2m]# Use iterators to execute query, as opposed to fully materialising the series# in memory.# CLI flag: -querier.iterators[iterators:\u0026lt;boolean\u0026gt;|default=false]# Use batch iterators to execute query, as opposed to fully materialising the# series in memory. Takes precedent over the -querier.iterators flag.# CLI flag: -querier.batch-iterators[batch_iterators:\u0026lt;boolean\u0026gt;|default=true]# Use streaming RPCs to query ingester.# CLI flag: -querier.ingester-streaming[ingester_streaming:\u0026lt;boolean\u0026gt;|default=true]# Maximum number of samples a single query can load into memory.# CLI flag: -querier.max-samples[max_samples:\u0026lt;int\u0026gt;|default=50000000]# Maximum lookback beyond which queries are not sent to ingester. 0 means all# queries are sent to ingester.# CLI flag: -querier.query-ingesters-within[query_ingesters_within:\u0026lt;duration\u0026gt;|default=0s]# The time after which a metric should only be queried from storage and not# just ingesters. 0 means all queries are sent to store. When running the# blocks storage, if this option is enabled, the time range of the query sent# to the store will be manipulated to ensure the query end is not more recent# than \u0026#39;now - query-store-after\u0026#39;.# CLI flag: -querier.query-store-after[query_store_after:\u0026lt;duration\u0026gt;|default=0s]# Maximum duration into the future you can query. 0 to disable.# CLI flag: -querier.max-query-into-future[max_query_into_future:\u0026lt;duration\u0026gt;|default=10m]# The default evaluation interval or step size for subqueries.# CLI flag: -querier.default-evaluation-interval[default_evaluation_interval:\u0026lt;duration\u0026gt;|default=1m]# Active query tracker monitors active queries, and writes them to the file in# given directory. If Cortex discovers any queries in this log during startup,# it will log them to the log file. Setting to empty value disables active# query tracker, which also disables -querier.max-concurrent option.# CLI flag: -querier.active-query-tracker-dir[active_query_tracker_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./active-query-tracker\u0026#34;]# Time since the last sample after which a time series is considered stale and# ignored by expression evaluations.# CLI flag: -querier.lookback-delta[lookback_delta:\u0026lt;duration\u0026gt;|default=5m]# Comma separated list of store-gateway addresses in DNS Service Discovery# format. This option should be set when using the blocks storage and the# store-gateway sharding is disabled (when enabled, the store-gateway# instances form a ring and addresses are picked from the ring).# CLI flag: -querier.store-gateway-addresses[store_gateway_addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]store_gateway_client:# Path to the client certificate file, which will be used for authenticating# with the server. Also requires the key path to be configured.# CLI flag: -querier.store-gateway-client.tls-cert-path[tls_cert_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the key file for the client certificate. Also requires the client# certificate to be configured.# CLI flag: -querier.store-gateway-client.tls-key-path[tls_key_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Path to the CA certificates file to validate server certificate against.# If not set, the host\u0026#39;s root CA certificates are used.# CLI flag: -querier.store-gateway-client.tls-ca-path[tls_ca_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Skip validating server certificate.# CLI flag: -querier.store-gateway-client.tls-insecure-skip-verify[tls_insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]# Second store engine to use for querying. Empty = disabled.# CLI flag: -querier.second-store-engine[second_store_engine:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If specified, second store is only used for queries before this timestamp.# Default value 0 means secondary store is always queried.# CLI flag: -querier.use-second-store-before-time[use_second_store_before_time:\u0026lt;time\u0026gt;|default=0]blocks_storage_config The blocks_storage_config configures the blocks storage.\nblocks_storage:# Backend storage to use. Supported backends are: s3, gcs, azure, filesystem.# CLI flag: -blocks-storage.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;s3\u0026#34;]s3:# The S3 bucket endpoint. It could be an AWS S3 endpoint listed at# https://docs.aws.amazon.com/general/latest/gr/s3.html or the address of an# S3-compatible service in hostname:port format.# CLI flag: -blocks-storage.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 bucket name# CLI flag: -blocks-storage.s3.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 secret access key# CLI flag: -blocks-storage.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 access key ID# CLI flag: -blocks-storage.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If enabled, use http:// for the S3 endpoint instead of https://. This# could be useful in local dev/test environments while using an# S3-compatible backend storage, like Minio.# CLI flag: -blocks-storage.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]http:# The time an idle connection will remain idle before closing.# CLI flag: -blocks-storage.s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# The amount of time the client will wait for a servers response headers.# CLI flag: -blocks-storage.s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=2m]# If the client connects to S3 via HTTPS and this option is enabled, the# client will accept any certificate and hostname.# CLI flag: -blocks-storage.s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]gcs:# GCS bucket name# CLI flag: -blocks-storage.gcs.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# JSON representing either a Google Developers Console# client_credentials.json file or a Google Developers service account key# file. If empty, fallback to Google default logic.# CLI flag: -blocks-storage.gcs.service-account[service_account:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]azure:# Azure storage account name# CLI flag: -blocks-storage.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage account key# CLI flag: -blocks-storage.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage container name# CLI flag: -blocks-storage.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage endpoint suffix without schema. The account name will be# prefixed to this value to create the FQDN# CLI flag: -blocks-storage.azure.endpoint-suffix[endpoint_suffix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of retries for recoverable errors# CLI flag: -blocks-storage.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]filesystem:# Local filesystem storage directory.# CLI flag: -blocks-storage.filesystem.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# This configures how the store-gateway synchronizes blocks stored in the# bucket.bucket_store:# Directory to store synchronized TSDB index headers.# CLI flag: -blocks-storage.bucket-store.sync-dir[sync_dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb-sync\u0026#34;]# How frequently scan the bucket to look for changes (new blocks shipped by# ingesters and blocks removed by retention or compaction). 0 disables it.# CLI flag: -blocks-storage.bucket-store.sync-interval[sync_interval:\u0026lt;duration\u0026gt;|default=5m]# Max size - in bytes - of a per-tenant chunk pool, used to reduce memory# allocations.# CLI flag: -blocks-storage.bucket-store.max-chunk-pool-bytes[max_chunk_pool_bytes:\u0026lt;int\u0026gt;|default=2147483648]# Max number of concurrent queries to execute against the long-term storage.# The limit is shared across all tenants.# CLI flag: -blocks-storage.bucket-store.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=100]# Maximum number of concurrent tenants synching blocks.# CLI flag: -blocks-storage.bucket-store.tenant-sync-concurrency[tenant_sync_concurrency:\u0026lt;int\u0026gt;|default=10]# Maximum number of concurrent blocks synching per tenant.# CLI flag: -blocks-storage.bucket-store.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from object# storage per tenant.# CLI flag: -blocks-storage.bucket-store.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of a block before it\u0026#39;s being read. Set it to safe value (e.g# 30m) if your object storage is eventually consistent. GCS and S3 are# (roughly) strongly consistent.# CLI flag: -blocks-storage.bucket-store.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]index_cache:# The index cache backend type. Supported values: inmemory, memcached.# CLI flag: -blocks-storage.bucket-store.index-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;inmemory\u0026#34;]inmemory:# Maximum size in bytes of in-memory index cache used to speed up blocks# index lookups (shared between all tenants).# CLI flag: -blocks-storage.bucket-store.index-cache.inmemory.max-size-bytes[max_size_bytes:\u0026lt;int\u0026gt;|default=1073741824]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Compress postings before storing them to postings cache.# CLI flag: -blocks-storage.bucket-store.index-cache.postings-compression-enabled[postings_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]chunks_cache:# Backend for chunks cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.chunks-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Size of each subrange that bucket object is split into for better# caching.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-size[subrange_size:\u0026lt;int\u0026gt;|default=16000]# Maximum number of sub-GetRange requests that a single GetRange request# can be split into when fetching chunks. Zero or negative value =# unlimited number of sub-requests.# CLI flag: -blocks-storage.bucket-store.chunks-cache.max-get-range-requests[max_get_range_requests:\u0026lt;int\u0026gt;|default=3]# TTL for caching object attributes for chunks.# CLI flag: -blocks-storage.bucket-store.chunks-cache.attributes-ttl[attributes_ttl:\u0026lt;duration\u0026gt;|default=24h]# TTL for caching individual chunks subranges.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-ttl[subrange_ttl:\u0026lt;duration\u0026gt;|default=24h]metadata_cache:# Backend for metadata cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.metadata-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# How long to cache list of tenants in the bucket.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenants-list-ttl[tenants_list_ttl:\u0026lt;duration\u0026gt;|default=15m]# How long to cache list of blocks for each tenant.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenant-blocks-list-ttl[tenant_blocks_list_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache list of chunks for a block.# CLI flag: -blocks-storage.bucket-store.metadata-cache.chunks-list-ttl[chunks_list_ttl:\u0026lt;duration\u0026gt;|default=24h]# How long to cache information that block metafile exists.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-exists-ttl[metafile_exists_ttl:\u0026lt;duration\u0026gt;|default=2h]# How long to cache information that block metafile doesn\u0026#39;t exist.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-doesnt-exist-ttl[metafile_doesnt_exist_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache content of the metafile.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-content-ttl[metafile_content_ttl:\u0026lt;duration\u0026gt;|default=24h]# Maximum size of metafile content to cache in bytes.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-max-size-bytes[metafile_max_size_bytes:\u0026lt;int\u0026gt;|default=1048576]# Duration after which the blocks marked for deletion will be filtered out# while fetching blocks. The idea of ignore-deletion-marks-delay is to# ignore blocks that are marked for deletion with some delay. This ensures# store can still serve blocks that are meant to be deleted but do not have# a replacement yet. Default is 6h, half of the default value for# -compactor.deletion-delay.# CLI flag: -blocks-storage.bucket-store.ignore-deletion-marks-delay[ignore_deletion_mark_delay:\u0026lt;duration\u0026gt;|default=6h]tsdb:# Local directory to store TSDBs in the ingesters.# CLI flag: -blocks-storage.tsdb.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb\u0026#34;]# TSDB blocks range period.# CLI flag: -blocks-storage.tsdb.block-ranges-period[block_ranges_period:\u0026lt;listofduration\u0026gt;|default=2h0m0s]# TSDB blocks retention in the ingester before a block is removed. This# should be larger than the block_ranges_period and large enough to give# store-gateways and queriers enough time to discover newly uploaded blocks.# CLI flag: -blocks-storage.tsdb.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=6h]# How frequently the TSDB blocks are scanned and new ones are shipped to the# storage. 0 means shipping is disabled.# CLI flag: -blocks-storage.tsdb.ship-interval[ship_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently shipping blocks to the storage.# CLI flag: -blocks-storage.tsdb.ship-concurrency[ship_concurrency:\u0026lt;int\u0026gt;|default=10]# How frequently does Cortex try to compact TSDB head. Block is only created# if data covers smallest block range. Must be greater than 0 and max 5# minutes.# CLI flag: -blocks-storage.tsdb.head-compaction-interval[head_compaction_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently compacting TSDB head into a new# block# CLI flag: -blocks-storage.tsdb.head-compaction-concurrency[head_compaction_concurrency:\u0026lt;int\u0026gt;|default=5]# If TSDB head is idle for this duration, it is compacted. 0 means disabled.# CLI flag: -blocks-storage.tsdb.head-compaction-idle-timeout[head_compaction_idle_timeout:\u0026lt;duration\u0026gt;|default=1h]# The number of shards of series to use in TSDB (must be a power of 2).# Reducing this will decrease memory footprint, but can negatively impact# performance.# CLI flag: -blocks-storage.tsdb.stripe-size[stripe_size:\u0026lt;int\u0026gt;|default=16384]# True to enable TSDB WAL compression.# CLI flag: -blocks-storage.tsdb.wal-compression-enabled[wal_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]# True to flush blocks to storage on shutdown. If false, incomplete blocks# will be reused after restart.# CLI flag: -blocks-storage.tsdb.flush-blocks-on-shutdown[flush_blocks_on_shutdown:\u0026lt;boolean\u0026gt;|default=false]# limit the number of concurrently opening TSDB\u0026#39;s on startup# CLI flag: -blocks-storage.tsdb.max-tsdb-opening-concurrency-on-startup[max_tsdb_opening_concurrency_on_startup:\u0026lt;int\u0026gt;|default=10]","excerpt":"The querier service handles queries using the PromQL query language. The querier service is used …","ref":"/docs/blocks-storage/querier/","title":"Querier"},{"body":"The query auditor is a tool bundled in the Cortex repository, but not included in Docker images \u0026ndash; this must be built from source. It\u0026rsquo;s primarily useful for those developing Cortex, but can be helpful to operators as well during certain scenarios (backend migrations come to mind).\nHow it works The query-audit tool performs a set of queries against two backends that expose the Prometheus read API. This is generally the query-frontend component of two Cortex deployments. It will then compare the differences in the responses to determine the average difference for each query. It does this by:\n Ensuring the resulting label sets match. For each label set, ensuring they contain the same number of samples as their pair from the other backend. For each sample, calculates their difference against it\u0026rsquo;s pair from the other backend/label set. Calculates the average diff per query from the above diffs. Limitations It currently only supports queries with Matrix response types.\nUse cases Correctness testing when working on the read path. Comparing results from different backends. Example Configuration control:host:http://localhost:8080/api/promheaders:\u0026#34;X-Scope-OrgID\u0026#34;: 1234test:host:http://localhost:8081/api/promheaders:\u0026#34;X-Scope-OrgID\u0026#34;: 1234queries:- query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m]))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-28T00:00:00Zstep_size:15m- query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m])) by (container_name)\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-28T00:00:00Zstep_size:15m- query:\u0026#39;sum(rate(container_cpu_usage_seconds_total[5m])) without (container_name)\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-26T00:00:00Zstep_size:15m- query:\u0026#39;histogram_quantile(0.9, sum(rate(cortex_cache_value_size_bytes_bucket[5m])) by (le, job))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15m# two shardable legs- query:\u0026#39;sum without (instance, job) (rate(cortex_query_frontend_queue_length[5m])) or sum by (job) (rate(cortex_query_frontend_queue_length[5m]))\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15m# one shardable leg- query:\u0026#39;sum without (instance, job) (rate(cortex_cache_request_duration_seconds_count[5m])) or rate(cortex_cache_request_duration_seconds_count[5m])\u0026#39;start:2019-11-25T00:00:00Zend:2019-11-25T06:00:00Zstep_size:15mExample Output Under ideal circumstances, you\u0026rsquo;ll see output like the following:\n$ go run ./tools/query-audit/ -f config.yaml 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) series: 1 samples: 289 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-28 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) by (container_name) series: 95 samples: 25877 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-28 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum(rate(container_cpu_usage_seconds_total[5m])) without (container_name) series: 4308 samples: 374989 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-26 00:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: histogram_quantile(0.9, sum(rate(cortex_cache_value_size_bytes_bucket[5m])) by (le, job)) series: 13 samples: 325 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum without (instance, job) (rate(cortex_query_frontend_queue_length[5m])) or sum by (job) (rate(cortex_query_frontend_queue_length[5m])) series: 21 samples: 525 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum without (instance, job) (rate(cortex_cache_request_duration_seconds_count[5m])) or rate(cortex_cache_request_duration_seconds_count[5m]) series: 942 samples: 23550 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum by (namespace) (predict_linear(container_cpu_usage_seconds_total[5m], 10)) series: 16 samples: 400 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 06:00:00 +0000 UTC step: 15m0s 0.000000% avg diff for: query: sum by (namespace) (avg_over_time((rate(container_cpu_usage_seconds_total[5m]))[10m:]) \u0026gt; 1) series: 4 samples: 52 start: 2019-11-25 00:00:00 +0000 UTC end: 2019-11-25 01:00:00 +0000 UTC step: 5m0s ","excerpt":"The query auditor is a tool bundled in the Cortex repository, but not included in Docker images …","ref":"/docs/operations/query-auditor/","title":"Query Auditor (tool)"},{"body":"REWE digital builds the technology that drives the e-commerce, app, and food pickup and delivery services for one of Germany’s largest grocery chains, REWE. Like other companies involved in the food supply chain, REWE has seen demand spike during the Covid-19 pandemic. Thanks to its adoption of Cortex last year, the monitoring team has been able to ensure stability at growing scale.\nThe REWE digital subsidiary was started in 2014 to advance its parent company’s digital transformation, so “we have a rather modern tech stack,” says Cloud Platform Engineer Martin Schneppenheim. A lot of the platform is run on Kubernetes using GKE while some is still running on-prem using Nomad. Still, there were some challenges that arose from the Spotify tribe model that the organization adopted. Each of the four tribes at REWE digital \u0026ndash; ECOM, FULFILLMENT, CONTENT and PLATFORM, and while the tribes mostly converged on the same technologies, he says, “each platform team has its own solution for, say, Kafka, for Prometheus, for Grafana.”\nPlus, over the past six years, the company has grown from 30 employees to around 600.\nWith this rapid growth, they realized by the end of 2018 that they needed a new solution. The tipping point came when they experienced some out-of-memory issues with Prometheus, he says, “and we had no idea why.”\nEach tribe had one Prometheus HA pair that was used by all the teams in the tribe. One of the tribes used one Prometheus pair which required 30-60 gigabytes of RAM per instance. “We still saw some random out-of-memory kills, and we believe it was because some queries were loading too many samples,” Schneppenheim says. “We had several platform teams doing basically the same thing, and we wanted to tackle such issues organization-wide.”\nSearching for a scalable monitoring solution The solution needed to support the Prometheus format, since all of REWE’s microservices had a Prometheus end point. And the team wanted to have trust in the project’s longevity. After considering M3, Victoria Metrics, and Thanos, the REWE digital team decided to go with Cortex. “Cortex had just been released as a CNCF project, and there were several developers from different companies,” he says. “That was another plus point for us.” The key selling point, he adds, was Cortex’s multi-tenant support, which also involves the different protection mechanisms built into Cortex to limit a tenant’s usage so that a single tenant doesn’t affect the performance for other tenants. “Every platform team was providing one Prometheus for their tribe,” Schneppenheim says, “and we wanted to move to something like a software-as-a-service approach, with just one team that provides Cortex, which can be used by all the teams within the company.”\nImplementation Implementation began with the Big Data tribe, which has since merged with the other tribes and has been the smallest in the company. “We already had Prometheus set up, and we just switched the data source from Prometheus to Cortex,” Schneppenheim says. “In the beginning it was just one dashboard where we switched the data sources, and later on we switched the data source for the whole tribe so that all dashboards used the Cortex data source by default, and the Prometheus deployment basically acted as remote writing Prometheus. We always had the chance to just switch back to the Prometheus, in case there were any failures, so there was not a big risk.”\nIn fact, things went smoothly, and a few months later, the ECOM tribe started writing metrics to Cortex. At the same time, the platform tribe decided to create one Grafana instance and use organizations to offer multi-tenancy. After that second migration, the tribe’s teams were able to migrate dashboards to the new Grafana instance, and then start querying against that data. By the end of the year, all the tribes will have migrated to Cortex and the Grafana instance.\nREWE digital adopted Cortex at “a very early stage,” Schneppenheim says. At first, “sometimes we had to read the code, because there was little documentation, but we were still confident that we took the right decision, because we got lots of support [from the community] in debugging some problems, which were usually misconfigurations.”\nHe points out that configuration has become simpler over the past year, with default values set in v1.0, and more documentation: “Things definitely became better.”\nResults Cortex’s horizontal scaling has proven to be crucial during the Covid-19 pandemic, when REWE’s grocery and food delivery services have seen extremely high demand. “Our primary focus was to ensure stability, so we had to scale, and we deployed more containers,” he says. “That meant we had way more metrics than before, on the one hand, and on the other hand, I believe our developers were watching our dashboards more closely, so we had way more queries as well.”\nSchneppenheim estimates that over the past two months, reads and writes have increased significantly, and the platform was able to handle the added load. Plus, “it was quite easy deploying another set of queriers,” he says.\nAside from that, Schneppenheim says, “the biggest advantage for our company is that we now have a team that can offer one thing as an internal service.” While the tribes’ ops teams still have to manage their own Prometheus servers, they have a much more stable and scalable system. The challenges are unpredictable resource usage on querying and some queries that can load too much data causing Prometheus to OOM, but with Cortex handling all the queries, this is no longer a problem. And while Schneppenheim’s team is still just two people (they’re hiring!), he adds, “we can spend more time actually learning how to run it, and become an expert within the company for Cortex and the things that come along with it, like high cardinality metric series, which we see every two weeks or so. We are the contact for all the monitoring now.”\nThere have been other technical advantages, too: “We have no gaps anymore in our Prometheus and Grafana,” he says. “In case a Prometheus instance fails or if it needs to be restarted, we automatically switch over to the replica with the HA tracker, which is a great thing.”\nWith Cortex’s query results cache, the queries are cached. The REWE digital team has found that this feature makes dashboards “super fast, because the query is likely already cached and it just has to load the new 30 seconds or so, since the last refresh,” says Schneppenheim. “Preloaded dashboards load or refresh really, really fast.”\nPlus, there is a higher retention with Cortex. “We now have 60 days’ retention; we used to have seven days only,” he says.\nThe benefits are also clear as the infrastructure grows. REWE digital has added a few more small Kubernetes clusters, which “obviously have the same monitoring/alerting needs as our biggest clusters,” he says. Previously, the team would have to deploy Prometheus and a separate Grafana instance (along with NGINX and DNS setup).\n“With our new SaaS approach, making monitoring available for these is as easy as adding a Prometheus pair, which sends metrics to our Cortex cluster, and adding this new tenant in our Grafana organization,” he says.\nWith Cortex, they’ve also been able to solve two use cases (Kubernetes clusters that had been split for technical reasons, and cloud migration) that required metrics from two different clusters to be available with the same tenant. “The dev teams had the need to aggregate metrics across these two clusters, which was easily possible, because we just ingested them under the same tenant ID,” says Schneppenheim.\nAnd those out-of-memory issues? “We are constantly growing, not only on the query side, but also on the ingesting metrics side as we onboard teams and tribes,” he says. “But we have fine-tuned it quite well, and there are not as many OOM kills, and if there are, we don\u0026rsquo;t see them in Grafana. That\u0026rsquo;s important to us, that our developers have a smooth experience.” (Most tribes use Grafana alerting; one uses Prometheus Alertmanager.)\nLooking ahead REWE digital’s main focus right now is to onboard the rest of the teams to Cortex. But looking ahead, the team is exploring Grafana Cloud Agent for the tribes that aren’t using Prometheus Alertmanager. “They don\u0026rsquo;t need Prometheus; we only use Prometheus to scrape the targets and send samples to our Cortex,” he says, “so that could definitely be interesting, especially given the performance improvements. Its sole purpose is to send metrics to Cortex as our remote-write backend, so maybe there will be other advantages in the future, like a more close monitoring.”\nThe in-development Cortex Blocks storage engine is also interesting to the team as a solution for the bottleneck it has around a small BigTable cluster. “We just run three BigTable nodes, and the BigTable read latency sometimes peaks at one second, which is also the upper bucket limit in the histogram,” he says. “This happens if users open Grafana dashboards querying a long time range with many panels. Our hope is that switching from BigTable to the new storage engine would fix this as the object store (GCS) scales on-demand.”\nThe REWE digital team has built and open sourced its own Cortex gateway, which is on the project roadmap. “This might be a chance for us to contribute,” says Schneppenheim.\nSchneppenheim is also hopeful that the positive results REWE digital has seen with Cortex may lead to its further adoption throughout the greater REWE Group organization. “We\u0026rsquo;re just a small company within the REWE group,” he says, but “we might offer it as internal software as a service for other parts of the Group. They can trust our solution.”\n","excerpt":"REWE digital builds the technology that drives the e-commerce, app, and food pickup and delivery …","ref":"/docs/case-studies/rewe-digital/","title":"How Cortex helped REWE digital ensure stability while scaling services during the Covid-19 pandemic"},{"body":"[this is a work in progress]\nSee also the Running in Production document.\nCredentials You can supply credentials to Cortex by setting environment variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY (and AWS_SESSION_TOKEN if you use MFA), or use a short-term token solution such as kiam.\nShould I use S3 or DynamoDB ? Note that the choices for the chunks storage backend are: \u0026ldquo;chunks\u0026rdquo; of timeseries data in S3 and index in DynamoDB, or everything in DynamoDB. Using just S3 is not an option, unless you use the blocks storage engine.\nBroadly S3 is much more expensive to read and write, while DynamoDB is much more expensive to store over months. S3 charges differently, so the cross-over will depend on the size of your chunks, and how long you keep them. Very roughly: for 3KB chunks if you keep them longer than 8 months then S3 is cheaper.\nDynamoDB capacity provisioning By default, the Cortex Tablemanager will provision tables with 1,000 units of write capacity and 300 read - these numbers are chosen to be high enough that most trial installations won\u0026rsquo;t see a bottleneck on storage, but do note that that AWS will charge you approximately $60 per day for this capacity.\nTo match your costs to requirements, observe the actual capacity utilisation via CloudWatch or Prometheus metrics, then adjust the Tablemanager provision via command-line options -dynamodb.chunk-table.write-throughput, read-throughput and similar with .periodic-table which controls the index table.\nTablemanager can even adjust the capacity dynamically, by watching metrics for DynamoDB throttling and ingester queue length. Here is an example set of command-line parameters from a fairly modest install:\n -target=table-manager -metrics.url=http://prometheus.monitoring.svc.cluster.local./api/prom/ -metrics.target-queue-length=100000 -dynamodb.url=dynamodb://us-east-1/ -schema-config-file=/etc/schema.yaml -dynamodb.periodic-table.write-throughput=1000 -dynamodb.periodic-table.write-throughput.scale.enabled=true -dynamodb.periodic-table.write-throughput.scale.min-capacity=200 -dynamodb.periodic-table.write-throughput.scale.max-capacity=2000 -dynamodb.periodic-table.write-throughput.scale.out-cooldown=300 # 5 minutes between scale ups -dynamodb.periodic-table.inactive-enable-ondemand-throughput-mode=true -dynamodb.periodic-table.read-throughput=300 -dynamodb.chunk-table.write-throughput=800 -dynamodb.chunk-table.write-throughput.scale.enabled=true -dynamodb.chunk-table.write-throughput.scale.min-capacity=200 -dynamodb.chunk-table.write-throughput.scale.max-capacity=1000 -dynamodb.chunk-table.write-throughput.scale.out-cooldown=300 # 5 minutes between scale ups -dynamodb.chunk-table.inactive-enable-ondemand-throughput-mode=true -dynamodb.chunk-table.read-throughput=300 Several things to note here:\n -metrics.url points at a Prometheus server running within the cluster, scraping Cortex. Currently it is not possible to use Cortex itself as the target here. -metrics.target-queue-length: when the ingester queue is below this level, Tablemanager will not scale up. When the queue is growing above this level, Tablemanager will scale up whatever table is being throttled. The plain throughput values are used when the tables are first created. Scale-up to any level up to this value will be very quick, but if you go higher than this initial value, AWS may take tens of minutes to finish scaling. In the config above they are set. ondemand-throughput-mode tells AWS to charge for what you use, as opposed to continuous provisioning. This mode is cost-effective for older data, which is never written and only read sporadically. If you want to add AWS tags to the created DynamoDB tables you can do it by adding a tags map to your schema definition. See schema configuration ","excerpt":"[this is a work in progress]\nSee also the Running in Production document.\nCredentials You can supply …","ref":"/docs/production/aws/","title":"Running Cortex with AWS Services"},{"body":"This feature is currently experimental and is only supported for Chunks storage.\nCortex supports deletion of series using Prometheus compatible API. It however does not support Prometheuses Clean Tombstones API because Cortex uses a different mechanism to manage deletions.\nHow it works A new service called purger is added which exposes deletion APIs and does the processing of the requests. To store the requests, and some additional information while performing deletions, the purger requires configuring an index and object store respectively for it. For more information about the purger configuration, please refer to the config file reference documentation.\nAll the requests specified below needs to be sent to purger.\nNote: If you have enabled multi-tenancy in your Cortex cluster then deletion APIs requests require to have the X-Scope-OrgID header set like for any other Cortex API.\nRequesting Deletion By calling the /api/v1/admin/tsdb/delete_series API like how it is done in Prometheus, you can request the deletion of series. Delete Series requests are immediately honored by eliminating series requested for deletion from query responses without actually deleting them from storage. The actual data is not deleted from storage until period configured for -purger.delete-request-cancel-period CLI flag or its respective YAML config option which helps operators take informed decision about continuing with the deletion or cancelling the request.\nCortex would keep eliminating series requested for deletion until the purger is done processing the delete request or the delete request gets cancelled.\nSample cURL command:\ncurl -X POST \\ '\u0026lt;purger_addr\u0026gt;/api/v1/admin/tsdb/delete_series?match%5B%5D=up\u0026amp;start=1591616227\u0026amp;end=1591619692' \\ -H 'x-scope-orgid: \u0026lt;tenant-id\u0026gt;' Cancellation of Delete Request Cortex allows cancellation of delete requests until they are not picked up for processing, which is controlled by the -purger.delete-request-cancel-period CLI flag or its respective YAML config option. Since Cortex does query time filtering of data request for deletion until it is actually deleted, you can take an informed decision to cancel the delete request by calling the API defined below:\nPOST /api/v1/admin/tsdb/cancel_delete_request?request_id=\u0026lt;request_id\u0026gt; PUT /api/v1/admin/tsdb/cancel_delete_request?request_id=\u0026lt;request_id\u0026gt; Sample cURL command:\ncurl -X POST \\ '\u0026lt;purger_addr\u0026gt;/api/v1/admin/tsdb/cancel_delete_request?request_id=\u0026lt;request_id\u0026gt;' \\ -H 'x-scope-orgid: \u0026lt;tenant-id\u0026gt;' You can find the id of the request that you want to cancel by using the GET delete_series API defined below.\nListing Delete Requests You can list the created delete requests using following API:\nGET /api/v1/admin/tsdb/delete_series Sample cURL command:\ncurl -X GET \\ \u0026lt;purger_addr\u0026gt;/api/v1/admin/tsdb/delete_series \\ -H 'x-scope-orgid: \u0026lt;orgid\u0026gt;' NOTE: List API returns both processed and un-processed requests except the cancelled ones since they are removed from the store.\n","excerpt":"This feature is currently experimental and is only supported for Chunks storage.\nCortex supports …","ref":"/docs/guides/deleting-series/","title":"Deleting Series"},{"body":"This feature is currently experimental and is only supported for Chunks storage.\nCortex chunks storage supports a gRPC-based plugin system to use alternative backends for the index and chunks store. A store plugin is a gRPC-based server which implements the methods required by the index and chunks store. Cortex chunks storage schema is then configured to use the plugin as backend system and gRPC will be used to communicate between Cortex and the plugin. For example, if you\u0026rsquo;re deploying your Cortex cluster on Kubernetes, the plugin would run as a sidecar container of your Cortex pods and the Cortex\u0026rsquo;s -grpc-store.server-address should be configured to the endpoint exposed by the sidecar plugin (eg. localhost:\u0026lt;port\u0026gt;).\nHow it works In the cortex configuration file, add store and object_store as grpc-store and configure storage with plugin server endpoint (ie. the address to the gRPC server which implements the cortex chunk store methods).\nschema: configs: - from: 2019-07-29 store: grpc-store object_store: grpc-store schema: v10 index: prefix: index_ period: 168h chunks: prefix: chunk_ period: 168h storage: grpc_store: # gRPC server address server_address: localhost:6666 Community plugins The following list shows Cortex storage plugins built and shared by the community:\n gRPC based Cortex chunk store for Mongo gRPC based Cortex chunk store for Mysql ","excerpt":"This feature is currently experimental and is only supported for Chunks storage.\nCortex chunks …","ref":"/docs/guides/grpc-based-plugin/","title":"gRPC storage plugin"},{"body":"The Cortex documentation is compiled into a website published at cortexmetrics.io. These instructions explain how to run the website locally, in order to have a quick feedback loop while contributing to the documentation or website styling.\nInitial setup The following initial setup is required only once:\n Install Hugo v0.72.0 (extended version) Install Node.js v14 or above (alternatively via nvm) Install required Node modules with: cd website \u0026amp;\u0026amp; npm install \u0026amp;\u0026amp; cd - Run make BUILD_IN_CONTAINER=false web-build Run it Once the initial setup is completed, you can run the website with the following command. The local website will run at http://localhost:1313/\n# Keep this running make web-serve Whenever you change the content of docs/ or markdown files in the repository root / you should run:\nmake BUILD_IN_CONTAINER=false web-pre Whenever you change the config file or CLI flags in the Cortex code, you should rebuild the config file reference documentation:\nmake BUILD_IN_CONTAINER=false doc web-pre ","excerpt":"The Cortex documentation is compiled into a website published at cortexmetrics.io. These …","ref":"/docs/contributing/how-to-run-the-website-locally/","title":"How to run the website locally"},{"body":"","excerpt":"","ref":"/docs/production/","title":"Production"},{"body":"You can use the Cortex query frontend with any Prometheus-API compatible service, including Prometheus and Thanos. Use this config file to get the benefits of query parallelisation and caching.\n# Disable the requirement that every request to Cortex has a# X-Scope-OrgID header. `fake` will be substituted in instead.auth_enabled:false# We only want to run the query-frontend module.target:query-frontend# We don\u0026#39;t want the usual /api/prom prefix.http_prefix:server:http_listen_port:9091query_range:split_queries_by_interval:24halign_queries_with_step:truecache_results:trueresults_cache:cache:# We\u0026#39;re going to use the in-process \u0026#34;FIFO\u0026#34; cache, but you can enable# memcached below.enable_fifocache:truefifocache:size:1024validity:24h# If you want to use a memcached cluster, you can either configure a# headless service in Kubernetes and Cortex will discover the individual# instances using a SRV DNS query (host) or list comma separated# memcached addresses.# host + service: this is the config you should set when you use the# SRV DNS (this is considered stable)# addresses: this is experimental and supports service discovery# (https://cortexmetrics.io/docs/configuration/arguments/#dns-service-discovery)# so it could either be a list of single addresses, or a SRV record# prefixed with dnssrvnoa+. Cortex will then do client-side hashing to# spread the load evenly.# memcached:# expiration : 24h# memcached_client:# host: memcached.default.svc.cluster.local# service: memcached# addresses: \u0026#34;\u0026#34;# consistent_hash: truefrontend:log_queries_longer_than:1scompress_responses:true# The Prometheus URL to which the query-frontend should connect to.downstream_url:http://prometheus.mydomain.com","excerpt":"You can use the Cortex query frontend with any Prometheus-API compatible service, including …","ref":"/docs/configuration/prometheus-frontend/","title":"Prometheus Frontend"},{"body":"The query-tee is a standalone service which can be used for testing purposes to compare the query performances of 2+ backend systems (ie. Cortex clusters) ingesting the same exact series.\nThis service exposes Prometheus-compatible read API endpoints and, for each received request, performs the request against all backends tracking the response time of each backend and then sends back to the client one of the received responses.\nHow to run it You can run query-tee in two ways:\n Build it from sources go run ./cmd/query-tee -help Run it via the provided Docker image docker run quay.io/cortexproject/query-tee -help The service requires at least 1 backend endpoint (but 2 are required in order to compare performances) configured as comma-separated HTTP(S) URLs via the CLI flag -backend.endpoints. For each incoming request, query-tee will clone the request and send it to each backend, tracking performance metrics for each backend before sending back the response to the client.\nHow it works API endpoints The following Prometheus API endpoints are supported by query-tee:\n /api/v1/query (GET) /api/v1/query_range (GET) /api/v1/labels (GET) /api/v1/label/{name}/values (GET) /api/v1/series (GET) /api/v1/metadata (GET) /api/v1/alerts (GET) /api/v1/rules (GET) Pass-through requests query-tee supports acting as a transparent proxy for requests to routes not matching any of the documented API endpoints above. When enabled, those requests are passed on to just the configured preferred backend. To activate this feature it requires setting -proxy.passthrough-non-registered-routes=true flag and configuring a preferred backend.\nAuthentication query-tee supports HTTP basic authentication. It allows either to configure username and password in the backend URL, to forward the request auth to the backend or merge the two.\nThe request sent from the query-tee to the backend includes HTTP basic authentication when one of the following conditions are met:\n If the endpoint URL has username and password, query-tee uses it. If the endpoint URL has username only, query-tee keeps the username and inject the password received in the incoming request (if any). If the endpoint URL has no username and no password, query-tee forwards the incoming request basic authentication (if any). Backend response selection query-tee allows to configure a preferred backend from which picking the response to send back to the client. The preferred backend can be configured via the CLI flag -backend.preferred=\u0026lt;hostname\u0026gt;, setting it to the hostname of the preferred backend.\nWhen a preferred backend is set, query-tee sends back to the client:\n The preferred backend response if the status code is 2xx or 4xx Otherwise, the first received 2xx or 4xx response if at least a backend succeeded Otherwise, the first received response When a preferred backend is not set, query-tee sends back to the client:\n The first received 2xx or 4xx response if at least a backend succeeded Otherwise, the first received response Note: from the query-tee perspective, a backend request is considered successful even if the status code is 4xx because it generally means the error is due to an invalid request and not to a backend issue.\nBackend results comparison query-tee allows to optionally enable the query results comparison between two backends. The results comparison can be enabled via the CLI flag -proxy.compare-responses=true and requires exactly two configured backends with a preferred one.\nWhen the comparison is enabled, the query-tee compares the response received from the two configured backends and logs a message for each query whose results don\u0026rsquo;t match, as well as keeps track of the number of successful and failed comparison through the metric cortex_querytee_responses_compared_total.\nFloating point sample values are compared with a small tolerance that can be configured via -proxy.value-comparison-tolerance. This prevents false positives due to differences in floating point values rounding introduced by the non deterministic series ordering within the Prometheus PromQL engine.\nSlow backends query-tee sends back to the client the first viable response as soon as available, without waiting to receive a response from all backends.\nExported metrics query-tee exposes the following Prometheus metrics on the port configured via the CLI flag -server.metrics-port:\n# HELP cortex_querytee_request_duration_seconds Time (in seconds) spent serving HTTP requests. # TYPE cortex_querytee_request_duration_seconds histogram cortex_querytee_request_duration_seconds_bucket{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;,le=\u0026#34;\u0026lt;bucket\u0026gt;\u0026#34;} cortex_querytee_request_duration_seconds_sum{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;} cortex_querytee_request_duration_seconds_count{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,status_code=\u0026#34;\u0026lt;status\u0026gt;\u0026#34;} # HELP cortex_querytee_responses_total Total number of responses sent back to the client by the selected backend. # TYPE cortex_querytee_responses_total counter cortex_querytee_responses_total{backend=\u0026#34;\u0026lt;hostname\u0026gt;\u0026#34;,method=\u0026#34;\u0026lt;method\u0026gt;\u0026#34;,route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;} # HELP cortex_querytee_responses_compared_total Total number of responses compared per route name by result. # TYPE cortex_querytee_responses_compared_total counter cortex_querytee_responses_compared_total{route=\u0026#34;\u0026lt;route\u0026gt;\u0026#34;,result=\u0026#34;\u0026lt;success|fail\u0026gt;\u0026#34;} ","excerpt":"The query-tee is a standalone service which can be used for testing purposes to compare the query …","ref":"/docs/operations/query-tee/","title":"Query Tee (service)"},{"body":"The store-gateway is the Cortex service responsible to query series from blocks. The store-gateway is required when running the Cortex blocks storage.\nThe store-gateway is semi-stateful.\nHow it works At startup store-gateways iterate over the entire storage bucket to discover blocks for all tenants and download the meta.json and index-header for each block. During this initial bucket synchronization phase, the store-gateway /ready readiness probe endpoint will fail.\nWhile running, store-gateways periodically rescan the storage bucket to discover new blocks (uploaded by the ingesters and compactor) and blocks marked for deletion or fully deleted since the last scan (as a result of compaction). The frequency at which this occurs is configured via -blocks-storage.bucket-store.sync-interval.\nThe blocks chunks and the entire index are never fully downloaded by the store-gateway. The index-header is stored to the local disk, in order to avoid to re-download it on subsequent restarts of a store-gateway. For this reason, it\u0026rsquo;s recommended - but not required - to run the store-gateway with a persistent disk. For example, if you\u0026rsquo;re running the Cortex cluster in Kubernetes, you may use a StatefulSet with a persistent volume claim for the store-gateways.\nFor more information about the index-header, please refer to Binary index-header documentation.\nBlocks sharding and replication The store-gateway optionally supports blocks sharding. Sharding can be used to horizontally scale blocks in a large cluster without hitting any vertical scalability limit.\nWhen sharding is enabled, store-gateway instances builds an hash ring and blocks get sharded and replicated across the pool of store-gateway instances registered within the ring.\nStore-gateways continuously monitor the ring state and whenever the ring topology changes (e.g. a new instance has been added/removed or gets healthy/unhealthy) each store-gateway instance resync the blocks assigned to its shard, based on the block ID hash matching the token ranges assigned to the instance itself within the ring.\nFor each block belonging to a store-gateway shard, the store-gateway loads its meta.json, the deletion-mark.json and the index-header. Once a block is loaded on the store-gateway, it\u0026rsquo;s ready to be queried by queriers. When the querier queries blocks through a store-gateway, the response will contain the list of actually queried block IDs. If a querier tries to query a block which has not been loaded by a store-gateway, the querier will either retry on a different store-gateway (if blocks replication is enabled) or fail the query.\nBlocks can be replicated across multiple store-gateway instances based on a replication factor configured via -store-gateway.sharding-ring.replication-factor. The blocks replication is used to protect from query failures caused by some blocks not loaded by any store-gateway instance at a given time like, for example, in the event of a store-gateway failure or while restarting a store-gateway instance (e.g. during a rolling update).\nThis feature can be enabled via -store-gateway.sharding-enabled=true and requires the backend hash ring to be configured via -store-gateway.sharding-ring.* flags (or their respective YAML config options).\nSharding strategies The store-gateway supports two sharding strategies:\n default shuffle-sharding The default sharding strategy spreads the blocks of each tenant across all store-gateway instances. It\u0026rsquo;s the easiest form of sharding supported, but doesn\u0026rsquo;t provide any workload isolation between different tenants.\nThe shuffle-sharding strategy spreads the blocks of a tenant across a subset of store-gateway instances. This way, the number of store-gateway instances loading blocks of a single tenant is limited and the blast radius of any issue that could be introduced by the tenant\u0026rsquo;s workload is limited to its shard instances.\nThe shuffle sharding strategy can be enabled via -store-gateway.sharding-strategy=shuffle-sharding and requires the -store-gateway.tenant-shard-size flag (or their respective YAML config options) to be set to the default shard size, which is the default number of store-gateway instances each tenant should be sharded to. The shard size can then be overridden on a per-tenant basis setting the store_gateway_tenant_shard_size in the limits overrides.\nPlease check out the shuffle sharding documentation for more information about how it works.\nAuto-forget When a store-gateway instance cleanly shutdowns, it automatically unregisters itself from the ring. However, in the event of a crash or node failure, the instance will not be unregistered from the ring, potentially leaving a spurious entry in the ring forever.\nTo protect from this, when an healthy store-gateway instance finds another instance in the ring which is unhealthy for more than 10 times the configured -store-gateway.sharding-ring.heartbeat-timeout, the healthy instance forcibly removes the unhealthy one from the ring.\nThis feature is called auto-forget and is built into the store-gateway.\nZone-awareness The store-gateway replication optionally supports zone-awareness. When zone-aware replication is enabled and the blocks replication factor is \u0026gt; 1, each block is guaranteed to be replicated across store-gateway instances running in different availability zones.\nTo enable the zone-aware replication for the store-gateways you should:\n Configure the availability zone for each store-gateway via the -store-gateway.sharding-ring.instance-availability-zone CLI flag (or its respective YAML config option) Enable blocks zone-aware replication via the -store-gateway.sharding-ring.zone-awareness-enabled CLI flag (or its respective YAML config option). Please be aware this configuration option should be set to store-gateways, queriers and rulers. Rollout store-gateways, queriers and rulers to apply the new configuration Caching The store-gateway supports the following caches:\n Index cache Chunks cache Metadata cache Caching is optional, but highly recommended in a production environment. Please also check out the production tips for more information about configuring the cache.\nIndex cache The store-gateway can use a cache to speed up lookups of postings and series from TSDB blocks indexes. Two backends are supported:\n inmemory memcached In-memory index cache The inmemory index cache is enabled by default and its max size can be configured through the flag -blocks-storage.bucket-store.index-cache.inmemory.max-size-bytes (or config file). The trade-off of using the in-memory index cache is:\n Pros: zero latency Cons: increased store-gateway memory usage, not shared across multiple store-gateway replicas (when sharding is disabled or replication factor \u0026gt; 1) Memcached index cache The memcached index cache allows to use Memcached as cache backend. This cache backend is configured using -blocks-storage.bucket-store.index-cache.backend=memcached and requires the Memcached server(s) addresses via -blocks-storage.bucket-store.index-cache.memcached.addresses (or config file). The addresses are resolved using the DNS service provider.\nThe trade-off of using the Memcached index cache is:\n Pros: can scale beyond a single node memory (Memcached cluster), shared across multiple store-gateway instances Cons: higher latency in the cache round trip compared to the in-memory one The Memcached client uses a jump hash algorithm to shard cached entries across a cluster of Memcached servers. For this reason, you should make sure memcached servers are not behind any kind of load balancer and their address is configured so that servers are added/removed to the end of the list whenever a scale up/down occurs.\nFor example, if you\u0026rsquo;re running Memcached in Kubernetes, you may:\n Deploy your Memcached cluster using a StatefulSet Create an headless service for Memcached StatefulSet Configure the Cortex\u0026rsquo;s Memcached client address using the dnssrvnoa+ service discovery Chunks cache Store-gateway can also use a cache for storing chunks fetched from the storage. Chunks contain actual samples, and can be reused if user query hits the same series for the same time range.\nTo enable chunks cache, please set -blocks-storage.bucket-store.chunks-cache.backend. Chunks can currently only be stored into Memcached cache. Memcached client can be configured via flags with -blocks-storage.bucket-store.chunks-cache.memcached.* prefix.\nThere are additional low-level options for configuring chunks cache. Please refer to other flags with -blocks-storage.bucket-store.chunks-cache.* prefix.\nMetadata cache Store-gateway and querier can use memcached for caching bucket metadata:\n List of tenants List of blocks per tenant Block\u0026rsquo;s meta.json content Block\u0026rsquo;s deletion-mark.json existence and content Using the metadata cache can significantly reduce the number of API calls to object storage and protects from linearly scale the number of these API calls with the number of querier and store-gateway instances (because the bucket is periodically scanned and synched by each querier and store-gateway).\nTo enable metadata cache, please set -blocks-storage.bucket-store.metadata-cache.backend. Only memcached backend is supported currently. Memcached client has additional configuration available via flags with -blocks-storage.bucket-store.metadata-cache.memcached.* prefix.\nAdditional options for configuring metadata cache have -blocks-storage.bucket-store.metadata-cache.* prefix. By configuring TTL to zero or negative value, caching of given item type is disabled.\nThe same memcached backend cluster should be shared between store-gateways and queriers.\nStore-gateway HTTP endpoints GET /store-gateway/ring\nDisplays the status of the store-gateways ring, including the tokens owned by each store-gateway and an option to remove (forget) instances from the ring. Store-gateway configuration This section described the store-gateway configuration. For the general Cortex configuration and references to common config blocks, please refer to the configuration documentation.\nstore_gateway_config The store_gateway_config configures the store-gateway service used by the blocks storage.\nstore_gateway:# Shard blocks across multiple store gateway instances. This option needs be# set both on the store-gateway and querier when running in microservices# mode.# CLI flag: -store-gateway.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]# The hash ring configuration. This option is required only if blocks sharding# is enabled.sharding_ring:# The key-value store used to share the hash ring across multiple instances.# This option needs be set both on the store-gateway and querier when# running in microservices mode.kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -store-gateway.sharding-ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -store-gateway.sharding-ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is:# store-gateway.sharding-ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is:# store-gateway.sharding-ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -store-gateway.sharding-ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -store-gateway.sharding-ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -store-gateway.sharding-ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -store-gateway.sharding-ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -store-gateway.sharding-ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=15s]# The heartbeat timeout after which store gateways are considered unhealthy# within the ring. This option needs be set both on the store-gateway and# querier when running in microservices mode.# CLI flag: -store-gateway.sharding-ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# The replication factor to use when sharding blocks. This option needs be# set both on the store-gateway and querier when running in microservices# mode.# CLI flag: -store-gateway.sharding-ring.replication-factor[replication_factor:\u0026lt;int\u0026gt;|default=3]# File path where tokens are stored. If empty, tokens are not stored at# shutdown and restored at startup.# CLI flag: -store-gateway.sharding-ring.tokens-file-path[tokens_file_path:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# True to enable zone-awareness and replicate blocks across different# availability zones.# CLI flag: -store-gateway.sharding-ring.zone-awareness-enabled[zone_awareness_enabled:\u0026lt;boolean\u0026gt;|default=false]# Name of network interface to read address from.# CLI flag: -store-gateway.sharding-ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]# The availability zone where this instance is running. Required if# zone-awareness is enabled.# CLI flag: -store-gateway.sharding-ring.instance-availability-zone[instance_availability_zone:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The sharding strategy to use. Supported values are: default,# shuffle-sharding.# CLI flag: -store-gateway.sharding-strategy[sharding_strategy:\u0026lt;string\u0026gt;|default=\u0026#34;default\u0026#34;]blocks_storage_config The blocks_storage_config configures the blocks storage.\nblocks_storage:# Backend storage to use. Supported backends are: s3, gcs, azure, filesystem.# CLI flag: -blocks-storage.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;s3\u0026#34;]s3:# The S3 bucket endpoint. It could be an AWS S3 endpoint listed at# https://docs.aws.amazon.com/general/latest/gr/s3.html or the address of an# S3-compatible service in hostname:port format.# CLI flag: -blocks-storage.s3.endpoint[endpoint:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 bucket name# CLI flag: -blocks-storage.s3.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 secret access key# CLI flag: -blocks-storage.s3.secret-access-key[secret_access_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# S3 access key ID# CLI flag: -blocks-storage.s3.access-key-id[access_key_id:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# If enabled, use http:// for the S3 endpoint instead of https://. This# could be useful in local dev/test environments while using an# S3-compatible backend storage, like Minio.# CLI flag: -blocks-storage.s3.insecure[insecure:\u0026lt;boolean\u0026gt;|default=false]http:# The time an idle connection will remain idle before closing.# CLI flag: -blocks-storage.s3.http.idle-conn-timeout[idle_conn_timeout:\u0026lt;duration\u0026gt;|default=1m30s]# The amount of time the client will wait for a servers response headers.# CLI flag: -blocks-storage.s3.http.response-header-timeout[response_header_timeout:\u0026lt;duration\u0026gt;|default=2m]# If the client connects to S3 via HTTPS and this option is enabled, the# client will accept any certificate and hostname.# CLI flag: -blocks-storage.s3.http.insecure-skip-verify[insecure_skip_verify:\u0026lt;boolean\u0026gt;|default=false]gcs:# GCS bucket name# CLI flag: -blocks-storage.gcs.bucket-name[bucket_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# JSON representing either a Google Developers Console# client_credentials.json file or a Google Developers service account key# file. If empty, fallback to Google default logic.# CLI flag: -blocks-storage.gcs.service-account[service_account:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]azure:# Azure storage account name# CLI flag: -blocks-storage.azure.account-name[account_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage account key# CLI flag: -blocks-storage.azure.account-key[account_key:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage container name# CLI flag: -blocks-storage.azure.container-name[container_name:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Azure storage endpoint suffix without schema. The account name will be# prefixed to this value to create the FQDN# CLI flag: -blocks-storage.azure.endpoint-suffix[endpoint_suffix:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Number of retries for recoverable errors# CLI flag: -blocks-storage.azure.max-retries[max_retries:\u0026lt;int\u0026gt;|default=20]filesystem:# Local filesystem storage directory.# CLI flag: -blocks-storage.filesystem.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# This configures how the store-gateway synchronizes blocks stored in the# bucket.bucket_store:# Directory to store synchronized TSDB index headers.# CLI flag: -blocks-storage.bucket-store.sync-dir[sync_dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb-sync\u0026#34;]# How frequently scan the bucket to look for changes (new blocks shipped by# ingesters and blocks removed by retention or compaction). 0 disables it.# CLI flag: -blocks-storage.bucket-store.sync-interval[sync_interval:\u0026lt;duration\u0026gt;|default=5m]# Max size - in bytes - of a per-tenant chunk pool, used to reduce memory# allocations.# CLI flag: -blocks-storage.bucket-store.max-chunk-pool-bytes[max_chunk_pool_bytes:\u0026lt;int\u0026gt;|default=2147483648]# Max number of concurrent queries to execute against the long-term storage.# The limit is shared across all tenants.# CLI flag: -blocks-storage.bucket-store.max-concurrent[max_concurrent:\u0026lt;int\u0026gt;|default=100]# Maximum number of concurrent tenants synching blocks.# CLI flag: -blocks-storage.bucket-store.tenant-sync-concurrency[tenant_sync_concurrency:\u0026lt;int\u0026gt;|default=10]# Maximum number of concurrent blocks synching per tenant.# CLI flag: -blocks-storage.bucket-store.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from object# storage per tenant.# CLI flag: -blocks-storage.bucket-store.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of a block before it\u0026#39;s being read. Set it to safe value (e.g# 30m) if your object storage is eventually consistent. GCS and S3 are# (roughly) strongly consistent.# CLI flag: -blocks-storage.bucket-store.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]index_cache:# The index cache backend type. Supported values: inmemory, memcached.# CLI flag: -blocks-storage.bucket-store.index-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;inmemory\u0026#34;]inmemory:# Maximum size in bytes of in-memory index cache used to speed up blocks# index lookups (shared between all tenants).# CLI flag: -blocks-storage.bucket-store.index-cache.inmemory.max-size-bytes[max_size_bytes:\u0026lt;int\u0026gt;|default=1073741824]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.index-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Compress postings before storing them to postings cache.# CLI flag: -blocks-storage.bucket-store.index-cache.postings-compression-enabled[postings_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]chunks_cache:# Backend for chunks cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.chunks-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.chunks-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# Size of each subrange that bucket object is split into for better# caching.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-size[subrange_size:\u0026lt;int\u0026gt;|default=16000]# Maximum number of sub-GetRange requests that a single GetRange request# can be split into when fetching chunks. Zero or negative value =# unlimited number of sub-requests.# CLI flag: -blocks-storage.bucket-store.chunks-cache.max-get-range-requests[max_get_range_requests:\u0026lt;int\u0026gt;|default=3]# TTL for caching object attributes for chunks.# CLI flag: -blocks-storage.bucket-store.chunks-cache.attributes-ttl[attributes_ttl:\u0026lt;duration\u0026gt;|default=24h]# TTL for caching individual chunks subranges.# CLI flag: -blocks-storage.bucket-store.chunks-cache.subrange-ttl[subrange_ttl:\u0026lt;duration\u0026gt;|default=24h]metadata_cache:# Backend for metadata cache, if not empty. Supported values: memcached.# CLI flag: -blocks-storage.bucket-store.metadata-cache.backend[backend:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]memcached:# Comma separated list of memcached addresses. Supported prefixes are:# dns+ (looked up as an A/AAAA query), dnssrv+ (looked up as a SRV# query, dnssrvnoa+ (looked up as a SRV query, with no A/AAAA lookup# made after that).# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.addresses[addresses:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# The socket read/write timeout.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.timeout[timeout:\u0026lt;duration\u0026gt;|default=100ms]# The maximum number of idle connections that will be maintained per# address.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-idle-connections[max_idle_connections:\u0026lt;int\u0026gt;|default=16]# The maximum number of concurrent asynchronous operations can occur.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-concurrency[max_async_concurrency:\u0026lt;int\u0026gt;|default=50]# The maximum number of enqueued asynchronous operations allowed.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-async-buffer-size[max_async_buffer_size:\u0026lt;int\u0026gt;|default=10000]# The maximum number of concurrent connections running get operations.# If set to 0, concurrency is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-concurrency[max_get_multi_concurrency:\u0026lt;int\u0026gt;|default=100]# The maximum number of keys a single underlying get operation should# run. If more keys are specified, internally keys are splitted into# multiple batches and fetched concurrently, honoring the max# concurrency. If set to 0, the max batch size is unlimited.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-get-multi-batch-size[max_get_multi_batch_size:\u0026lt;int\u0026gt;|default=0]# The maximum size of an item stored in memcached. Bigger items are not# stored. If set to 0, no maximum size is enforced.# CLI flag: -blocks-storage.bucket-store.metadata-cache.memcached.max-item-size[max_item_size:\u0026lt;int\u0026gt;|default=1048576]# How long to cache list of tenants in the bucket.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenants-list-ttl[tenants_list_ttl:\u0026lt;duration\u0026gt;|default=15m]# How long to cache list of blocks for each tenant.# CLI flag: -blocks-storage.bucket-store.metadata-cache.tenant-blocks-list-ttl[tenant_blocks_list_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache list of chunks for a block.# CLI flag: -blocks-storage.bucket-store.metadata-cache.chunks-list-ttl[chunks_list_ttl:\u0026lt;duration\u0026gt;|default=24h]# How long to cache information that block metafile exists.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-exists-ttl[metafile_exists_ttl:\u0026lt;duration\u0026gt;|default=2h]# How long to cache information that block metafile doesn\u0026#39;t exist.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-doesnt-exist-ttl[metafile_doesnt_exist_ttl:\u0026lt;duration\u0026gt;|default=5m]# How long to cache content of the metafile.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-content-ttl[metafile_content_ttl:\u0026lt;duration\u0026gt;|default=24h]# Maximum size of metafile content to cache in bytes.# CLI flag: -blocks-storage.bucket-store.metadata-cache.metafile-max-size-bytes[metafile_max_size_bytes:\u0026lt;int\u0026gt;|default=1048576]# Duration after which the blocks marked for deletion will be filtered out# while fetching blocks. The idea of ignore-deletion-marks-delay is to# ignore blocks that are marked for deletion with some delay. This ensures# store can still serve blocks that are meant to be deleted but do not have# a replacement yet. Default is 6h, half of the default value for# -compactor.deletion-delay.# CLI flag: -blocks-storage.bucket-store.ignore-deletion-marks-delay[ignore_deletion_mark_delay:\u0026lt;duration\u0026gt;|default=6h]tsdb:# Local directory to store TSDBs in the ingesters.# CLI flag: -blocks-storage.tsdb.dir[dir:\u0026lt;string\u0026gt;|default=\u0026#34;tsdb\u0026#34;]# TSDB blocks range period.# CLI flag: -blocks-storage.tsdb.block-ranges-period[block_ranges_period:\u0026lt;listofduration\u0026gt;|default=2h0m0s]# TSDB blocks retention in the ingester before a block is removed. This# should be larger than the block_ranges_period and large enough to give# store-gateways and queriers enough time to discover newly uploaded blocks.# CLI flag: -blocks-storage.tsdb.retention-period[retention_period:\u0026lt;duration\u0026gt;|default=6h]# How frequently the TSDB blocks are scanned and new ones are shipped to the# storage. 0 means shipping is disabled.# CLI flag: -blocks-storage.tsdb.ship-interval[ship_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently shipping blocks to the storage.# CLI flag: -blocks-storage.tsdb.ship-concurrency[ship_concurrency:\u0026lt;int\u0026gt;|default=10]# How frequently does Cortex try to compact TSDB head. Block is only created# if data covers smallest block range. Must be greater than 0 and max 5# minutes.# CLI flag: -blocks-storage.tsdb.head-compaction-interval[head_compaction_interval:\u0026lt;duration\u0026gt;|default=1m]# Maximum number of tenants concurrently compacting TSDB head into a new# block# CLI flag: -blocks-storage.tsdb.head-compaction-concurrency[head_compaction_concurrency:\u0026lt;int\u0026gt;|default=5]# If TSDB head is idle for this duration, it is compacted. 0 means disabled.# CLI flag: -blocks-storage.tsdb.head-compaction-idle-timeout[head_compaction_idle_timeout:\u0026lt;duration\u0026gt;|default=1h]# The number of shards of series to use in TSDB (must be a power of 2).# Reducing this will decrease memory footprint, but can negatively impact# performance.# CLI flag: -blocks-storage.tsdb.stripe-size[stripe_size:\u0026lt;int\u0026gt;|default=16384]# True to enable TSDB WAL compression.# CLI flag: -blocks-storage.tsdb.wal-compression-enabled[wal_compression_enabled:\u0026lt;boolean\u0026gt;|default=false]# True to flush blocks to storage on shutdown. If false, incomplete blocks# will be reused after restart.# CLI flag: -blocks-storage.tsdb.flush-blocks-on-shutdown[flush_blocks_on_shutdown:\u0026lt;boolean\u0026gt;|default=false]# limit the number of concurrently opening TSDB\u0026#39;s on startup# CLI flag: -blocks-storage.tsdb.max-tsdb-opening-concurrency-on-startup[max_tsdb_opening_concurrency_on_startup:\u0026lt;int\u0026gt;|default=10]","excerpt":"The store-gateway is the Cortex service responsible to query series from blocks. The store-gateway …","ref":"/docs/blocks-storage/store-gateway/","title":"Store-gateway"},{"body":"The compactor is an optional service which compacts multiple blocks of a given tenant into a single optimized larger block. Running compactor is highly recommended to reduce storage costs (deduplication, index size reduction), and increase query speed (querying fewer blocks is faster).\nThe compactor is stateless.\nHow it works The compactor has two main benefits:\n Vertically compact blocks uploaded by all ingesters for the same time range Horizontally compact blocks with small time ranges into a single larger block The vertical compaction merges all the blocks of a tenant uploaded by ingesters for the same time range (2 hours ranges by default) into a single block, while de-duplicating samples that are originally written to N blocks as a result of replication. This step reduces number of blocks for single 2 hours time range from #(number of ingesters) to 1 per tenant.\nThe horizontal compaction triggers after the vertical compaction and compacts several blocks with adjacent 2-hour range periods into a single larger block. Even though the total size of block chunks doesn\u0026rsquo;t change after this compaction, it may still significantly reduce the size of the index and the index-header kept in memory by store-gateways.\nCompactor sharding The compactor optionally supports sharding.\nWhen sharding is enabled, multiple compactor instances can coordinate to split the workload and shard blocks by tenant. All the blocks of a tenant are processed by a single compactor instance at any given time, but compaction for different tenants may simultaneously run on different compactor instances.\nWhenever the pool of compactors increase or decrease (ie. following up a scale up/down), tenants are resharded across the available compactor instances without any manual intervention.\nThe compactor sharding is based on the Cortex hash ring. At startup, a compactor generates random tokens and registers itself to the ring. While running, it periodically scans the storage bucket (every -compactor.compaction-interval) to discover the list of tenants in the storage and compacts blocks for each tenant whose hash matches the token ranges assigned to the instance itself within the ring.\nThis feature can be enabled via -compactor.sharding-enabled=true and requires the backend hash ring to be configured via -compactor.ring.* flags (or their respective YAML config options).\nSoft and hard blocks deletion When the compactor successfully compacts some source blocks into a larger block, source blocks are deleted from the storage. Blocks deletion is not immediate, but follows a two steps process:\n First, a block is marked for deletion (soft delete) Then, once a block is marked for deletion for longer then -compactor.deletion-delay, the block is deleted from the storage (hard delete) The compactor is both responsible to mark blocks for deletion and then hard delete them once the deletion delay expires. The soft deletion is based on a tiny deletion-mark.json file stored within the block location in the bucket which gets looked up both by queriers and store-gateways.\nThis soft deletion mechanism is used to give enough time to queriers and store-gateways to discover the new compacted blocks before the old source blocks are deleted. If source blocks would be immediately hard deleted by the compactor, some queries involving the compacted blocks may fail until the queriers and store-gateways haven\u0026rsquo;t rescanned the bucket and found both deleted source blocks and the new compacted ones.\nCompactor disk utilization The compactor needs to download source blocks from the bucket to the local disk, and store the compacted block to the local disk before uploading it to the bucket. Depending on the largest tenants in your cluster and the configured -compactor.block-ranges, the compactor may need a lot of disk space.\nAssuming max_compaction_range_blocks_size is the total size of blocks for the largest tenant (you can measure it inspecting the bucket) and the longest -compactor.block-ranges period, the formula to estimate the minimum disk space required is:\nmin_disk_space_required = compactor.compaction-concurrency * max_compaction_range_blocks_size * 2 Alternatively, assuming the largest -compactor.block-ranges is 24h (default), you could consider 150GB of disk space every 10M active series owned by the largest tenant. For example, if your largest tenant has 30M active series and -compactor.compaction-concurrency=1 we would recommend having a disk with at least 450GB available.\nCompactor HTTP endpoints GET /compactor/ring\nDisplays the status of the compactors ring, including the tokens owned by each compactor and an option to remove (forget) instances from the ring. Compactor configuration This section described the compactor configuration. For the general Cortex configuration and references to common config blocks, please refer to the configuration documentation.\ncompactor_config The compactor_config configures the compactor for the blocks storage.\ncompactor:# List of compaction time ranges.# CLI flag: -compactor.block-ranges[block_ranges:\u0026lt;listofduration\u0026gt;|default=2h0m0s,12h0m0s,24h0m0s]# Number of Go routines to use when syncing block index and chunks files from# the long term storage.# CLI flag: -compactor.block-sync-concurrency[block_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Number of Go routines to use when syncing block meta files from the long# term storage.# CLI flag: -compactor.meta-sync-concurrency[meta_sync_concurrency:\u0026lt;int\u0026gt;|default=20]# Minimum age of fresh (non-compacted) blocks before they are being processed.# Malformed blocks older than the maximum of consistency-delay and 48h0m0s# will be removed.# CLI flag: -compactor.consistency-delay[consistency_delay:\u0026lt;duration\u0026gt;|default=0s]# Data directory in which to cache blocks and process compactions# CLI flag: -compactor.data-dir[data_dir:\u0026lt;string\u0026gt;|default=\u0026#34;./data\u0026#34;]# The frequency at which the compaction runs# CLI flag: -compactor.compaction-interval[compaction_interval:\u0026lt;duration\u0026gt;|default=1h]# How many times to retry a failed compaction during a single compaction# interval# CLI flag: -compactor.compaction-retries[compaction_retries:\u0026lt;int\u0026gt;|default=3]# Max number of concurrent compactions running.# CLI flag: -compactor.compaction-concurrency[compaction_concurrency:\u0026lt;int\u0026gt;|default=1]# Time before a block marked for deletion is deleted from bucket. If not 0,# blocks will be marked for deletion and compactor component will delete# blocks marked for deletion from the bucket. If delete-delay is 0, blocks# will be deleted straight away. Note that deleting blocks immediately can# cause query failures, if store gateway still has the block loaded, or# compactor is ignoring the deletion because it\u0026#39;s compacting the block at the# same time.# CLI flag: -compactor.deletion-delay[deletion_delay:\u0026lt;duration\u0026gt;|default=12h]# Shard tenants across multiple compactor instances. Sharding is required if# you run multiple compactor instances, in order to coordinate compactions and# avoid race conditions leading to the same tenant blocks simultaneously# compacted by different instances.# CLI flag: -compactor.sharding-enabled[sharding_enabled:\u0026lt;boolean\u0026gt;|default=false]sharding_ring:kvstore:# Backend storage to use for the ring. Supported values are: consul, etcd,# inmemory, memberlist, multi.# CLI flag: -compactor.ring.store[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;]# The prefix for the keys in the store. Should end with a /.# CLI flag: -compactor.ring.prefix[prefix:\u0026lt;string\u0026gt;|default=\u0026#34;collectors/\u0026#34;]# The consul_config configures the consul client.# The CLI flags prefix for this block config is: compactor.ring[consul:\u0026lt;consul_config\u0026gt;]# The etcd_config configures the etcd client.# The CLI flags prefix for this block config is: compactor.ring[etcd:\u0026lt;etcd_config\u0026gt;]multi:# Primary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.primary[primary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Secondary backend storage used by multi-client.# CLI flag: -compactor.ring.multi.secondary[secondary:\u0026lt;string\u0026gt;|default=\u0026#34;\u0026#34;]# Mirror writes to secondary store.# CLI flag: -compactor.ring.multi.mirror-enabled[mirror_enabled:\u0026lt;boolean\u0026gt;|default=false]# Timeout for storing value to secondary store.# CLI flag: -compactor.ring.multi.mirror-timeout[mirror_timeout:\u0026lt;duration\u0026gt;|default=2s]# Period at which to heartbeat to the ring.# CLI flag: -compactor.ring.heartbeat-period[heartbeat_period:\u0026lt;duration\u0026gt;|default=5s]# The heartbeat timeout after which compactors are considered unhealthy# within the ring.# CLI flag: -compactor.ring.heartbeat-timeout[heartbeat_timeout:\u0026lt;duration\u0026gt;|default=1m]# Name of network interface to read address from.# CLI flag: -compactor.ring.instance-interface-names[instance_interface_names:\u0026lt;listofstring\u0026gt;|default=[eth0en0]]","excerpt":"The compactor is an optional service which compacts multiple blocks of a given tenant into a single …","ref":"/docs/blocks-storage/compactor/","title":"Compactor"},{"body":"Context One option to scale the ruler is by scaling it horizontally. However, with multiple ruler instances running they will need to coordinate to determine which instance will evaluate which rule. Similar to the ingesters, the rulers establish a hash ring to divide up the responsibilities of evaluating rules.\nConfig In order to enable sharding in the ruler the following flag needs to be set:\n -ruler.enable-sharding=true In addition the ruler requires it\u0026rsquo;s own ring to be configured, for instance:\n -ruler.ring.consul.hostname=consul.dev.svc.cluster.local:8500 The only configuration that is required is to enable sharding and configure a key value store. From there the rulers will shard and handle the division of rules automatically.\nUnlike ingesters, rulers do not hand over responsibility: all rules are re-sharded randomly every time a ruler is added to or removed from the ring.\nRuler Storage The ruler supports six kinds of storage (configdb, azure, gcs, s3, swift, local). Most kinds of storage work with the sharded ruler configuration in an obvious way. i.e. configure all rulers to use the same backend.\nThe local implementation reads Prometheus recording rules off of the local filesystem. This is a read only backend that does not support the creation and deletion of rules through the API. Despite the fact that it reads the local filesystem this method can still be used in a sharded ruler configuration if the operator takes care to load the same rules to every ruler. For instance this could be accomplished by mounting a Kubernetes ConfigMap onto every ruler pod.\nA typical local config may look something like:\n -ruler.storage.type=local -ruler.storage.local.directory=/tmp/cortex/rules With the above configuration the ruler would expect the following layout:\n/tmp/cortex/rules/\u0026lt;tenant id\u0026gt;/rules1.yaml /rules2.yaml Yaml files are expected to be in the Prometheus format.\n","excerpt":"Context One option to scale the ruler is by scaling it horizontally. However, with multiple ruler …","ref":"/docs/guides/ruler-sharding/","title":"Config for horizontally scaling the Ruler"},{"body":"To upgrade the Golang version:\n Upgrade build image version Upgrade Golang version in build-image/Dockerfile Build new image make build-image/.uptodate Publish the new image to quay.io (requires a maintainer) Update the Docker image tag in .circleci/config.yml Upgrade integration tests version Update the Golang version installed in the integration job in .circleci/config.yml If the minimum support Golang version should be upgraded as well:\n Upgrade go version in go.mod ","excerpt":"To upgrade the Golang version:\n Upgrade build image version Upgrade Golang version in …","ref":"/docs/contributing/how-to-upgrade-golang-version/","title":"How to upgrade Golang version"},{"body":"This page shares some tips and things to take in consideration when setting up a production Cortex cluster based on the blocks storage.\nQuerier Ensure caching is enabled The querier relies on caching to reduce the number API calls to the storage bucket. Ensure caching is properly configured and properly scaled.\nAvoid querying non compacted blocks When running Cortex blocks storage cluster at scale, querying non compacted blocks may be inefficient for two reasons:\n Non compacted blocks contain duplicated samples (as effect of the ingested samples replication) Overhead introduced querying many small indexes Because of this, we would suggest to avoid querying non compacted blocks. In order to do it, you should:\n Run the compactor Configure queriers -querier.query-store-after large enough to give compactor enough time to compact newly uploaded blocks (see below) Configure queriers -querier.query-ingesters-within equal to -querier.query-store-after plus 5m (5 minutes is just a delta to query the boundary both from ingesters and queriers) Configure ingesters -blocks-storage.tsdb.retention-period at least as -querier.query-ingesters-within Lower -blocks-storage.bucket-store.ignore-deletion-marks-delay to 1h, otherwise non compacted blocks could be queried anyway, even if their compacted replacement is available How to estimate -querier.query-store-after The -querier.query-store-after should be set to a duration large enough to give compactor enough time to compact newly uploaded blocks, and queriers and store-gateways to discover and sync newly compacted blocks.\nThe following diagram shows all the timings involved in the estimation. This diagram should be used only as a template and you\u0026rsquo;re expected to tweak the assumptions based on real measurements in your Cortex cluster. In this example, the following assumptions have been done:\n An ingester takes up to 30 minutes to upload a block to the storage The compactor takes up to 3 hours to compact 2h blocks shipped from all ingesters Querier and store-gateways take up to 15 minutes to discover and load a new compacted block Given these assumptions, in the worst case scenario it would take up to 6h and 45m since when a sample has been ingested until that sample has been appended to a block flushed to the storage and that block has been vertically compacted with all other overlapping 2h blocks shipped from ingesters.\nStore-gateway Ensure caching is enabled The store-gateway heavily relies on caching both to speed up the queries and to reduce the number of API calls to the storage bucket. Ensure caching is properly configured and properly scaled.\nEnsure a high number of max open file descriptors The store-gateway stores each block’s index-header on the local disk and loads it via mmap. This means that the store-gateway keeps a file descriptor open for each loaded block. If your Cortex cluster has many blocks in the bucket, the store-gateway may hit the file-max ulimit (maximum number of open file descriptions by a process); in such case, we recommend increasing the limit on your system or running more store-gateway instances with blocks sharding enabled.\nCompactor Ensure the compactor has enough disk space The compactor generally needs a lot of disk space in order to download source blocks from the bucket and store the compacted block before uploading it to the storage. Please refer to Compactor disk utilization for more information about how to do capacity planning.\nCaching Ensure memcached is properly scaled The rule of thumb to ensure memcached is properly scaled is to make sure evictions happen infrequently. When that\u0026rsquo;s not the case and they affect query performances, the suggestion is to scale out the memcached cluster adding more nodes or increasing the memory limit of existing ones.\nWe also recommend to run a different memcached cluster for each cache type (metadata, index, chunks). It\u0026rsquo;s not required, but suggested to not worry about the effect of memory pressure on a cache type against others.\n","excerpt":"This page shares some tips and things to take in consideration when setting up a production Cortex …","ref":"/docs/blocks-storage/production-tips/","title":"Production tips"},{"body":"Requests mirroring (or shadowing) is a technique you can use to mirror requests from a primary Cortex cluster to a secondary one.\nFor example, requests mirroring can be used when you need to setup a testing Cortex cluster receiving the same series ingested by a primary one without having control over Prometheus remote write config (if you do, then configuring two remote write entries in Prometheus would be the preferred option).\nMirroring with Envoy proxy Envoy proxy can be used to mirror HTTP requests to a secondary upstream cluster. From a network path perspective, you should run Envoy in front of both clusters distributors, letting Envoy to proxy requests to the primary Cortex cluster and mirror them to a secondary cluster in background. The performances and availability of the secondary cluster have no impact on the requests to the primary one. The response to the client will always be the one from the primary one. In this sense, the requests from Envoy to the secondary cluster are \u0026ldquo;fire and forget\u0026rdquo;.\nExample Envoy config The following Envoy configuration shows an example with two Cortex clusters. Envoy will listen on port 9900 and will proxies all requests to cortex-primary:80, mirroring it to cortex-secondary:80 too.\nadmin:# No access logs.access_log_path:/dev/nulladdress:socket_address:{address: 0.0.0.0, port_value:9901}static_resources:listeners:- name:cortex_listeneraddress:socket_address:{address: 0.0.0.0, port_value:9900}filter_chains:- filters:- name:envoy.http_connection_managerconfig:stat_prefix:cortex_ingressroute_config:name:all_routesvirtual_hosts:- name:all_hostsdomains:[\u0026#34;*\u0026#34;]routes:- match:{prefix:\u0026#34;/\u0026#34;}route:cluster:cortex_primary# Specifies the upstream timeout. This spans between the point at which the entire downstream# request has been processed and when the upstream response has been completely processed.timeout:15s# Specifies the cluster that requests will be mirrored to. The performances and availability of# the secondary cluster have no impact on the requests to the primary one. The response to the# client will always be the one from the primary one. The requests from Envoy to the secondary# cluster are \u0026#34;fire and forget\u0026#34;.request_mirror_policies:- cluster:cortex_secondaryhttp_filters:- name:envoy.routerclusters:- name:cortex_primarytype:STRICT_DNSconnect_timeout:1shosts:[{socket_address:{address: cortex-primary, port_value:80}}]dns_refresh_rate:5s- name:cortex_secondarytype:STRICT_DNSconnect_timeout:1shosts:[{socket_address:{address: cortex-secondary, port_value:80}}]dns_refresh_rate:5s","excerpt":"Requests mirroring (or shadowing) is a technique you can use to mirror requests from a primary …","ref":"/docs/operations/requests-mirroring-to-secondary-cluster/","title":"Requests mirroring to secondary cluster"},{"body":"This guide covers how to run a single local Cortex instance - with the chunks storage engine - storing time series chunks and index in Cassandra.\nIn this guide we\u0026rsquo;re going to:\n Setup a locally running Cassandra Configure Cortex to store chunks and index on Cassandra Configure Prometheus to send series to Cortex Configure Grafana to visualise metrics Setup a locally running Cassandra Run Cassandra with the following command:\ndocker run -d --name cassandra --rm -p 9042:9042 cassandra:3.11 Use Docker to execute the Cassandra Query Language (CQL) shell in the container:\ndocker exec -it \u0026lt;container_id\u0026gt; cqlsh Create a new Cassandra keyspace for Cortex metrics:\nA keyspace is an object that is used to hold column families, user defined types. A keyspace is like RDBMS database which contains column families, indexes, user defined types.\nCREATE KEYSPACE cortex WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1}; Configure Cortex to store chunks and index on Cassandra Now, we have to configure Cortex to store the chunks and index in Cassandra. Create a config file called single-process-config.yaml, then add the content below. Make sure to replace the following placeholders:\n LOCALHOST: Addresses of your Cassandra instance. This can accept multiple addresses by passing them as comma separated values. KEYSPACE: The name of the Cassandra keyspace used to store the metrics. single-process-config.yaml\n# Configuration for running Cortex in single-process mode. # This should not be used in production. It is only for getting started # and development. # Disable the requirement that every request to Cortex has a # X-Scope-OrgID header. `fake` will be substituted in instead. auth_enabled: false server: http_listen_port: 9009 # Configure the server to allow messages up to 100MB. grpc_server_max_recv_msg_size: 104857600 grpc_server_max_send_msg_size: 104857600 grpc_server_max_concurrent_streams: 1000 distributor: shard_by_all_labels: true pool: health_check_ingesters: true ingester_client: grpc_client_config: # Configure the client to allow messages up to 100MB. max_recv_msg_size: 104857600 max_send_msg_size: 104857600 grpc_compression: gzip ingester: lifecycler: # The address to advertise for this ingester. Will be autodiscovered by # looking up address on eth0 or en0; can be specified if this fails. address: 127.0.0.1 # We want to start immediately and flush on shutdown. join_after: 0 final_sleep: 0s num_tokens: 512 # Use an in memory ring store, so we don't need to launch a Consul. ring: kvstore: store: inmemory replication_factor: 1 # Use cassandra as storage -for both index store and chunks store. schema: configs: - from: 2019-07-29 store: cassandra object_store: cassandra schema: v10 index: prefix: index_ period: 168h chunks: prefix: chunk_ period: 168h storage: cassandra: addresses: LOCALHOST # configure cassandra addresses here. keyspace: KEYSPACE # configure desired keyspace here. The latest tag is not published for the Cortex docker image. Visit quay.io/repository/cortexproject/cortex to find the latest stable version tag and use it in the command below (currently it is v1.4.0).\nRun Cortex using the latest stable version:\ndocker run -d --name=cortex -v $(pwd)/single-process-config.yaml:/etc/single-process-config.yaml -p 9009:9009 quay.io/cortexproject/cortex:v1.4.0 -config.file=/etc/single-process-config.yaml In case you prefer to run the master version, please follow this documentation on how to build Cortex from source.\nConfigure the index and chunk table options In order to create index and chunk tables on Cassandra, Cortex will use the default table options of your Cassandra. If you want to configure the table options, use the storage.cassandra.table_options property or cassandra.table-options flag. This configuration property is just string type and this value used as plain text on WITH option of table creation query. It is recommended to enclose the value of table_options in double-quotes because you should enclose strings of table options in quotes on Cassandra.\nFor example, suppose the name of index(or chunk) table is \u0026lsquo;test_table\u0026rsquo;. Details about column definitions of the table are omitted. If no table options configured, then Cortex will generate the query to create a table without a WITH clause to use default table options:\nCREATE TABLE IF NOT EXISTS cortex.test_table (...) If table options configured with table_options as below:\nstorage: cassandra: addresses: 127.0.0.1 keyspace: cortex table_options: \u0026quot;gc_grace_seocnds = 86400 AND comments = 'this is a test table' AND COMPACT STORAGE AND caching = { 'keys': 'ALL', 'rows_per_partition': 1024 }\u0026quot; Then Cortex will generate the query to create a table with a WITH clause as below:\nCREATE TABLE IF NOT EXISTS cortex.test_table (...) WITH gc_grace_seocnds = 86400 AND comments = 'this is a test table' AND COMPACT STORAGE AND caching = { 'keys': 'ALL', 'rows_per_partition': 1024 } Available settings of the table options on Cassandra depend on Cassandra version or storage which is compatible. For details about table options, see the official document of storage you are using.\nWARNING: Make sure there are no incorrect options and mistakes. Misconfigured table options may cause a failure in creating a table by Table Manager at runtime and seriously affect your Cortex.\nConfigure Prometheus to send series to Cortex Now that Cortex is up, it should be running on http://localhost:9009.\nAdd the following section to your Prometheus configuration file. This will configure the remote write to send metrics to Cortex.\nremote_write: - url: http://localhost:9009/api/prom/push Configure Grafana to visualise metrics Run grafana to visualise metrics from Cortex:\ndocker run -d --name=grafana -p 3000:3000 grafana/grafana Add a data source in Grafana by selecting Prometheus as the data source type and use the Cortex URL to query metrics: http://localhost:9009/api/prom.\nFinally, You can monitor Cortex\u0026rsquo;s reads \u0026amp; writes by creating the dashboard. You can follow this documentation to do so.\n","excerpt":"This guide covers how to run a single local Cortex instance - with the chunks storage engine - …","ref":"/docs/production/cassandra/","title":"Running Cortex with Cassandra"},{"body":"Cortex chunks storage uses a NoSQL Store to store its index and optionally an Object store to store its chunks. Cortex has overtime evolved its schema to be more optimal and better fit the use cases and query patterns that arose.\nThe schema configuration is used only by the chunks storage, while it\u0026rsquo;s not used by the blocks storage engine.\nSchema versions Currently there are 11 schemas that are used in production but we recommend running with the v9 schema for most use cases and v10 schema if you expect to have very high cardinality metrics. You can move from one schema to another if a new schema fits your purpose better, but you still need to configure Cortex to make sure it can read the old data in the old schemas.\nConfiguration You can configure the schemas using a YAML config file, that you can point to using the -schema-config-file flag. It has the following YAML spec:\nconfigs:[]\u0026lt;period_config\u0026gt;Where period_config is\n# In YYYY-MM-DD format, for example: 2020-03-01. from: \u0026lt;string\u0026gt; # The index client to use, valid options: aws-dynamo, bigtable, bigtable-hashed, cassandra, boltdb. store: \u0026lt;string\u0026gt; # The object client to use. If none is specified, `store` is used for storing chunks as well. Valid options: s3, aws-dynamo, bigtable, bigtable-hashed, gcs, cassandra, filesystem. object_store: \u0026lt;string\u0026gt; # The schema version to use. Valid ones are v1, v2, v3,... v6, v9, v10, v11. Recommended for production: v9 for most use cases or v10 if you expect to have very high cardinality metrics. schema: \u0026lt;string\u0026gt; index: \u0026lt;periodic_table_config\u0026gt; chunks: \u0026lt;periodic_table_config\u0026gt; Where periodic_table_config is\n# The prefix to use for the tables. prefix: \u0026lt;string\u0026gt; # We typically run Cortex with new tables every week to keep the index size low and to make retention easier. This sets the period at which new tables are created and used. Typically 1w (1week). period: \u0026lt;duration\u0026gt; # The tags that can be set on the dynamo table. tags: \u0026lt;map[string]string\u0026gt; Now an example of this file (also something recommended when starting out) is:\nconfigs: - from: \u0026quot;2020-03-01\u0026quot; # Or typically a week before the Cortex cluster was created. schema: v9 index: period: 1w prefix: cortex_index_ # Chunks section is optional and required only if you're not using a # separate object store. chunks: period: 1w prefix: cortex_chunks store: aws-dynamo/bigtable-hashed/cassandra/boltdb object_store: \u0026lt;above options\u0026gt;/s3/gcs/azure/filesystem An example of an advanced schema file with a lot of changes:\nconfigs: # Starting from 2018-08-23 Cortex should store chunks and indexes # on Google BigTable using weekly periodic tables. The chunks table # names will be prefixed with \u0026quot;dev_chunks_\u0026quot;, while index tables will be # prefixed with \u0026quot;dev_index_\u0026quot;. - from: \u0026quot;2018-08-23\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ store: gcp-columnkey # Starting 2018-02-13 we moved from BigTable to GCS for storing the chunks. - from: \u0026quot;2019-02-13\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: gcp-columnkey # Starting 2019-02-24 we moved our index from bigtable-columnkey to bigtable-hashed # which improves the distribution of keys. - from: \u0026quot;2019-02-24\u0026quot; schema: v9 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: bigtable-hashed # Starting 2019-03-05 we moved from v9 schema to v10 schema. - from: \u0026quot;2019-03-05\u0026quot; schema: v10 chunks: period: 1w prefix: dev_chunks_ index: period: 1w prefix: dev_index_ object_store: gcs store: bigtable-hashed Note how we started out with v9 and just Bigtable, but later migrated to GCS as the object store, finally moving to v10. This is a complex schema file showing several changes changes over the time, while a typical schema config file usually has just one or two schema versions.\nMigrating from flags to schema file Legacy versions of Cortex did support the ability to configure schema via flags. If you are still using flags, you need to migrate your configuration from flags to the config file.\nIf you\u0026rsquo;re using:\n chunk.storage-client: then set the corresponding object_store field correctly in the schema file. dynamodb.daily-buckets-from: then set the corresponding from date with v2 schema. dynamodb.base64-buckets-from: then set the corresponding from date with v3 schema. dynamodb.v{4,5,6,9}-schema-from: then set the corresponding from date with schema v{4,5,6,9} bigtable.column-key-from: then set the corresponding from date and use the store as bigtable-columnkey. dynamodb.use-periodic-tables: then set the right index and chunk fields with corresponding values from dynamodb.periodic-table.{prefix, period, tag} and dynamodb.chunk-table.{prefix, period, tag} flags. Note that the default period is 7 days, so please set the period as 168h in the config file if none is set in the flags. ","excerpt":"Cortex chunks storage uses a NoSQL Store to store its index and optionally an Object store to store …","ref":"/docs/configuration/schema-configuration/","title":"Schema Configuration"},{"body":"In order to query series inside blocks from object storage, the store-gateway has to know certain initial info from each block index. In order to achieve so, the store-gateway builds an index-header for each block and stores it on local disk; such index-header is built by downloading specific pieces of original block\u0026rsquo;s index and storing them on local disk. Index header is then used by store-gateway at query time.\nStore-gateways build the index-header with specific sections of the block\u0026rsquo;s index downloaded using GET byte range requests. Since downloading specific sections of the original block\u0026rsquo;s index is a computationally easy operation, the index-header is never uploaded back to the object storage and multiple store-gateway instances (or the same instance after a rolling update without a persistent disk) will re-build the index-header from original block\u0026rsquo;s index each time, if not already existing on local disk.\nFormat (version 1) The index-header is a subset of the block index and contains:\n Symbol Table, used to unintern string values Posting Offset Table, used to lookup postings The following describes the format of the index-header file found in each block store-gateway local directory. It is terminated by a table of contents which serves as an entry point into the index.\n┌─────────────────────────────┬───────────────────────────────┐ │ magic(0xBAAAD792) \u0026lt;4b\u0026gt; │ version(1) \u0026lt;1 byte\u0026gt; │ ├─────────────────────────────┬───────────────────────────────┤ │ index version(2) \u0026lt;1 byte\u0026gt; │ index PostingOffsetTable \u0026lt;8b\u0026gt; │ ├─────────────────────────────┴───────────────────────────────┤ │ ┌─────────────────────────────────────────────────────────┐ │ │ │ Symbol Table (exact copy from original index) │ │ │ ├─────────────────────────────────────────────────────────┤ │ │ │ Posting Offset Table (exact copy from index) │ │ │ ├─────────────────────────────────────────────────────────┤ │ │ │ TOC │ │ │ └─────────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ ","excerpt":"In order to query series inside blocks from object storage, the store-gateway has to know certain …","ref":"/docs/blocks-storage/binary-index-header/","title":"Binary index-header"},{"body":"Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many opportunities for using caching to accelerate queries and reduce cost. Cortex can use a cache for:\n The results of a whole query And for the chunk storage:\n Individual chunks Index lookups for one label on one day Reducing duplication of writes. This doc aims to describe what each cache does, how to configure them and how to tune them.\nCortex Caching Options Cortex can use various different technologies for caching - Memcached, Redis or an in-process FIFO cache. The recommended caching technology for production workloads is Memcached. Using Memcached in your Cortex install means results from one process can be re-used by another. In-process caching can cut fetch times slightly and reduce the load on Memcached, but can only be used by a single process.\nIf multiple caches are enabled for each caching opportunities, they will be tiered – writes will go to all caches, but reads will first go to the in-memory FIFO cache, then memcached, then redis.\nMemcached For small deployments you can use a single memcached cluster for all the caching opportunities – the keys do not collide.\nFor large deployments we recommend separate memcached deployments for each of the caching opportunities, as this allows more sophisticated sizing, monitoring and configuration of each cache. For help provisioning and monitoring memcached clusters using tanka, see the memcached jsonnet module and the memcached-mixin.\nCortex uses DNS SRV records to find the various memcached servers in a cluster. You should ensure your memcached servers are not behind any kind of load balancer. If deploying Cortex on Kubernetes, Cortex should be pointed at a memcached headless service.\nThe flags used to configure memcached are common for each caching caching opportunity, differentiated by a prefix:\n-\u0026lt;prefix\u0026gt;.cache.write-back-buffer int How many chunks to buffer for background write back. (default 10000) -\u0026lt;prefix\u0026gt;.cache.write-back-goroutines int How many goroutines to use to write back to memcache. (default 10) -\u0026lt;prefix\u0026gt;.memcached.batchsize int How many keys to fetch in each batch. -\u0026lt;prefix\u0026gt;.memcached.consistent-hash Use consistent hashing to distribute to memcache servers. -\u0026lt;prefix\u0026gt;.memcached.expiration duration How long keys stay in the memcache. -\u0026lt;prefix\u0026gt;.memcached.hostname string Hostname for memcached service to use when caching chunks. If empty, no memcached will be used. -\u0026lt;prefix\u0026gt;.memcached.max-idle-conns int Maximum number of idle connections in pool. (default 16) -\u0026lt;prefix\u0026gt;.memcached.parallelism int Maximum active requests to memcache. (default 100) -\u0026lt;prefix\u0026gt;.memcached.service string SRV service used to discover memcache servers. (default \u0026quot;memcached\u0026quot;) -\u0026lt;prefix\u0026gt;.memcached.timeout duration Maximum time to wait before giving up on memcached requests. (default 100ms) -\u0026lt;prefix\u0026gt;.memcached.update-interval duration Period with which to poll DNS for memcache servers. (default 1m0s) See the memcached_config and memcached_client_config documentation if you use a config file with Cortex.\nFIFO Cache (Experimental) The FIFO cache is an in-memory, in-process (non-shared) cache that uses a First-In-First-Out (FIFO) eviction strategy. The FIFO cache is useful for simple scenarios where deploying an additional memcached server is too much work, such as when experimenting with the Query Frontend. The FIFO cache can also be used in front of Memcached to reduce latency for commonly accessed keys. The FIFO cache stores a fixed number of entries, and therefore it’s memory usage depends on the caches value’s size.\nTo enable the FIFO cache, use the following flags:\n-\u0026lt;prefix\u0026gt;.cache.enable-fifocache Enable in-memory cache. -\u0026lt;prefix\u0026gt;.fifocache.duration duration The expiry duration for the cache. -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes int Maximum memory size of the cache. -\u0026lt;prefix\u0026gt;.fifocache.max-size-items int Maximum number of entries in the cache. See fifo_cache_config documentation if you use a config file with Cortex.\nRedis (Experimental) You can also use Redis for out-of-process caching; this is a relatively new addition to Cortex and is under active development.\n-\u0026lt;prefix\u0026gt;.redis.endpoint string Redis endpoint to use when caching chunks. If empty, no redis will be used. For Redis Server - Redis service endpoint For Redis Cluster - comma-separated list of Redis node's endpoints For Redis Sentinel - comma-separated list of Redis Sentinel endpoints -\u0026lt;prefix\u0026gt;.redis.master-name Redis Sentinel master group name. An empty string for Redis Server or Redis Cluster -\u0026lt;prefix\u0026gt;.redis.tls-enabled Enable connecting to redis with TLS. -\u0026lt;prefix\u0026gt;.redis.tls-insecure-skip-verify Skip validating server certificate. -\u0026lt;prefix\u0026gt;.redis.expiration duration How long keys stay in the redis. -\u0026lt;prefix\u0026gt;.redis.db int Database index. (default 0) -\u0026lt;prefix\u0026gt;.redis.pool-size int Maximum number of socket connections in pool. -\u0026lt;prefix\u0026gt;.redis.password value Password to use when connecting to redis. -\u0026lt;prefix\u0026gt;.redis.timeout duration Maximum time to wait before giving up on redis requests. (default 100ms) -\u0026lt;prefix\u0026gt;.redis.idle-timeout duration Amount of time after which client closes idle connections. -\u0026lt;prefix\u0026gt;.redis.max-connection-age duration Amount of time after which client closes connections. See redis_config documentation if you use a config file with Cortex.\nCortex Caching Opportunities Chunks Cache The chunk cache stores immutable compressed chunks. The cache is used by queries to reduce load on the chunk store. These are typically a few KB in size, and depend mostly on the duration and encoding of your chunks. The chunk cache is a write-through cache - chunks are written to the cache as they are flushed to the chunk store. This ensures the cache always contains the most recent chunks. Items stay in the cache indefinitely.\nThe chunk cache should be configured on the ingester, querier and ruler using the flags with the prefix -store.chunks-cache.\nIt is best practice to ensure the chunk cache is big enough to accommodate at least 24 hours of chunk data. You can use the following query (from the cortex-mixin) to estimate the required number of memcached replicas:\n// 4 x in-memory series size = 24hrs of data. ( 4 * sum by(cluster, namespace) ( cortex_ingester_memory_series{job=~\u0026quot;.+/ingester\u0026quot;} * cortex_ingester_chunk_size_bytes_sum{job=~\u0026quot;.+/ingester\u0026quot;} / cortex_ingester_chunk_size_bytes_count{job=~\u0026quot;.+/ingester\u0026quot;} ) / 1e9 ) \u0026gt; ( sum by (cluster, namespace) (memcached_limit_bytes{job=~\u0026quot;.+/memcached\u0026quot;}) / 1e9 ) Index Read Cache The index read cache stores entire rows from the inverted label index. The cache is used by queries to reduce load on the index. These are typically only a few KB in size, but can grow up to many MB for very high cardinality metrics. The index read cache is populated when there is a cache miss.\nThe index read cache should be configured on the querier and ruler, using the flags with the -store.index-cache-read prefix.\nQuery Results Cache The query results cache contains protobuf \u0026amp; snappy encoded query results. These query results can potentially be very large, and as such the maximum value size in memcached should be increased beyond the default 1M. The cache is populated when there is a cache miss. Items stay in the cache indefinitely.\nThe query results cache should be configured on the query-frontend using flags with -frontend prefix:\n -frontend.memcached.* flags to use Memcached backend -frontend.redis.* flags to use Redis backend -frontend.fifocache.* and -frontend.cache.enable-fifocache flags to use the per-process in-memory cache (not shared across multiple query-frontend instances) Please keep in mind to also enable -querier.cache-results=true and configure -querier.split-queries-by-interval=24h (24h is a good starting point).\nIndex Write Cache The index write cache is used to avoid re-writing index and chunk data which has already been stored in the back-end database, aka “deduplication”. This can reduce write load on your backend-database by around 12x.\nYou should not use in-process caching for the index write cache - most of the deduplication comes from replication between ingesters.\nThe index write cache contains row and column keys written to the index. If an entry is in the index write cache it will not be written to the index. As such, entries are only written to the index write cache after being successfully written to the index. Data stays in the index indefinitely or until it is evicted by newer entries.\nThe index write cache should be configures on the ingesters using flags with the -store.index-cache-write prefix.\n","excerpt":"Correctly configured caching is important for a production-ready Cortex cluster. Cortex has many …","ref":"/docs/production/caching/","title":"Caching in Cortex"},{"body":"Cortex integration tests are written in Go and based on a custom framework running Cortex and its dependencies in Docker containers and using the Go testing package for assertions. Integration tests run in CI for every PR, and can be easily executed locally during development (it just requires Docker).\nHow to run integration tests When integration tests run in CI, we build the Cortex docker image based on the PR code and then run the integration tests against it. When running tests locally you should build the Cortex Docker image first:\nmake ./cmd/cortex/.uptodate This will locally build the quay.io/cortexproject/cortex:latest image used by integration tests. Whenever the Cortex code changes (cmd/, pkg/ or vendors) you should rebuild the Cortex image, while it\u0026rsquo;s not necessary to rebuild it while developing integration tests.\nOnce the Docker image is built, you can run integration tests:\ngo test -v -tags=requires_docker ./integration/... If you want to run a single test you can use a filter. For example, to only run TestChunksStorageAllIndexBackends:\ngo test -v -tags=requires_docker ./integration -run \u0026quot;^TestChunksStorageAllIndexBackends$\u0026quot; Supported environment variables CORTEX_IMAGE\nDocker image used to run Cortex in integration tests (defaults to quay.io/cortexproject/cortex:latest) CORTEX_CHECKOUT_DIR\nThe absolute path of the Cortex repository local checkout (defaults to $GOPATH/src/github.com/cortexproject/cortex) \u0026ndash; E2E_TEMP_DIR\nThe absolute path to a directory where the integration test will create an additional temporary directory to store files generated during the test. \u0026ndash; E2E_NETWORK_NAME\nName of the docker network to create and use for integration tests. If no variable is set, defaults to e2e-cortex-test. The requires_docker tag Integration tests have requires_docker tag (// +build requires_docker line followed by empty line on top of Go files), to avoid running them unintentionally as they require Docker, e.g. by running go test ./... in main Cortex package.\nIsolation Each integration test runs in isolation. For each integration test, we do create a Docker network, start Cortex and its dependencies containers, push/query series to/from Cortex and run assertions on it. Once the test has done, both the Docker network and containers are terminated and deleted.\n","excerpt":"Cortex integration tests are written in Go and based on a custom framework running Cortex and its …","ref":"/docs/contributing/how-integration-tests-work/","title":"How integration tests work"},{"body":"The build image currently can only be updated by a Cortex maintainer. If you\u0026rsquo;re not a maintainer you can still open a PR with the changes, asking a maintainer to assist you publishing the updated image. The procedure is:\n Update build-image/Docker Build the image running make build-image/.uptodate Publish the image to the repository running docker push quay.io/cortexproject/build-image:TAG (this can only be done by a maintainer) Replace the image tag in .circleci/config.yml (there may be multiple references) Replace the image tag in .github/workflows/* (there may be multiple references) Open a PR and make sure the CI with new build-image passes ","excerpt":"The build image currently can only be updated by a Cortex maintainer. If you\u0026rsquo;re not a …","ref":"/docs/contributing/how-to-update-the-build-image/","title":"How to update the build image"},{"body":"Cortex exposes an HTTP API for pushing and querying time series data, and operating the cluster itself.\nFor the sake of clarity, in this document we have grouped API endpoints by service, but keep in mind that they\u0026rsquo;re exposed both when running Cortex in microservices and singly-binary mode:\n Microservices: each service exposes its own endpoints Single-binary: the Cortex process exposes all API endpoints for the services running internally Endpoints API Service Endpoint Index page All services GET / Configuration All services GET /config Services status All services GET /services Readiness probe All services GET /ready Metrics All services GET /metrics Remote write Distributor POST /api/v1/push Tenants stats Distributor GET /distributor/all_user_stats HA tracker status Distributor GET /distributor/ha_tracker Flush chunks / blocks Ingester GET,POST /ingester/flush Shutdown Ingester GET,POST /ingester/shutdown Ingesters ring status Ingester GET /ingester/ring Instant query Querier, Query-frontend GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/query Range query Querier, Query-frontend GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/query_range Get series by label matchers Querier, Query-frontend GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/series Get label names Querier, Query-frontend GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/labels Get label values Querier, Query-frontend GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/label/{name}/values Get metric metadata Querier, Query-frontend GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/metadata Remote read Querier, Query-frontend POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/read Get tenant ingestion stats Querier GET /api/v1/user_stats Get tenant chunks Querier GET /api/v1/chunks Ruler ring status Ruler GET /ruler/ring List rules Ruler GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/rules List alerts Ruler GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/alerts List rule groups Ruler GET /api/v1/rules Get rule groups by namespace Ruler GET /api/v1/rules/{namespace} Get rule group Ruler GET /api/v1/rules/{namespace}/{groupName} Set rule group Ruler POST /api/v1/rules/{namespace} Delete rule group Ruler DELETE /api/v1/rules/{namespace}/{groupName} Delete namespace Ruler DELETE /api/v1/rules/{namespace} Alertmanager status Alertmanager GET /multitenant_alertmanager/status Alertmanager UI Alertmanager GET /\u0026lt;alertmanager-http-prefix\u0026gt; Get Alertmanager configuration Alertmanager GET /api/v1/alerts Set Alertmanager configuration Alertmanager POST /api/v1/alerts Delete Alertmanager configuration Alertmanager DELETE /api/v1/alerts Delete series Purger PUT,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series List delete requests Purger GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series Cancel delete request Purger PUT,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/cancel_delete_request Store-gateway ring status Store-gateway GET /store-gateway/ring Compactor ring status Compactor GET /compactor/ring Get rule files Configs API (deprecated) GET /api/prom/configs/rules Set rule files Configs API (deprecated) POST /api/prom/configs/rules Get template files Configs API (deprecated) GET /api/prom/configs/templates Set template files Configs API (deprecated) POST /api/prom/configs/templates Get Alertmanager config file Configs API (deprecated) GET /api/prom/configs/alertmanager Set Alertmanager config file Configs API (deprecated) POST /api/prom/configs/alertmanager Validate Alertmanager config Configs API (deprecated) POST /api/prom/configs/alertmanager/validate Deactivate configs Configs API (deprecated) DELETE /api/prom/configs/deactivate Restore configs Configs API (deprecated) POST /api/prom/configs/restore Path prefixes In this documentation you will find the usage of some placeholders for the path prefixes, whenever the prefix is configurable. The following table shows the supported prefixes.\n Prefix Default CLI Flag YAML Config \u0026lt;legacy-http-prefix\u0026gt; /api/prom -http.prefix http_prefix \u0026lt;prometheus-http-prefix\u0026gt; /prometheus -http.prometheus-http-prefix api \u0026gt; prometheus_http_prefix \u0026lt;alertmanager-http-prefix\u0026gt; /alertmanager -http.alertmanager-http-prefix api \u0026gt; alertmanager_http_prefix Authentication When multi-tenancy is enabled, endpoints requiring authentication are expected to be called with the X-Scope-OrgID HTTP request header set to the tenant ID. Otherwise, when multi-tenancy is disabled, Cortex doesn\u0026rsquo;t require any request to have the X-Scope-OrgID header.\nMulti-tenancy can be enabled/disabled via the CLI flag -auth.enabled or its respective YAML config option.\nFor more information, please refer to the dedicated Authentication and Authorisation guide.\nAll services The following API endpoints are exposed by all services.\nIndex page GET / Displays an index page with links to other web pages exposed by Cortex.\nConfiguration GET /config Displays the configuration currently applied to Cortex (in YAML format), including default values and settings via CLI flags. Sensitive data is masked. Please be aware that the exported configuration doesn\u0026rsquo;t include the per-tenant overrides.\nServices status GET /services Displays a web page with the status of internal Cortex services.\nReadiness probe GET /ready Returns 200 when Cortex is ready to serve traffic.\nMetrics GET /metrics Returns the metrics for the running Cortex service in the Prometheus exposition format.\nDistributor Remote write POST /api/v1/push # Legacy POST \u0026lt;legacy-http-prefix\u0026gt;/push Entrypoint for the Prometheus remote write.\nThis API endpoint accepts an HTTP POST request with a body containing a request encoded with Protocol Buffers and compressed with Snappy. The definition of the protobuf message can be found in cortex.proto. The HTTP request should contain the header X-Prometheus-Remote-Write-Version set to 0.1.0.\nFor more information, please check out Prometheus Remote storage integrations.\nRequires authentication.\nTenants stats GET /distributor/all_user_stats # Legacy GET /all_user_stats Displays a web page with per-tenant statistics updated in realtime, including the total number of active series across all ingesters and the current ingestion rate (samples / sec).\nHA tracker status GET /distributor/ha_tracker # Legacy GET /ha-tracker Displays a web page with the current status of the HA tracker, including the elected replica for each Prometheus HA cluster.\nIngester Flush chunks / blocks GET,POST /ingester/flush # Legacy GET,POST /flush Triggers a flush of the in-memory time series data (chunks or blocks) to the long-term storage. This endpoint triggers the flush also when -ingester.flush-on-shutdown-with-wal-enabled or -blocks-storage.tsdb.flush-blocks-on-shutdown are disabled.\nShutdown GET,POST /ingester/shutdown # Legacy GET,POST /shutdown Flushes in-memory time series data from ingester to the long-term storage, and shuts down the ingester service. Notice that the other Cortex services are still running, and the operator (or any automation) is expected to terminate the process with a SIGINT / SIGTERM signal after the shutdown endpoint returns. In the meantime, /ready will not return 200.\nThis API endpoint is usually used by scale down automations.\nIngesters ring status GET /ingester/ring # Legacy GET /ring Displays a web page with the ingesters hash ring status, including the state, healthy and last heartbeat time of each ingester.\nQuerier / Query-frontend The following endpoints are exposed both by the querier and query-frontend.\nInstant query GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/query # Legacy GET,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/query Prometheus-compatible instant query endpoint.\nFor more information, please check out the Prometheus instant query documentation.\nRequires authentication.\nRange query GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/query_range # Legacy GET,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/query_range Prometheus-compatible range query endpoint. When the request is sent through the query-frontend, the query will be accelerated by query-frontend (results caching and execution parallelisation).\nFor more information, please check out the Prometheus range query documentation.\nRequires authentication.\nGet series by label matchers GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/series # Legacy GET,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/series Find series by label matchers. Differently than Prometheus and due to scalability and performances reasons, Cortex currently ignores the start and end request parameters and always fetches the series from in-memory data stored in the ingesters.\nFor more information, please check out the Prometheus series endpoint documentation.\nRequires authentication.\nGet label names GET,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/labels # Legacy GET,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/labels Get label names of ingested series. Differently than Prometheus and due to scalability and performances reasons, Cortex currently ignores the start and end request parameters and always fetches the label names from in-memory data stored in the ingesters.\nFor more information, please check out the Prometheus get label names documentation.\nRequires authentication.\nGet label values GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/label/{name}/values # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/api/v1/label/{name}/values Get label values for a given label name. Differently than Prometheus and due to scalability and performances reasons, Cortex currently ignores the start and end request parameters and always fetches the label values from in-memory data stored in the ingesters.\nFor more information, please check out the Prometheus get label values documentation.\nRequires authentication.\nGet metric metadata GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/metadata # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/api/v1/metadata Prometheus-compatible metric metadata endpoint.\nFor more information, please check out the Prometheus metric metadata documentation.\nRequires authentication.\nRemote read POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/read # Legacy POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/read Prometheus-compatible remote read endpoint.\nFor more information, please check out Prometheus Remote storage integrations.\nRequires authentication.\nQuerier Get tenant ingestion stats GET /api/v1/user_stats # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/user_stats Returns realtime ingestion rate, for the authenticated tenant, in JSON format.\nRequires authentication.\nGet tenant chunks GET /api/v1/chunks # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/chunks Fetch a compressed tar of all the chunks containing samples for the given time range and label matchers. This endpoint is supported only by the chunks storage, requires -querier.ingester-streaming=true and should not be exposed to users but just used for debugging purposes.\n URL query parameter Description start Start timestamp, in RFC3339 format or unix epoch. end End timestamp, in RFC3339 format or unix epoch. matcher Label matcher that selects the series for which chunks should be fetched. Requires authentication.\nRuler The ruler API endpoints require to configure a backend object storage to store the recording rules and alerts. The ruler API uses the concept of a \u0026ldquo;namespace\u0026rdquo; when creating rule groups. This is a stand in for the name of the rule file in Prometheus and rule groups must be named uniquely within a namespace.\nRuler ring status GET /ruler/ring # Legacy GET /ruler_ring Displays a web page with the ruler hash ring status, including the state, healthy and last heartbeat time of each ruler.\nList rules GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/rules # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/api/v1/rules Prometheus-compatible rules endpoint to list alerting and recording rules that are currently loaded.\nFor more information, please check out the Prometheus rules documentation.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nList alerts GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/alerts # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/api/v1/alerts Prometheus-compatible rules endpoint to list of all active alerts.\nFor more information, please check out the Prometheus alerts documentation.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nList rule groups GET /api/v1/rules # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/rules List all rules configured for the authenticated tenant. This endpoint returns a YAML dictionary with all the rule groups for each namespace and 200 status code on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nExample response ---\u0026lt;namespace1\u0026gt;:- name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:- record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;- alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;- name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:- record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;- alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;\u0026lt;namespace2\u0026gt;:- name:\u0026lt;string\u0026gt; interval: \u0026lt;duration;optional\u0026gt;rules:- record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;- alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;Get rule groups by namespace GET /api/v1/rules/{namespace} # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/rules/{namespace} Returns the rule groups defined for a given namespace.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nExample response name:\u0026lt;string\u0026gt;interval:\u0026lt;duration;optional\u0026gt;rules:- record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;- alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;Get rule group GET /api/v1/rules/{namespace}/{groupName} # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/rules/{namespace}/{groupName} Returns the rule group matching the request namespace and group name.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nSet rule group POST /api/v1/rules/{namespace} # Legacy POST \u0026lt;legacy-http-prefix\u0026gt;/rules/{namespace} Creates or updates a rule group. This endpoint expects a request with Content-Type: application/yaml header and the rules YAML definition in the request body, and returns 202 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nExample request Request headers:\n Content-Type: application/yaml Request body:\nname:\u0026lt;string\u0026gt;interval:\u0026lt;duration;optional\u0026gt;rules:- record:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;- alert:\u0026lt;string\u0026gt; expr: \u0026lt;string\u0026gt;for:\u0026lt;duration\u0026gt; annotations:\u0026lt;annotation_name\u0026gt;:\u0026lt;string\u0026gt; labels:\u0026lt;label_name\u0026gt;:\u0026lt;string\u0026gt;Delete rule group DELETE /api/v1/rules/{namespace}/{groupName} # Legacy DELETE \u0026lt;legacy-http-prefix\u0026gt;/rules/{namespace}/{groupName} Deletes a rule group by namespace and group name. This endpoints returns 202 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nDelete namespace DELETE /api/v1/rules/{namespace} # Legacy DELETE \u0026lt;legacy-http-prefix\u0026gt;/rules/{namespace} Deletes all the rule groups in a namespace (including the namespace itself). This endpoint returns 202 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.ruler.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nAlertmanager Alertmanager status GET /multitenant_alertmanager/status # Legacy (microservices mode only) GET /status Displays a web page with the current status of the Alertmanager, including the Alertmanager cluster members.\nAlertmanager UI GET /\u0026lt;alertmanager-http-prefix\u0026gt; # Legacy (microservices mode only) GET /\u0026lt;legacy-http-prefix\u0026gt; Displays the Alertmanager UI.\nRequires authentication.\nGet Alertmanager configuration GET /api/v1/alerts Get the current Alertmanager configuration for the authenticated tenant, reading it from the configured object storage.\nThis endpoint doesn\u0026rsquo;t accept any URL query parameter and returns 200 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.alertmanager.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nSet Alertmanager configuration POST /api/v1/alerts Stores or updates the Alertmanager configuration for the authenticated tenant. The Alertmanager configuration is stored in the configured backend object storage.\nThis endpoint expects the Alertmanager YAML configuration in the request body and returns 201 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.alertmanager.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nExample request body template_files:default_template:| {{ define \u0026#34;__alertmanager\u0026#34; }}AlertManager{{ end }}{{define\u0026#34;__alertmanagerURL\u0026#34;}}{{.ExternalURL}}/#/alerts?receiver={{ .Receiver | urlquery }}{{ end }}alertmanager_config:| global:smtp_smarthost:\u0026#39;localhost:25\u0026#39;smtp_from:\u0026#39;youraddress@example.org\u0026#39;templates:- \u0026#39;default_template\u0026#39;route:receiver:example-emailreceivers:- name:example-emailemail_configs:- to:\u0026#39;youraddress@example.org\u0026#39;Delete Alertmanager configuration DELETE /api/v1/alerts Deletes the Alertmanager configuration for the authenticated tenant.\nThis endpoint doesn\u0026rsquo;t accept any URL query parameter and returns 200 on success.\nThis experimental endpoint is disabled by default and can be enabled via the -experimental.alertmanager.enable-api CLI flag (or its respective YAML config option).\nRequires authentication.\nPurger The Purger service provides APIs for requesting deletion of series in chunks storage and managing delete requests. For more information about it, please read the Delete series Guide.\nDelete series PUT,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series # Legacy PUT,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series Prometheus-compatible delete series endpoint.\nFor more information, please check out the Prometheus delete series documentation.\nRequires authentication.\nList delete requests GET \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series # Legacy GET \u0026lt;legacy-http-prefix\u0026gt;/api/v1/admin/tsdb/delete_series List all the delete requests.\nRequires authentication.\nCancel delete request PUT,POST \u0026lt;prometheus-http-prefix\u0026gt;/api/v1/admin/tsdb/cancel_delete_request # Legacy PUT,POST \u0026lt;legacy-http-prefix\u0026gt;/api/v1/admin/tsdb/cancel_delete_request Cancel a delete request while the request is still in the grace period (before the request is effectively processed by the purger and time series data is hard-deleted from the storage).\n URL query parameter Description request_id Deletion request ID to cancel. Can be obtained by the List delete requests endpoint. Requires authentication.\nStore-gateway Store-gateway ring status GET /store-gateway/ring Displays a web page with the store-gateway hash ring status, including the state, healthy and last heartbeat time of each store-gateway.\nCompactor Compactor ring status GET /compactor/ring Displays a web page with the compactor hash ring status, including the state, healthy and last heartbeat time of each compactor.\nConfigs API This service has been deprecated in favour of Ruler and Alertmanager API.\nThe configs API service provides an API-driven multi-tenant approach to handling various configuration files for Prometheus. The service hosts an API where users can read and write Prometheus rule files, Alertmanager configuration files, and Alertmanager templates to a database. Each tenant will have its own set of rule files, Alertmanager config, and templates.\nRequest / response schema The following schema is used both when retrieving the current configs from the API and when setting new configs via the API:\n{ \u0026#34;id\u0026#34;: 99, \u0026#34;rule_format_version\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;alertmanager_config\u0026#34;: \u0026#34;\u0026lt;standard alertmanager.yaml config\u0026gt;\u0026#34;, \u0026#34;rules_files\u0026#34;: { \u0026#34;rules.yaml\u0026#34;: \u0026#34;\u0026lt;standard rules.yaml config\u0026gt;\u0026#34;, \u0026#34;rules2.yaml\u0026#34;: \u0026#34;\u0026lt;standard rules.yaml config\u0026gt;\u0026#34; }, \u0026#34;template_files\u0026#34;: { \u0026#34;templates.tmpl\u0026#34;: \u0026#34;\u0026lt;standard template file\u0026gt;\u0026#34;, \u0026#34;templates2.tmpl\u0026#34;: \u0026#34;\u0026lt;standard template file\u0026gt;\u0026#34; } } id\nShould be incremented every time data is updated; Cortex will use the config with the highest number. rule_format_version\nAllows compatibility for tenants with config in Prometheus V1 format. Pass \u0026ldquo;1\u0026rdquo; or \u0026ldquo;2\u0026rdquo; according to which Prometheus version you want to match. alertmanager_config\nThe contents of the alertmanager config file should be as described here, encoded as a single string to fit within the overall JSON payload. config.rules_files\nThe contents of a rules file should be as described here, encoded as a single string to fit within the overall JSON payload. config.template_files\nThe contents of a template file should be as described here, encoded as a single string to fit within the overall JSON payload. These entries should match the templates entries in alertmanager_config. Example: template_files:myorg.tmpl:| {{ define \u0026#34;__alertmanager\u0026#34; }}AlertManager{{ end }}{{define\u0026#34;__alertmanagerURL\u0026#34;}}{{.ExternalURL}}/#/alerts?receiver={{ .Receiver | urlquery }}{{ end }}alertmanager_config:| templates:- \u0026#39;myorg.tmpl\u0026#39; Get rule files GET /api/prom/configs/rules Get the current rule files for the authenticated tenant.\nRequires authentication.\nSet rule files POST /api/prom/configs/rules Replace the current rule files for the authenticated tenant.\nRequires authentication.\nGet template files GET /api/prom/configs/templates Get the current template files for the authenticated tenant.\nRequires authentication.\nSet template files POST /api/prom/configs/templates Replace the current template files for the authenticated tenant.\nRequires authentication.\nGet Alertmanager config file GET /api/prom/configs/alertmanager Get the current Alertmanager config for the authenticated tenant.\nRequires authentication.\nSet Alertmanager config file POST /api/prom/configs/alertmanager Replace the current Alertmanager config for the authenticated tenant.\nRequires authentication.\nValidate Alertmanager config file POST /api/prom/configs/alertmanager/validate Validate the Alertmanager config in the request body. The request body is expected to contain only the Alertmanager YAML config.\nDeactivate configs DELETE /api/prom/configs/deactivate Disable configs for the authenticated tenant. Please be aware that setting a new config will effectively \u0026ldquo;re-enable\u0026rdquo; the Rules and Alertmanager configuration for the tenant.\nRequires authentication.\nRestore configs POST /api/prom/configs/restore Re-enable configs for the authenticated tenant, after being previously deactivated.\nRequires authentication.\n","excerpt":"Cortex exposes an HTTP API for pushing and querying time series data, and operating the cluster …","ref":"/docs/api/","title":"HTTP API"},{"body":"Currently the ingesters running in the chunks storage mode, store all their data in memory. If there is a crash, there could be loss of data. WAL helps fill this gap in reliability.\nTo use WAL, there are some changes that needs to be made in the deployment.\nChanges to deployment Since ingesters need to have the same persistent volume across restarts/rollout, all the ingesters should be run on statefulset with fixed volumes.\n Following flags needs to be set\n --ingester.wal-enabled to true which enables writing to WAL during ingestion. --ingester.wal-dir to the directory where the WAL data should be stores and/or recovered from. Note that this should be on the mounted volume. --ingester.checkpoint-duration to the interval at which checkpoints should be created. Default is 30m, and depending on the number of series, it can be brought down to 15m if there are less series per ingester (say 1M). --ingester.recover-from-wal to true to recover data from an existing WAL. The data is recovered even if WAL is disabled and this is set to true. The WAL dir needs to be set for this. If you are going to enable WAL, it is advisable to always set this to true. --ingester.tokens-file-path should be set to the filepath where the tokens should be stored. Note that this should be on the mounted volume. Why this is required is described below. Changes in lifecycle when WAL is enabled Flushing of data to chunk store during rollouts or scale down is disabled. This is because during a rollout of statefulset there are no ingesters that are simultaneously leaving and joining, rather the same ingester is shut down and brought back again with updated config. Hence flushing is skipped and the data is recovered from the WAL.\n As there are no transfers between ingesters, the tokens are stored and recovered from disk between rollout/restarts. This is not a new thing but it is effective when using statefulsets.\n Disk space requirements Based on tests in real world:\n Numbers from an ingester with 1.2M series, ~80k samples/s ingested and ~15s scrape interval. Checkpoint period was 20mins, so we need to scale up the number of WAL files to account for the default of 30mins. There were 87 WAL files (an upper estimate) in 20 mins. At any given point, we have 2 complete checkpoints present on the disk and a 2 sets of WAL files between checkpoints (and now). This peaks at 3 checkpoints and 3 lots of WAL momentarily, as we remove the old checkpoints. Observation Disk utilisation Size of 1 checkpoint for 1.2M series 1410 MiB Avg checkpoint size per series 1.2 KiB No. of WAL files between checkpoints (30m checkpoint) 30 mins x 87 / 20mins = 130 Size per WAL file 32 MiB (reduced from Prometheus) Total size of WAL 4160 MiB Steady state usage 2 x 1410 MiB + 2 x 4160 MiB = ~11 GiB Peak usage 3 x 1410 MiB + 3 x 4160 MiB = ~16.3 GiB For 1M series at 15s scrape interval with checkpoint duration of 30m\n Usage Disk utilisation Steady state usage 11 GiB / 1.2 = ~9.2 GiB Peak usage 17 GiB / 1.2 = ~13.6 GiB You should not target 100% disk utilisation; 70% is a safer margin, hence for a 1M active series ingester, a 20GiB disk should suffice.\nMigrating from stateless deployments The ingester deployment without WAL and statefulset with WAL should be scaled down and up respectively in sync without transfer of data between them to ensure that any ingestion after migration is reliable immediately.\nLet\u0026rsquo;s take an example of 4 ingesters. The migration would look something like this:\n Bring up one stateful ingester ingester-0 and wait till it\u0026rsquo;s ready (accepting read and write requests). Scale down old ingester deployment to 3 and wait till the leaving ingester flushes all the data to chunk store. Once that ingester has disappeared from kc get pods ..., add another stateful ingester and wait till it\u0026rsquo;s ready. This assures not transfer. Now you have ingester-0 ingester-1. Repeat step 2 to reduce remove another ingester from old deployment. Repeat step 3 to add another stateful ingester. Now you have ingester-0 ingester-1 ingester-2. Repeat step 4 and 5, and now you will finally have ingester-0 ingester-1 ingester-2 ingester-3. How to scale up/down Scale up Scaling up is same as what you would do without WAL or statefulsets. Nothing to change here.\nScale down Since Kubernetes doesn\u0026rsquo;t differentiate between rollout and scale down when sending a signal, the flushing of chunks is disabled by default. Hence the only thing to take care during scale down is flushing of chunks.\nThere are 2 ways to do it, with the latter being a fallback option.\nFirst option Consider you have 4 ingesters ingester-0 ingester-1 ingester-2 ingester-3 and you want to scale down to 2 ingesters, the ingesters which will be shutdown according to statefulset rules are ingester-3 and then ingester-2.\nHence before actually scaling down in Kubernetes, port forward those ingesters and hit the /shutdown endpoint. This will flush the chunks and shut down the ingesters (while also removing itself from the ring).\nAfter hitting the endpoint for ingester-2 ingester-3, scale down the ingesters to 2.\nPS: Given you have to scale down 1 ingester at a time, you can pipeline the shutdown and scaledown process instead of hitting shutdown endpoint for all to-be-scaled-down ingesters at the same time.\nFallback option\nThere is a flusher target that can be used to flush the data in the WAL. It\u0026rsquo;s config can be found here. As flusher depends on the chunk store and the http API components, you need to also set all the config related to them similar to ingesters (see api,storage,chunk_store,limits,runtime_config and schema). Pro tip: Re-use the ingester config and set the target as flusher with additional flusher config, the irrelevant config will be ignored.\nYou can run it as a Kubernetes job which will:\n Attach to the volume of the scaled down ingester. Recover from the WAL. And flush all the chunks. This job is to be run for all the PVCs linked to the ingesters that you missed hitting the shutdown endpoint as a first option.\nAdditional notes If you have lots of ingestion with the WAL replay taking a longer time, you can try reducing the checkpoint duration (--ingester.checkpoint-duration) to 15m. This would require slightly higher disk bandwidth for writes (still less in absolute terms), but it will reduce the WAL replay time overall. Non-Kubernetes or baremetal deployments When the ingester restarts for any reason (upgrade, crash, etc), it should be able to attach to the same volume in order to recover back the WAL and tokens. If it fails to attach to the same volume for any reason, use the flusher to flush that data. 2 ingesters should not be working with the same volume/directory for the WAL. It will cause data corruptions. Basing from above point, rollout should include bringing down an ingester completely and then starting the new ingester. Not the other way round, i.e. bringing another ingester live and taking the old one down. ","excerpt":"Currently the ingesters running in the chunks storage mode, store all their data in memory. If there …","ref":"/docs/production/ingesters-with-wal/","title":"Ingesters with WAL"},{"body":"This article describes how to migrate existing Cortex cluster from chunks storage to blocks storage, and highlight possible issues you may encounter in the process.\nThis document replaces the Cortex proposal, which was written before support for migration was in place.\nIntroduction This article assumes that:\n Cortex cluster is managed by Kubernetes Cortex is using chunks storage Ingesters are using WAL Cortex version 1.3.0 or later. If your ingesters are not using WAL, the documented procedure will still apply, but the presented migration script will not work properly without changes, as it assumes that ingesters are managed via StatefulSet.\nThe migration procedure is composed by 3 steps:\n Preparation Ingesters migration Cleanup In case of any issue during or after the migration, this document also outlines a Rollback strategy.\nStep 1: Preparation Before starting the migration of ingesters, we need to prepare other services.\nQuerier and Ruler Everything discussed for querier applies to ruler as well, since it shares querier configuration – CLI flags prefix is -querier even when used by ruler.\nQuerier and ruler need to be reconfigured as follow:\n -querier.second-store-engine=blocks -querier.query-store-after=0 -querier.ingester-streaming=false -querier.second-store-engine=blocks Querier (and ruler) needs to be reconfigured to query both chunks storage and blocks storage at the same time. This is achieved by using -querier.second-store-engine=blocks option, and providing querier with full blocks configuration, but keeping \u0026ldquo;primary\u0026rdquo; store set to -store.engine=chunks.\n-querier.query-store-after=0 Querier (and ruler) has an option -querier.query-store-after to query store only if query hits data older than some period of time. For example, if ingesters keep 12h of data in memory, there is no need to hit the store for queries that only need last 1h of data. During the migration, this flag needs to be set to 0, to make queriers always consult the store when handling queries. As chunks ingesters shut down, they flush chunks to the storage. They are then replaced with new ingesters configured to use blocks. Queriers cannot fetch recent chunks from ingesters directly (as blocks ingester don\u0026rsquo;t reload chunks), and need to use storage instead.\n-querier.ingester-streaming=false Querier (and ruler) in Cortex version 1.3.0 has a bug and doesn\u0026rsquo;t properly merge streamed results from chunks and blocks-based ingesters. Instead it only returns data from blocks instesters. To avoid this problem we can use newer Cortex release, or temporarily disable this feature by setting -querier.ingester-streaming=false. After migration is complete (i.e. all ingesters are running blocks only), this can be turned back to true, which is the default value.\nQuery-frontend Query-frontend needs to be reconfigured as follow:\n -querier.parallelise-shardable-queries=false -querier.parallelise-shardable-queries=false Query frontend has an option -querier.parallelise-shardable-queries to split some incoming queries into multiple queries based on sharding factor used in v11 schema of chunk storage. As the description implies, it only works when using chunks storage. During and after the migration to blocks (and also after possible rollback), this option needs to be disabled otherwise query-frontend will generate queries that cannot be satisfied by blocks storage.\nCompactor and Store-gateway Compactor and store-gateway services should be deployed and successfully up and running before migrating ingesters.\nIngester – blocks Migration script presented in Step 2 assumes that there are two StatefulSets of ingesters: existing one configured with chunks, and the new one with blocks. New StatefulSet with blocks ingesters should have 0 replicas at the beginning of migration.\nStep 2: Ingesters migration We have developed a script available in Cortex tools/migrate-ingester-statefulsets.sh to migrate ingesters between two StatefulSets, shutting down ingesters one by one.\nIt can be used like this:\n$ tools/migrate-ingester-statefulsets.sh \u0026lt;namespace\u0026gt; \u0026lt;ingester-old\u0026gt; \u0026lt;ingester-new\u0026gt; \u0026lt;num-instances\u0026gt; Where parameters are:\n \u0026lt;namespace\u0026gt;: Kubernetes namespace where the Cortex cluster is running \u0026lt;ingester-old\u0026gt;: name of the ingesters StatefulSet to scale down (running chunks storage) \u0026lt;ingester-new\u0026gt;: name of the ingesters StatefulSet to scale up (running blocks storage) \u0026lt;num-instances\u0026gt;: number of instances to scale down (in ingester-old statefulset) and scale up (in ingester-new), or \u0026ldquo;all\u0026rdquo; – which will scale down all remaining instances in ingester-old statefulset After starting new pod in ingester-new statefulset, script then triggers /shutdown endpoint on the old ingester. When the flushing on the old ingester is complete, scale down of statefulset continues, and process repeats.\nThe script supports both migration from chunks to blocks, and viceversa (eg. rollback).\nKnown issues There are few known issues with the script:\n If expected messages don\u0026rsquo;t appear in the log, but pod keeps on running, the script will never finish. Script doesn\u0026rsquo;t verify that flush finished without any error. Step 3: Cleanup When the ingesters migration finishes, there are still two StatefulSets, with original StatefulSet (running the chunks storage) having 0 instances now.\nAt this point, we can delete the old StatefulSet and its persistent volumes and recreate it with final blocks storage configuration (eg. changing PVs), and use the script again to move pods from ingester-blocks to ingester.\nQuerier (and ruler) can be reconfigured to use blocks as \u0026ldquo;primary\u0026rdquo; store to search, and chunks as secondary:\n -store.engine=blocks -querier.second-store-engine=chunks -querier.use-second-store-before-time=\u0026lt;timestamp after ingesters migration has completed\u0026gt; -querier.ingester-streaming=true -querier.use-second-store-before-time The CLI flag -querier.use-second-store-before-time (or its respective YAML config option) is only available for secondary store. This flag can be set to a timestamp when migration has finished, and it avoids querying secondary store (chunks) for data when running queries that don\u0026rsquo;t need data before given time.\n-querier.ingester-streaming=true If querier was configured to disable ingester streaming during migration (required for Cortex 1.3.0), Querier can be configured to make use of streamed responses from ingester at this point (-querier.ingester-streaming=true).\nRollback If rollback to chunks is needed for any reason, it is possible to use the same migration script with reversed arguments:\n Scale down ingesters StatefulSet running blocks storage Scale up ingesters StatefulSet running chunks storage Blocks ingesters support the same /shutdown endpoint for flushing data.\nDuring the rollback, queriers and rulers need to use the same configuration changes as during migration. You should also make sure the following settings are applied:\n -store.engine=chunks -querier.second-store-engine=blocks -querier.use-second-store-before-time should not be set -querier.ingester-streaming=false Once the rollback is complete, some configuration changes need to stay in place, because some data has already been stored to blocks:\n The query sharding in the query-frontend must be kept disabled, otherwise querying blocks will not work correctly store-gateway needs to keep running, otherwise querying blocks will fail compactor may be shutdown, after it has no more compaction work to do Kubernetes resources related to the ingesters running the blocks storage may be deleted.\nKnown issues After rollback, chunks ingesters will replay their old Write-Ahead-Log, thus loading old chunks into memory. WAL doesn\u0026rsquo;t remember whether these old chunks were already flushed or not, so they will be flushed again to the storage. Until that flush happens, Cortex reports those chunks as unflushed, which may trigger some alerts based on cortex_oldest_unflushed_chunk_timestamp_seconds metric.\nAppendix Jsonnet config This section shows how to use cortex-jsonnet to configure additional services.\nWe will assume that main.jsonnet is main configuration for the cluster, that also imports temp.jsonnet – with our temporary configuration for migration.\nIn main.jsonnet we have something like this:\nlocal cortex = import 'cortex/cortex.libsonnet'; local wal = import 'cortex/wal.libsonnet'; local temp = import 'temp.jsonnet'; // Note that 'tsdb' is not imported here. cortex + wal + temp { _images+:: (import 'images.libsonnet'), _config+:: { cluster: 'k8s-cluster', namespace: 'k8s-namespace', ... To configure querier to use secondary store for querying, we need to add:\n querier_second_storage_engine: 'blocks', blocks_storage_bucket_name: 'bucket-for-storing-blocks', to the _config object in main.jsonnet.\nLet\u0026rsquo;s generate blocks configuration now in temp.jsonnet. There are comments inside that should give you an idea about what\u0026rsquo;s happening. Most important thing is generating resources with blocks configuration, and exposing some of them.\n{ local cortex = import 'cortex/cortex.libsonnet', local tsdb = import 'cortex/tsdb.libsonnet', local rootConfig = self._config, local statefulSet = $.apps.v1beta1.statefulSet, // Prepare TSDB resources, but hide them. Cherry-picked resources will be exposed later. tsdb_config:: cortex + tsdb + { _config+:: { cluster: rootConfig.cluster, namespace: rootConfig.namespace, external_url: rootConfig.external_url, // This Cortex cluster is using the blocks storage. storage_tsdb_bucket_name: rootConfig.storage_tsdb_bucket_name, cortex_store_gateway_data_disk_size: '100Gi', cortex_compactor_data_disk_class: 'fast', }, // We create another statefulset for ingesters here, with different name. ingester_blocks_statefulset: self.newIngesterStatefulSet('ingester-blocks', self.ingester_container) + statefulSet.mixin.spec.withReplicas(0), ingester_blocks_pdb: self.newIngesterPdb('ingester-blocks-pdb', 'ingester-blocks'), ingester_blocks_service: $.util.serviceFor(self.ingester_blocks_statefulset, self.ingester_service_ignored_labels), }, _config+: { queryFrontend+: { // Disabled because querying blocks-data breaks if query is rewritten for sharding. sharded_queries_enabled: false, }, }, // Expose some services from TSDB configuration, needed for running Querier with Chunks as primary and TSDB as secondary store. tsdb_store_gateway_pdb: self.tsdb_config.store_gateway_pdb, tsdb_store_gateway_service: self.tsdb_config.store_gateway_service, tsdb_store_gateway_statefulset: self.tsdb_config.store_gateway_statefulset, tsdb_memcached_metadata: self.tsdb_config.memcached_metadata, tsdb_ingester_statefulset: self.tsdb_config.ingester_blocks_statefulset, tsdb_ingester_pdb: self.tsdb_config.ingester_blocks_pdb, tsdb_ingester_service: self.tsdb_config.ingester_blocks_service, tsdb_compactor_statefulset: self.tsdb_config.compactor_statefulset, // Querier and ruler configuration used during migration, and after. query_config_during_migration:: { // Disable streaming, as it is broken when querying both chunks and blocks ingesters at the same time. 'querier.ingester-streaming': 'false', // query-store-after is required during migration, since new ingesters running on blocks will not load any chunks from chunks-WAL. // All such chunks are however flushed to the store. 'querier.query-store-after': '0', }, query_config_after_migration:: { 'querier.ingester-streaming': 'true', 'querier.query-ingesters-within': '13h', // TSDB ingesters have data for up to 4d. 'querier.query-store-after': '12h', // Can be enabled once blocks ingesters are running for 12h. // Switch TSDB and chunks. TSDB is \u0026quot;primary\u0026quot; now so that we can skip querying chunks for old queries. // We can do this, because querier/ruler have both configurations. 'store.engine': 'blocks', 'querier.second-store-engine': 'chunks', 'querier.use-second-store-before-time': '2020-07-28T17:00:00Z', // If migration from chunks finished around 18:10 CEST, no need to query chunk store for queries before this time. }, querier_args+:: self.tsdb_config.blocks_metadata_caching_config + self.query_config_during_migration, // + self.query_config_after_migration, ruler_args+:: self.tsdb_config.blocks_metadata_caching_config + self.query_config_during_migration, // + self.query_config_after_migration, } ","excerpt":"This article describes how to migrate existing Cortex cluster from chunks storage to blocks storage, …","ref":"/docs/blocks-storage/migrate-cortex-cluster-from-chunks-to-blocks/","title":"Migrate Cortex cluster from chunks to blocks"},{"body":"Historically scaling the Cortex query frontend has posed some challenges. This document aims to detail how to use some of the added configuration parameters to correctly scale the frontend. Note that these instructions apply in both the HA single binary scenario or microservices mode.\nDNS Configuration / Readiness When a new frontend is first created on scale up it will not immediately have queriers attached to it. The existing endpoint /ready was updated to only return http 200 when the query frontend was ready to serve queries. Make sure to configure this endpoint as a healthcheck in your load balancer. Otherwise a query frontend scale up event might result in failed queries or high latency for a bit while queriers attach.\nQuerier Max Concurrency Make sure to configure the querier frontend worker to match max concurrency. This will allow the operator to freely scale the frontend up and down without impacting the amount of work an individual querier is attempting to perform. More details here.\nExample Configuration CLI\n-querier.worker-match-max-concurrent=true Config File\nfrontend_worker:match_max_concurrent:true","excerpt":"Historically scaling the Cortex query frontend has posed some challenges. This document aims to …","ref":"/docs/operations/scaling-query-frontend/","title":"Scaling the Query Frontend"},{"body":"Cortex is a distributed system with significant traffic between its services. To allow for secure communication, Cortex supports TLS between all its components. This guide describes the process of setting up TLS.\nGeneration of certs to configure TLS The first step to securing inter-service communication in Cortex with TLS is generating certificates. A Certifying Authority (CA) will be used for this purpose which should be private to the organization, as any certificates signed by this CA will have permissions to communicate with the cluster.\nWe will use the following script to generate self signed certs for the cluster:\n# keys openssl genrsa -out root.key openssl genrsa -out client.key openssl genrsa -out server.key # root cert / certifying authority openssl req -x509 -new -nodes -key root.key -subj \u0026quot;/C=US/ST=KY/O=Org/CN=root\u0026quot; -sha256 -days 100000 -out root.crt # csrs - certificate signing requests openssl req -new -sha256 -key client.key -subj \u0026quot;/C=US/ST=KY/O=Org/CN=client\u0026quot; -out client.csr openssl req -new -sha256 -key server.key -subj \u0026quot;/C=US/ST=KY/O=Org/CN=localhost\u0026quot; -out server.csr # certificates openssl x509 -req -in client.csr -CA root.crt -CAkey root.key -CAcreateserial -out client.crt -days 100000 -sha256 openssl x509 -req -in server.csr -CA root.crt -CAkey root.key -CAcreateserial -out server.crt -days 100000 -sha256 Note that the above script generates certificates that are valid for 100000 days. This can be changed by adjusting the -days option in the above commands. It is recommended that the certs be replaced atleast once every 2 years.\nThe above script generates keys client.key, server.key and certs client.crt, server.crt for both the client and server. The CA cert is generated as root.crt.\nLoad certs into the HTTP/GRPC server/client Every HTTP/GRPC link between Cortex components supports TLS configuration through the following config parameters:\nServer flags # Path to the TLS Cert for the HTTP Server -server.http-tls-cert-path=/path/to/server.crt # Path to the TLS Key for the HTTP Server -server.http-tls-key-path=/path/to/server.key # Type of Client Auth for the HTTP Server -server.http-tls-client-auth=\u0026quot;RequireAndVerifyClientCert\u0026quot; # Path to the Client CA Cert for the HTTP Server -server.http-tls-ca-path=\u0026quot;/path/to/root.crt\u0026quot; # Path to the TLS Cert for the GRPC Server -server.grpc-tls-cert-path=/path/to/server.crt # Path to the TLS Key for the GRPC Server -server.grpc-tls-key-path=/path/to/server.key # Type of Client Auth for the GRPC Server -server.grpc-tls-client-auth=\u0026quot;RequireAndVerifyClientCert\u0026quot; # Path to the Client CA Cert for the GRPC Server -server.grpc-tls-ca-path=/path/to/root.crt Client flags Client flags are component specific.\nFor an HTTP client in the Alertmanager:\n # Path to the TLS Cert for the HTTP Client -alertmanager.configs.tls-cert-path=/path/to/client.crt # Path to the TLS Key for the HTTP Client -alertmanager.configs.tls-key-path=/path/to/client.key # Path to the TLS CA for the HTTP Client -alertmanager.configs.tls-ca-path=/path/to/root.crt For a GRPC client in the Querier:\n # Path to the TLS Cert for the GRPC Client -querier.frontend-client.tls-cert-path=/path/to/client.crt # Path to the TLS Key for the GRPC Client -querier.frontend-client.tls-key-path=/path/to/client.key # Path to the TLS CA for the GRPC Client -querier.frontend-client.tls-ca-path=/path/to/root.crt Similarly, for the GRPC Ingester Client:\n # Path to the TLS Cert for the GRPC Client -ingester.client.tls-cert-path=/path/to/client.crt # Path to the TLS Key for the GRPC Client -ingester.client.tls-key-path=/path/to/client.key # Path to the TLS CA for the GRPC Client -ingester.client.tls-ca-path=/path/to/root.crt TLS can be configured in a similar fashion for other HTTP/GRPC clients in Cortex.\n","excerpt":"Cortex is a distributed system with significant traffic between its services. To allow for secure …","ref":"/docs/production/tls/","title":"Securing communication between Cortex components with TLS"},{"body":"Cortex leverages on sharding techniques to horizontally scale both single and multi-tenant clusters beyond the capacity of a single node.\nBackground The default sharding strategy employed by Cortex distributes the workload across the entire pool of instances running a given service (eg. ingesters). For example, on the write path each tenant\u0026rsquo;s series are sharded across all ingesters, regardless how many active series the tenant has or how many different tenants are in the cluster.\nThe default strategy allows to have a fair balance on the resources consumed by each instance (ie. CPU and memory) and to maximise these resources across the cluster.\nHowever, in a multi-tenant cluster this approach also introduces some downsides:\n An outage affects all tenants A misbehaving tenant (eg. causing out of memory) could affect all other tenants The goal of shuffle sharding is to provide an alternative sharding strategy to reduce the blast radius of an outage and better isolate tenants.\nWhat is shuffle sharding Shuffle sharding is a technique used to isolate different tenant\u0026rsquo;s workloads and to give each tenant a single-tenant experience even if they\u0026rsquo;re running in a shared cluster. This technique has been publicly shared and clearly explained by AWS in their builders\u0026rsquo; library and a reference implementation has been shown in the Route53 Infima library.\nThe idea is to assign each tenant a shard composed by a subset of the Cortex service instances, aiming to minimize the overlapping instances between two different tenants. Shuffle sharding brings the following benefits over the default sharding strategy:\n An outage on some Cortex cluster instances/nodes will only affect a subset of tenants. A misbehaving tenant will affect only its shard instances. Due to the low overlap of instances between different tenants, it\u0026rsquo;s statistically quite likely that any other tenant will run on different instances or only a subset of instances will match the affected ones. Low overlapping instances probability For example, given a Cortex cluster running 50 ingesters and assigning each tenant 4 out of 50 ingesters, shuffling instances between each tenant, we get 230K possible combinations.\nRandomly picking two different tenants we have the:\n 71% chance that they will not share any instance 26% chance that they will share only 1 instance 2.7% chance that they will share 2 instances 0.08% chance that they will share 3 instances Only a 0.0004% chance that their instances will fully overlap Cortex shuffle sharding Cortex currently supports shuffle sharding in the following services:\n Ingesters Query-frontend Store-gateway Ruler Shuffle sharding is disabled by default and needs to be explicitly enabled in the configuration.\nGuaranteed properties The Cortex shuffle sharding implementation guarantees the following properties:\n Stability\nGiven a consistent state of the hash ring, the shuffle sharding algorithm always selects the same instances for a given tenant, even across different machines. Consistency\nAdding or removing 1 instance from the hash ring leads to only 1 instance changed at most, in each tenant\u0026rsquo;s shard. Shuffling\nProbabilistically and for a large enough cluster, it ensures that every tenant gets a different set of instances, with a reduced number of overlapping instances between two tenants to improve failure isolation. Zone-awareness\nWhen zone-aware replication is enabled, the subset of instances selected for each tenant contains a balanced number of instances for each availability zone. Ingesters shuffle sharding By default the Cortex distributor spreads the received series across all running ingesters.\nWhen shuffle sharding is enabled via -distributor.sharding-strategy=shuffle-sharding (or its respective YAML config option), the distributor spreads each tenant series across -distributor.ingestion-tenant-shard-size number of ingesters.\nThe shard size can be overridden on a per-tenant basis in the limits overrides configuration.\nQuery-frontend shuffle sharding By default all Cortex queriers can execute received queries for given tenant.\nWhen shuffle sharding is enabled by setting -frontend.max-queriers-per-tenant (or its respective YAML config option) to a value higher than 0 and lower than the number of available queriers, only specified number of queriers will execute queries for single tenant. Note that this distribution happens in query-frontend. When not using query-frontend, this option is not available.\nThe maximum number of queriers can be overridden on a per-tenant basis in the limits overrides configuration.\nStore-gateway shuffle sharding The Cortex store-gateway \u0026ndash; used by the blocks storage \u0026ndash; by default spreads each tenant\u0026rsquo;s blocks across all running store-gateways.\nWhen shuffle sharding is enabled via -store-gateway.sharding-strategy=shuffle-sharding (or its respective YAML config option), each tenant blocks will be sharded across a subset of -store-gateway.tenant-shard-size store-gateway instances.\nThe shard size can be overridden on a per-tenant basis setting store_gateway_tenant_shard_size in the limits overrides configuration.\nPlease check out the store-gateway documentation for more information about how it works.\nRuler shuffle sharding Cortex ruler can run in three modes:\n No sharding at all. This is the most basic mode of the ruler. It is activated by using -ruler.enable-sharding=false (default) and works correctly only if single ruler is running. In this mode the Ruler loads all rules for all tenants. Default sharding, activated by using -ruler.enable-sharding=true and -ruler.sharding-strategy=default (default). In this mode rulers register themselves into the ring. Each ruler will then select and evaluate only those rules that it \u0026ldquo;owns\u0026rdquo;. Shuffle sharding, activated by using -ruler.enable-sharding=true and -ruler.sharding-strategy=shuffle-sharding. Similarly to default sharding, rulers use the ring to distribute workload, but rule groups for each tenant can only be evaluated on limited number of rulers (-ruler.tenant-shard-size, can also be set per tenant as ruler_tenant_shard_size in overrides). Note that when using sharding strategy, each rule group is evaluated by single ruler only, there is no replication.\n","excerpt":"Cortex leverages on sharding techniques to horizontally scale both single and multi-tenant clusters …","ref":"/docs/guides/shuffle-sharding/","title":"Shuffle Sharding"},{"body":"Configuration for running Cortex in single-process mode. This should not be used in production. It is only for getting started and development.\n# Configuration for running Cortex in single-process mode.# This configuration should not be used in production.# It is only for getting started and development.# Disable the requirement that every request to Cortex has a# X-Scope-OrgID header. `fake` will be substituted in instead.auth_enabled:falseserver:http_listen_port:9009# Configure the server to allow messages up to 100MB.grpc_server_max_recv_msg_size:104857600grpc_server_max_send_msg_size:104857600grpc_server_max_concurrent_streams:1000distributor:shard_by_all_labels:truepool:health_check_ingesters:trueingester_client:grpc_client_config:# Configure the client to allow messages up to 100MB.max_recv_msg_size:104857600max_send_msg_size:104857600grpc_compression:gzipingester:# We want our ingesters to flush chunks at the same time to optimise# deduplication opportunities.spread_flushes:truechunk_age_jitter:0walconfig:wal_enabled:truerecover_from_wal:truewal_dir:/tmp/cortex/wallifecycler:# The address to advertise for this ingester. Will be autodiscovered by# looking up address on eth0 or en0; can be specified if this fails.# address: 127.0.0.1# We want to start immediately and flush on shutdown.join_after:0min_ready_duration:0sfinal_sleep:0snum_tokens:512tokens_file_path:/tmp/cortex/wal/tokens# Use an in memory ring store, so we don\u0026#39;t need to launch a Consul.ring:kvstore:store:inmemoryreplication_factor:1# Use local storage - BoltDB for the index, and the filesystem# for the chunks.schema:configs:- from:2019-07-29store:boltdbobject_store:filesystemschema:v10index:prefix:index_period:1wstorage:boltdb:directory:/tmp/cortex/indexfilesystem:directory:/tmp/cortex/chunksdelete_store:store:boltdbpurger:object_store_type:filesystemfrontend_worker:# Configure the frontend worker in the querier to match worker count# to max_concurrent on the queriers.match_max_concurrent:true# Configure the ruler to scan the /tmp/cortex/rules directory for prometheus# rules: https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#recording-rulesruler:enable_api:trueenable_sharding:falsestorage:type:locallocal:directory:/tmp/cortex/rules","excerpt":"Configuration for running Cortex in single-process mode. This should not be used in production. It …","ref":"/docs/configuration/single-process-config/","title":"Single-process"},{"body":"Cortex supports data replication for different services. By default, data is transparently replicated across the whole pool of service instances, regardless of whether these instances are all running within the same availability zone (or data center, or rack) or in different ones.\nIt is completely possible that all the replicas for the given data are held within the same availability zone, even if the Cortex cluster spans multiple zones. Storing multiple replicas for a given data within the same availability zone poses a risk for data loss if there is an outage affecting various nodes within a zone or a full zone outage.\nFor this reason, Cortex optionally supports zone-aware replication. When zone-aware replication is enabled, replicas for the given data are guaranteed to span across different availability zones. This requires Cortex cluster to run at least in a number of zones equal to the configured replication factor.\nThe Cortex services supporting zone-aware replication are:\n Distributors and Ingesters Store-gateways (blocks storage only) Distributors / Ingesters: time-series replication The Cortex time-series replication is used to hold multiple (typically 3) replicas of each time series in the ingesters.\nTo enable the zone-aware replication for the ingesters you should:\n Configure the availability zone for each ingester via the -ingester.availability-zone CLI flag (or its respective YAML config option) Rollout ingesters to apply the configured zone Enable time-series zone-aware replication via the -distributor.zone-awareness-enabled CLI flag (or its respective YAML config option). Please be aware this configuration option should be set to distributors, queriers and rulers. Store-gateways: blocks replication The Cortex store-gateway (used only when Cortex is running with the blocks storage) supports blocks sharding, used to horizontally scale blocks in a large cluster without hitting any vertical scalability limit.\nTo enable the zone-aware replication for the store-gateways, please refer to the store-gateway documentation.\nMinimum number of zones For Cortex to function correctly, there must be at least the same number of availability zones as the replication factor. For example, if the replication factor is configured to 3 (default for time-series replication), the Cortex cluster should be spread at least over 3 availability zones.\nIt is safe to have more zones than the replication factor, but it cannot be less. Having fewer availability zones than replication factor causes a replica write to be missed, and in some cases, the write fails if the availability zones count is too low.\nImpact on unbalanced zones Cortex requires that each zone runs the same number of instances of a given service for which the zone-aware replication is enabled. This guarantees a fair split of the workload across zones.\nOn the contrary, if zones are unbalanced, the zones with a lower number of instances would have an higher pressure on resources utilization (eg. CPU and memory) compared to zones with an higher number of instances.\nImpact on costs Depending on the underlying infrastructure being used, deploying Cortex across multiple availability zones may cause an increase in running costs as most cloud providers charge for inter availability zone networking. The most significant change would be for a Cortex cluster currently running in a single zone.\n","excerpt":"Cortex supports data replication for different services. By default, data is transparently …","ref":"/docs/guides/zone-aware-replication/","title":"Zone Aware Replication"},{"body":"All Cortex components take the tenant ID from a header X-Scope-OrgID on each request. They trust this value completely: if you need to protect your Cortex installation from accidental or malicious calls then you must add an additional layer of protection.\nTypically this means you run Cortex behind a reverse proxy, and you must ensure that all callers, both machines sending data over the remote_write interface and humans sending queries from GUIs, supply credentials which identify them and confirm they are authorised.\nWhen configuring the remote_write API in Prometheus there is no way to add extra headers. The user and password fields of http Basic auth, or Bearer token, can be used to convey the tenant ID and/or credentials.\nTo disable the multi-tenant functionality, you can pass the argument -auth.enabled=false to every Cortex component, which will set the OrgID to the string fake for every request.\n","excerpt":"All Cortex components take the tenant ID from a header X-Scope-OrgID on each request. They trust …","ref":"/docs/production/auth/","title":"Authentication and Authorisation"},{"body":"If you have configured your cluster to write new data to blocks, there is still a question about old data. Cortex can query both chunks and the blocks at the same time, but converting old chunks to blocks still has some benefits, like being able to decommission the chunks storage backend and save costs. This document presents set of tools for doing the conversion.\nOriginal design document for blocksconvert is also available.\nTools Cortex provides a tool called blocksconvert, which is actually collection of three tools for converting chunks to blocks.\nTools are:\n Scanner\nScans the chunks index database and produces so-called \u0026ldquo;plan files\u0026rdquo;, each file being a set of series and chunks for each series. Plan files are uploaded to the same object store bucket where blocks live. Scheduler\nLooks for plan files, and distributes them to builders. Scheduler has global view of overall conversion progress. Builder\nAsks scheduler for next plan file to work on, fetches chunks, puts them into TSDB block, and uploads the block to the object store. It repeats this process until there are no more plans. All tools start HTTP server (see -server.http* options) exposing the /metrics endpoint. All tools also start gRPC server (-server.grpc* options), but only Scheduler exposes services on it.\nScanner Scanner is started by running blocksconvert -target=scanner. Scanner requires configuration for accessing Cortex Index:\n -schema-config-file – this is standard Cortex schema file. -bigtable.instance, -bigtable.project – options for BigTable access. -blocks-storage.backend and corresponding -blocks-storage.* options for storing plan files. -scanner.output-dir – specifies local directory for writing plan files to. Finished plan files are deleted after upload to the bucket. List of scanned tables is also kept in this directory, to avoid scanning the same tables multiple times when Scanner is restarted. -scanner.allowed-users – comma-separated list of Cortex tenants that should have plans generated. If empty, plans for all found users are generated. -scanner.ignore-users-regex - If plans for all users are generated (-scanner.allowed-users is not set), then users matching this non-empty regular expression will be skipped. -scanner.tables-limit – How many tables should be scanned? By default all tables are scanned, but when testing scanner it may be useful to start with small number of tables first. -scanner.tables – Comma-separated list of tables to be scanned. Can be used to scan specific tables only. Note that schema is still used to find all tables first, and then this list is consulted to select only specified tables. Scanner will read the Cortex schema file to discover Index tables, and then it will start scanning them from most-recent table first, going back. For each table, it will fully read the table and generate a plan for each user and day stored in the table. Plan files are then uploaded to the configured blocks-storage bucket (at the -blocksconvert.bucket-prefix location prefix), and local copies are deleted. After that, scanner continues with the next table until it scans them all or -scanner.tables-limit is reached.\nNote that even though blocksconvert has options for configuring different Index store backends, it only supports BigTable at the moment.\nIt is expected that only single Scanner process is running. Scanner does the scanning of multiple table subranges concurrently.\nScanner exposes metrics with cortex_blocksconvert_scanner_ prefix, eg. total number of scanned index entries of different type, number of open files (scanner doesn\u0026rsquo;t close currently plan files until entire table has been scanned), scanned BigTable rows and parsed index entries.\nScanner only supports schema version v9, v10 and v11. Earlier schema versions are currently not supported.\nScheduler Scheduler is started by running blocksconvert -target=scheduler. It only needs to be configured with options to access the object store with blocks:\n -blocks-storage.* - Blocks storage object store configuration. -scheduler.scan-interval – How often to scan for plan files and their status. -scheduler.allowed-users – Comma-separated list of Cortex tenants. If set, only plans for these tenants will be offered to Builders. It is expected that only single Scheduler process is running. Schedulers consume very little resources.\nScheduler\u0026rsquo;s metrics have cortex_blocksconvert_scheduler prefix (number of plans in different states, oldest/newest plan). Scheduler HTTP server also exposes /plans page that shows currently queued plans, and all plans and their status for all users.\nBuilder Builder asks scheduler for next plan to work on, downloads the plan, builds the block and uploads the block to the blocks storage. It then repeats the process while there are still plans.\nBuilder is started by blocksconvert -target=builder. It needs to be configured with Scheduler endpoint, Cortex schema file, chunk-store specific options and blocks storage to upload blocks to.\n -builder.scheduler-endpoint - where to find scheduler, eg. \u0026ldquo;scheduler:9095\u0026rdquo; -schema-config-file - Cortex schema file, used to find out which chunks store to use for given plan -gcs.bucketname – when using GCS as chunks store (other chunks backend storages, like S3, are supported as well) -blocks-storage.* - blocks storage configuration -builder.output-dir - Local directory where Builder keeps the block while it is being built. Once block is uploaded to blocks storage, it is deleted from local directory. Multiple builders may run at the same time, each builder will receive different plan to work on from scheduler. Builders are CPU intensive (decoding and merging chunks), and require fast disk IO for writing blocks.\nBuilders\u0026rsquo;s metrics have cortex_blocksconvert_builder prefix, and include total number of fetched chunks and their size, read position of the current plan and plan size, total number of written series and samples, number of chunks that couldn\u0026rsquo;t be downloaded.\nLimitations The blocksconvert toolset currently has the following limitations:\n Supports only BigTable for chunks index backend Supports only chunks schema versions v9, v10 and v11 ","excerpt":"If you have configured your cluster to write new data to blocks, there is still a question about old …","ref":"/docs/blocks-storage/convert-long-term-storage-from-chunks-to-blocks/","title":"Convert long-term storage from chunks to blocks"},{"body":"","excerpt":"","ref":"/docs/guides/","title":"Guides"},{"body":"For the v1.0 release, we want to provide the following guarantees:\nFlags, Config and minor version upgrades Upgrading cortex from one minor version to the next should \u0026ldquo;just work\u0026rdquo;; that being said, we don\u0026rsquo;t want to bump the major version every time we remove a flag, so we will will keep deprecated flags around for 2 minor release. There is a metric (cortex_deprecated_flags_inuse_total) you can alert on to find out if you\u0026rsquo;re using a deprecated flag.\nSimilarly to flags, minor version upgrades using config files should \u0026ldquo;just work\u0026rdquo;. If we do need to change config, we will keep the old way working for two minor version. There will be a metric you can alert on for this too.\nThese guarantees don\u0026rsquo;t apply for experimental features.\nReading old data The Cortex maintainers commit to ensuring future version of Cortex can read data written by versions up to two years old. In practice we expect to be able to read more, but this is our guarantee.\nAPI Compatibility Cortex strives to be 100% API compatible with Prometheus (under /api/prom/*); any deviation from this is considered a bug, except:\n Requiring the __name__ label on queries when querying the chunks storage (queries to ingesters or clusters running the blocks storage are not affected). For queries to the /api/v1/series, /api/v1/labels and /api/v1/label/{name}/values endpoints, query\u0026rsquo;s time range is ignored and the data is always fetched from ingesters. Additional API endpoints for creating, removing and modifying alerts and recording rules. Additional API around pushing metrics (under /api/push). Additional API endpoints for management of Cortex itself, such as the ring. These APIs are not part of the any compatibility guarantees. Experimental features Cortex is an actively developed project and we want to encourage the introduction of new features and capability. As such, not everything in each release of Cortex is considered \u0026ldquo;production-ready\u0026rdquo;. We don\u0026rsquo;t provide any backwards compatibility guarantees on these and the config and flags might break.\nCurrently experimental features are:\n Azure blob storage. Zone awareness based replication. Shuffle sharding (both read and write path). Ruler API (to PUT rules). Alertmanager API Memcached client DNS-based service discovery. Delete series APIs. In-memory (FIFO) and Redis cache. Openstack Swift storage. gRPC Store. Querier support for querying chunks and blocks store at the same time. Tracking of active series and exporting them as metrics (-ingester.active-series-metrics-enabled and related flags) Shuffle-sharding of queriers in the query-frontend (i.e. use of -frontend.max-queriers-per-tenant flag with non-zero value). TLS configuration in gRPC and HTTP clients. TLS configuration in Etcd client. Blocksconvert tools ","excerpt":"For the v1.0 release, we want to provide the following guarantees:\nFlags, Config and minor version …","ref":"/docs/configuration/v1guarantees/","title":"v1.x Guarantees"},{"body":"","excerpt":"","ref":"/docs/configuration/","title":"Configuration"},{"body":"The Cortex blocks storage engine stores series in TSDB blocks uploaded in the storage bucket. This makes very easy to migrate the storage from Thanos and/or Prometheus to Cortex, when running the blocks storage.\nCortex blocks storage requirements The Cortex blocks storage has few requirements that should be considered when migrating TSDB blocks from Thanos / Prometheus to Cortex:\n The blocks in the bucket should be located at bucket://\u0026lt;tenant-id\u0026gt;/\nCortex isolates blocks on a per-tenant basis in the bucket and, for this reason, each tenant blocks should be uploaded to a different location in the bucket. The bucket prefix, where a specific tenant blocks should be uploaded, is /\u0026lt;tenant-id\u0026gt;/; if Cortex is running with auth disabled (no multi-tenancy) then the \u0026lt;tenant-id\u0026gt; to use is fake. Remove Thanos external labels and inject __org_id__ into each block\u0026rsquo;s meta.json\nEvery block has a little metadata file named meta.json. Thanos stores external labels at thanos \u0026gt; labels, which should be all removed when migrating to Cortex, while the \u0026quot;__org_id__\u0026quot;: \u0026quot;\u0026lt;tenant-id\u0026gt;\u0026quot; added. How to migrate the storage Currently, no tool is provided to migrate TSDB blocks from Thanos / Prometheus to Cortex, but writing an automation should be fairly easy. This automation could do the following:\n Upload TSDB blocks from Thanos / Prometheus to Cortex bucket Manipulate meta.json file for each block in the Cortex bucket Upload TSDB blocks to Cortex bucket TSDB blocks stored in Prometheus local disk or Thanos bucket should be copied/uploaded to the Cortex bucket at the location bucket://\u0026lt;tenant-id\u0026gt;/ (when Cortex is running with auth disabled then \u0026lt;tenant-id\u0026gt; must be fake).\nManipulate meta.json file For each block copied/uploaded to the Cortex bucket, the meta.json should be manipulated. The easiest approach would be iterating the tenants and blocks in the bucket and for each block:\n Download the meta.json to the local filesystem Decode the JSON Manipulate the data structure (see below) Re-encode the JSON Re-upload it to the bucket (overwriting the previous version of the meta.json file) The meta.json should be manipulated in order to ensure:\n It contains the thanos root-level entry The thanos \u0026gt; labels do not contain any Thanos-specific external label The thanos \u0026gt; labels contain the Cortex-specific external label \u0026quot;__org_id__\u0026quot;: \u0026quot;\u0026lt;tenant-id\u0026gt;\u0026quot; When migrating from Thanos When migrating from Thanos, the easiest approach would be keep the existing thanos root-level entry as is, except:\n Completely remove the content of thanos \u0026gt; labels Add \u0026quot;__org_id__\u0026quot;: \u0026quot;\u0026lt;tenant-id\u0026gt;\u0026quot; to thanos \u0026gt; labels For example, when migrating a block from Thanos for the tenant user-1, the thanos root-level property within the meta.json file will look like:\n{ \u0026#34;thanos\u0026#34;: { \u0026#34;labels\u0026#34;: { \u0026#34;__org_id__\u0026#34;: \u0026#34;user-1\u0026#34; }, \u0026#34;downsample\u0026#34;: { \u0026#34;resolution\u0026#34;: 0 }, \u0026#34;source\u0026#34;: \u0026#34;compactor\u0026#34; } } When migrating from Prometheus When migrating from Prometheus, the meta.json file will not contain any thanos root-level entry and, for this reason, it would need to be generated:\n Create the thanos root-level entry (see below) Add \u0026quot;__org_id__\u0026quot;: \u0026quot;\u0026lt;tenant-id\u0026gt;\u0026quot; to thanos \u0026gt; labels For example, when migrating a block from Prometheus for the tenant user-1, the thanos root-level property within the meta.json file should be as follow:\n{ \u0026#34;thanos\u0026#34;: { \u0026#34;labels\u0026#34;: { \u0026#34;__org_id__\u0026#34;: \u0026#34;user-1\u0026#34; }, \u0026#34;downsample\u0026#34;: { \u0026#34;resolution\u0026#34;: 0 }, \u0026#34;source\u0026#34;: \u0026#34;compactor\u0026#34; } } ","excerpt":"The Cortex blocks storage engine stores series in TSDB blocks uploaded in the storage bucket. This …","ref":"/docs/blocks-storage/migrate-storage-from-thanos-and-prometheus/","title":"Migrate the storage from Thanos and Prometheus"},{"body":"","excerpt":"","ref":"/docs/operations/","title":"Operating Cortex"},{"body":"The blocks storage is a Cortex storage engine based on Prometheus TSDB: it stores each tenant\u0026rsquo;s time series into their own TSDB which write out their series to a on-disk block (defaults to 2h block range periods). Each block is composed by chunk files - containing the timestamp-value pairs for multiple series - and an index, which indexes metric names and labels to time series in the chunk files.\nThe supported backends for the blocks storage are:\n Amazon S3 Google Cloud Storage Microsoft Azure Storage Local Filesystem (single node only) Internally, some components are based on Thanos, but no Thanos knowledge is required in order to run it.\nArchitecture When running the Cortex blocks storage, the Cortex architecture doesn\u0026rsquo;t significantly change and thus the general architecture documentation applies to the blocks storage as well. However, there are two additional Cortex services when running the blocks storage:\n Store-gateway Compactor The store-gateway is responsible to query blocks and is used by the querier at query time. The store-gateway is required when running the blocks storage.\nThe compactor is responsible to merge and deduplicate smaller blocks into larger ones, in order to reduce the number of blocks stored in the long-term storage for a given tenant and query them more efficiently. The compactor is optional but highly recommended.\nFinally, the table-manager and the schema configuration are not used by the blocks storage.\nThe write path Ingesters receive incoming samples from the distributors. Each push request belongs to a tenant, and the ingester appends the received samples to the specific per-tenant TSDB stored on the local disk. The received samples are both kept in-memory and written to a write-ahead log (WAL) and used to recover the in-memory series in case the ingester abruptly terminates. The per-tenant TSDB is lazily created in each ingester as soon as the first samples are received for that tenant.\nThe in-memory samples are periodically flushed to disk - and the WAL truncated - when a new TSDB block is created, which by default occurs every 2 hours. Each newly created block is then uploaded to the long-term storage and kept in the ingester until the configured -blocks-storage.tsdb.retention-period expires, in order to give queriers and store-gateways enough time to discover the new block on the storage and download its index-header.\nIn order to effectively use the WAL and being able to recover the in-memory series upon ingester abruptly termination, the WAL needs to be stored to a persistent disk which can survive in the event of an ingester failure (ie. AWS EBS volume or GCP persistent disk when running in the cloud). For example, if you\u0026rsquo;re running the Cortex cluster in Kubernetes, you may use a StatefulSet with a persistent volume claim for the ingesters. The location on the filesystem where the WAL is stored is the same where local TSDB blocks (compacted from head) are stored and cannot be decoupled.\nDistributor series sharding and replication The series sharding and replication done by the distributor doesn\u0026rsquo;t change based on the storage engine.\nIt\u0026rsquo;s important to note that - differently than the chunks storage - due to the replication factor N (typically 3), each time series is stored by N ingesters. Since each ingester writes its own block to the long-term storage, this leads a storage utilization N times more than the chunks storage. Compactor solves this problem by merging blocks from multiple ingesters into a single block, and removing duplicated samples.\nFor more information, please refer to the following dedicated sections:\n Compactor Production tips The read path Queriers and store-gateways periodically iterate over the storage bucket to discover blocks recently uploaded by ingesters.\nFor each discovered block, queriers only download the block\u0026rsquo;s meta.json file (containing some metadata including min and max timestamp of samples within the block), while store-gateways download the meta.json as well as the index-header, which is a small subset of the block\u0026rsquo;s index used by the store-gateway to lookup series at query time.\nQueriers use the blocks metadata to compute the list of blocks that need to be queried at query time and fetch matching series from the store-gateway instances holding the required blocks.\nFor more information, please refer to the following dedicated sections:\n Querier Store-gateway Production tips Configuration The general configuration documentation also applies to a Cortex cluster running the blocks storage. The blocks storage can be enabled switching the storage engine to blocks:\nstorage:# The storage engine to use. Use \u0026#34;blocks\u0026#34; for the blocks storage.# CLI flag: -store.engineengine:blocksKnown issues GitHub issues tagged with the storage/blocks label are the best source of currently known issues affecting the blocks storage.\n","excerpt":"The blocks storage is a Cortex storage engine based on Prometheus TSDB: it stores each …","ref":"/docs/blocks-storage/","title":"Blocks Storage"},{"body":"Context You can have more than a single Prometheus monitoring and ingesting the same metrics for redundancy. Cortex already does replication for redundancy and it doesn\u0026rsquo;t make sense to ingest the same data twice. So in Cortex, we made sure we can dedupe the data we receive from HA Pairs of Prometheus. We do this via the following:\nAssume that there are two teams, each running their own Prometheus, monitoring different services. Let\u0026rsquo;s call the Prometheis T1 and T2. Now, if the teams are running HA pairs, let\u0026rsquo;s call the individual Prometheis, T1.a, T1.b and T2.a and T2.b.\nIn Cortex we make sure we only ingest from one of T1.a and T1.b, and only from one of T2.a and T2.b. We do this by electing a leader replica for each cluster of Prometheus. For example, in the case of T1, let it be T1.a. As long as T1.a is the leader, we drop the samples sent by T1.b. And if Cortex sees no new samples from T1.a for a short period (30s by default), it\u0026rsquo;ll switch the leader to be T1.b.\nThis means if T1.a goes down for a few minutes Cortex\u0026rsquo;s HA sample handling will have switched and elected T1.b as the leader. This failover timeout is what enables us to only accept samples from a single replica at a time, but ensure we don\u0026rsquo;t drop too much data in case of issues. Note that with the default scrape period of 15s, and the default timeouts in Cortex, in most cases you\u0026rsquo;ll only lose a single scrape of data in the case of a leader election failover. For any rate queries the rate window should be at least 4x the scrape period to account for any of these failover scenarios, for example with the default scrape period of 15s then you should calculate rates over at least 1m periods.\nNow we do the same leader election process T2.\nConfig Client Side So for Cortex to achieve this, we need 2 identifiers for each process, one identifier for the cluster (T1 or T2, etc) and one identifier to identify the replica in the cluster (a or b). The easiest way to do with is by setting external labels, the default labels are cluster and __replica__. For example:\ncluster: prom-team1 __replica__: replica1 (or pod-name) and\ncluster: prom-team1 __replica__: replica2 Note: These are external labels and have nothing to do with remote_write config.\nThese two label names are configurable per-tenant within Cortex, and should be set to something sensible. For example, cluster label is already used by some workloads, and you should set the label to be something else but uniquely identifies the cluster. Good examples for this label-name would be team, cluster, prometheus, etc.\nThe replica label should be set so that the value for each prometheus is unique in that cluster. Note: Cortex drops this label when ingesting data, but preserves the cluster label. This way, your timeseries won\u0026rsquo;t change when replicas change.\nServer Side The minimal configuration requires:\n Enabling the HA tracker via -distributor.ha-tracker.enable=true CLI flag (or its YAML config option) Configuring the KV store for the ring (See: Ring/HA Tracker Store). Only Consul and etcd are currently supported. Multi shoud be used for migration purposes only. Setting the limits configuration to accept samples via -distributor.ha-tracker.enable-for-all-users (or its YAML config option) The following configuration snippet shows an example of the HA tracker config via YAML config file:\nlimits:...accept_ha_samples:true...distributor:...ha_tracker:enable_ha_tracker:true...kvstore:[store:\u0026lt;string\u0026gt;|default=\u0026#34;consul\u0026#34;][consul | etcd:\u0026lt;config\u0026gt;]......For further configuration file documentation, see the distributor section and Ring/HA Tracker Store.\nFor flag configuration, see the distributor flags having ha-tracker in them.\n","excerpt":"Context You can have more than a single Prometheus monitoring and ingesting the same metrics for …","ref":"/docs/production/ha-pair-handling/","title":"Config for sending HA Pairs data to Cortex"},{"body":"Welcome! We\u0026rsquo;re excited that you\u0026rsquo;re interested in contributing. Below are some basic guidelines.\nWorkflow Cortex follows a standard GitHub pull request workflow. If you\u0026rsquo;re unfamiliar with this workflow, read the very helpful Understanding the GitHub flow guide from GitHub.\nYou are welcome to create draft PRs at any stage of readiness - this can be helpful to ask for assistance or to develop an idea. But before a piece of work is finished it should:\n Be organised into one or more commits, each of which has a commit message that describes all changes made in that commit (\u0026lsquo;why\u0026rsquo; more than \u0026lsquo;what\u0026rsquo; - we can read the diffs to see the code that changed). Each commit should build towards the whole - don\u0026rsquo;t leave in back-tracks and mistakes that you later corrected. Have unit and/or integration tests for new functionality or tests that would have caught the bug being fixed. Include a CHANGELOG message if users of Cortex need to hear about what you did. If you have made any changes to flags or config, run make doc and commit the changed files to update the config file documentation. Formatting Cortex projects uses goimports tool (go get golang.org/x/tools/cmd/goimports to install) to format the Go files, and sort imports. We use goimports with -local github.com/cortexproject/cortex parameter, to put Cortex internal imports into a separate group. We try to keep imports sorted into three groups: imports from standard library, imports of 3rd party packages and internal Cortex imports. Goimports will fix the order, but will keep existing newlines between imports in the groups. We try to avoid extra newlines like that.\nYou\u0026rsquo;re using an IDE you may find useful the following settings for the Cortex project:\n VSCode Developer Certificates of Origin (DCOs) Before submitting your work in a pull request, make sure that all commits are signed off with a Developer Certificate of Origin (DCO). Here\u0026rsquo;s an example:\ngit commit -s -m \u0026#34;Here is my signed commit\u0026#34; You can find further instructions here.\nBuilding Cortex To build:\nmake (By default, the build runs in a Docker container, using an image built with all the tools required. The source code is mounted from where you run make into the build container as a Docker volume.)\nTo run the unit tests suite:\ngo test ./... To run the integration tests suite please see \u0026ldquo;How integration tests work\u0026rdquo;.\nDependency management We uses Go modules to manage dependencies on external packages. This requires a working Go environment with version 1.11 or greater, git and bzr installed.\nTo add or update a new dependency, use the go get command:\n# Pick the latest tagged release. go get example.com/some/module/pkg # Pick a specific version. go get example.com/some/module/pkg@vX.Y.Z Tidy up the go.mod and go.sum files:\ngo mod tidy go mod vendor git add go.mod go.sum vendor git commit You have to commit the changes to go.mod and go.sum before submitting the pull request.\nDesign patterns and Code conventions Please see the dedicated \u0026ldquo;Design patterns and Code conventions\u0026rdquo; page.\nDocumentation The Cortex documentation is compiled into a website published at cortexmetrics.io. Please see \u0026ldquo;How to run the website locally\u0026rdquo; for instructions.\nNote: if you attempt to view pages on Github, it\u0026rsquo;s likely that you might find broken links or pages. That is expected and should not be addressed unless it is causing issues with the site that occur as part of the build.\n","excerpt":"Welcome! We\u0026rsquo;re excited that you\u0026rsquo;re interested in contributing. Below are some basic …","ref":"/docs/contributing/","title":"Contributing"},{"body":"","excerpt":"","ref":"/docs/case-studies/","title":"Case Studies"},{"body":"This document defines project governance for the project.\nVoting The Cortex project employs voting to ensure no single member can dominate the project. Any maintainer may cast a vote. To avoid having a single company dominate the project, at most two votes from maintainers working for the same company will count.\nFor formal votes, a specific statement of what is being voted on should be added to the relevant github issue or PR, and a link to that issue or PR added to the maintainers meeting agenda document. Maintainers should indicate their yes/no vote on that issue or PR, and after a suitable period of time, the votes will be tallied and the outcome noted.\nChanges in Maintainership New maintainers are proposed by an existing maintainer and are elected by a 2/3 majority vote.\nMaintainers can be removed by a 2/3 majority vote.\nApproving PRs PRs may be merged after receiving at least two positive votes. If the PR author is a maintainer, this counts as a vote.\nGithub Project Administration Maintainers will be added to the collaborators list of the Cortex repository with \u0026ldquo;Write\u0026rdquo; access.\nAfter 6 months a maintainer will be given \u0026ldquo;Admin\u0026rdquo; access to the Cortex repository.\nChanges in Governance All changes in Governance require a 2/3 majority vote.\nOther Changes Unless specified above, all other changes to the project require a 2/3 majority vote. Additionally, any maintainer may request that any change require a 2/3 majority vote.\n","excerpt":"This document defines project governance for the project.\nVoting The Cortex project employs voting …","ref":"/docs/governance/","title":"Governance"},{"body":"master / unreleased [CHANGE] Blocks storage: update the default HTTP configuration values for the S3 client to the upstream Thanos default values. #3244 -blocks-storage.s3.http.idle-conn-timeout is set 90 seconds. -blocks-storage.s3.http.response-header-timeout is set to 2 minutes. [CHANGE] Improved shuffle sharding support in the write path. This work introduced some config changes: #3090 Introduced -distributor.sharding-strategy CLI flag (and its respective sharding_strategy YAML config option) to explicitly specify which sharding strategy should be used in the write path -experimental.distributor.user-subring-size flag renamed to -distributor.ingestion-tenant-shard-size user_subring_size limit YAML config option renamed to ingestion_tenant_shard_size [CHANGE] Dropped \u0026ldquo;blank Alertmanager configuration; using fallback\u0026rdquo; message from Info to Debug level. #3205 [CHANGE] Zone-awareness replication for time-series now should be explicitly enabled in the distributor via the -distributor.zone-awareness-enabled CLI flag (or its respective YAML config option). Before, zone-aware replication was implicitly enabled if a zone was set on ingesters. #3200 [CHANGE] Removed the deprecated CLI flag -config-yaml. You should use -schema-config-file instead. #3225 [CHANGE] Enforced the HTTP method required by some API endpoints which did (incorrectly) allow any method before that. #3228 GET / GET /config GET /debug/fgprof GET /distributor/all_user_stats GET /distributor/ha_tracker GET /all_user_stats GET /ha-tracker GET /api/v1/user_stats GET /api/v1/chunks GET \u0026lt;legacy-http-prefix\u0026gt;/user_stats GET \u0026lt;legacy-http-prefix\u0026gt;/chunks GET /services GET /multitenant_alertmanager/status GET /status (alertmanager microservice) GET|POST /ingester/ring GET|POST /ring GET|POST /store-gateway/ring GET|POST /compactor/ring GET|POST /ingester/flush GET|POST /ingester/shutdown GET|POST /flush GET|POST /shutdown GET|POST /ruler/ring POST /api/v1/push POST \u0026lt;legacy-http-prefix\u0026gt;/push POST /push POST /ingester/push [CHANGE] Renamed CLI flags to configure the network interface names from which automatically detect the instance IP. #3295 -compactor.ring.instance-interface renamed to -compactor.ring.instance-interface-names -store-gateway.sharding-ring.instance-interface renamed to -store-gateway.sharding-ring.instance-interface-names -distributor.ring.instance-interface renamed to -distributor.ring.instance-interface-names -ruler.ring.instance-interface renamed to -ruler.ring.instance-interface-names [CHANGE] Renamed -\u0026lt;prefix\u0026gt;.redis.enable-tls CLI flag to -\u0026lt;prefix\u0026gt;.redis.tls-enabled, and its respective YAML config option from enable_tls to tls_enabled. #3298 [CHANGE] Increased default -\u0026lt;prefix\u0026gt;.redis.timeout from 100ms to 500ms. #3301 [FEATURE] Added support for shuffle-sharding queriers in the query-frontend. When configured (-frontend.max-queriers-per-tenant globally, or using per-tenant limit max_queriers_per_tenant), each tenants\u0026rsquo;s requests will be handled by different set of queriers. #3113 #3257 [FEATURE] Query-frontend: added compression config to support results cache with compression. #3217 [ENHANCEMENT] Allow to specify multiple comma-separated Cortex services to -target CLI option (or its respective YAML config option). For example, -target=all,compactor can be used to start Cortex single-binary with compactor as well. #3275 [ENHANCEMENT] Expose additional HTTP configs for the S3 backend client. New flag are listed below: #3244 -blocks-storage.s3.http.idle-conn-timeout -blocks-storage.s3.http.response-header-timeout -blocks-storage.s3.http.insecure-skip-verify [ENHANCEMENT] Added cortex_query_frontend_connected_clients metric to show the number of workers currently connected to the frontend. #3207 [ENHANCEMENT] Shuffle sharding: improved shuffle sharding in the write path. Shuffle sharding now should be explicitly enabled via -distributor.sharding-strategy CLI flag (or its respective YAML config option) and guarantees stability, consistency, shuffling and balanced zone-awareness properties. #3090 #3214 [ENHANCEMENT] Ingester: added new metric cortex_ingester_active_series to track active series more accurately. Also added options to control whether active series tracking is enabled (-ingester.active-series-enabled, defaults to false), and how often this metric is updated (-ingester.active-series-update-period) and max idle time for series to be considered inactive (-ingester.active-series-idle-timeout). #3153 [ENHANCEMENT] Blocksconvert – Builder: download plan file locally before processing it. #3209 [ENHANCEMENT] Blocksconvert – Cleaner: added new tool for deleting chunks data. #3283 [ENHANCEMENT] Store-gateway: added zone-aware replication support to blocks replication in the store-gateway. #3200 [ENHANCEMENT] Store-gateway: exported new metrics. #3231 cortex_bucket_store_cached_series_fetch_duration_seconds cortex_bucket_store_cached_postings_fetch_duration_seconds cortex_bucket_stores_gate_queries_max [ENHANCEMENT] Added -version flag to Cortex. #3233 [ENHANCEMENT] Blocksconvert – Scanner: support for scanning specific date-range only. #3222 [ENHANCEMENT] Blocksconvert – Scanner: metrics for tracking progress. #3222 [ENHANCEMENT] Blocksconvert – Builder: retry block upload before giving up. #3245 [ENHANCEMENT] Hash ring: added instance registered timestamp to the ring. #3248 [ENHANCEMENT] Reduce tail latency by smoothing out spikes in rate of chunk flush operations. #3191 [ENHANCEMENT] User Cortex as User Agent in http requests issued by Configs DB client. #3264 [ENHANCEMENT] Experimental Ruler API: Fetch rule groups from object storage in parallel. #3218 [ENHANCEMENT] Chunks GCS object storage client uses the fields selector to limit the payload size when listing objects in the bucket. #3218 #3292 [ENHANCEMENT] Added shuffle sharding support to ruler. Added new metric cortex_ruler_sync_rules_total. #3235 [ENHANCEMENT] Return an explicit error when the store-gateway is explicitly requested without a blocks storage engine. #3287 [ENHANCEMENT] Ruler: only load rules that belong to the ruler. Improves rules synching performances when ruler sharding is enabled. #3269 [ENHANCEMENT] Added -\u0026lt;prefix\u0026gt;.redis.tls-insecure-skip-verify flag. #3298 [BUGFIX] No-longer-needed ingester operations for queries triggered by queriers and rulers are now canceled. #3178 [BUGFIX] Ruler: directories in the configured rules-path will be removed on startup and shutdown in order to ensure they don\u0026rsquo;t persist between runs. #3195 [BUGFIX] Handle hash-collisions in the query path. #3192 [BUGFIX] Check for postgres rows errors. #3197 [BUGFIX] Ruler Experimental API: Don\u0026rsquo;t allow rule groups without names or empty rule groups. #3210 [BUGFIX] Experimental Alertmanager API: Do not allow empty Alertmanager configurations or bad template filenames to be submitted through the configuration API. #3185 [BUGFIX] Reduce failures to update heartbeat when using Consul. #3259 [BUGFIX] When using ruler sharding, moving all user rule groups from ruler to a different one and then back could end up with some user groups not being evaluated at all. #3235 [BUGFIX] Fixed shuffle sharding consistency when zone-awareness is enabled and the shard size is increased or instances in a new zone are added. #3299 [BUGFIX] Use a valid grpc header when logging IP addresses. #3307 [BUGFIX] Fixed the metric cortex_prometheus_rule_group_duration_seconds in the Ruler, it wouldn\u0026rsquo;t report any values. #3310 [BUGFIX] Fixed gRPC connections leaking in rulers when rulers sharding is enabled and APIs called. #3314 1.4.0 / 2020-10-02 [CHANGE] TLS configuration for gRPC, HTTP and etcd clients is now marked as experimental. These features are not yet fully baked, and we expect possible small breaking changes in Cortex 1.5. #3198 [CHANGE] Cassandra backend support is now GA (stable). #3180 [CHANGE] Blocks storage is now GA (stable). The -experimental prefix has been removed from all CLI flags related to the blocks storage (no YAML config changes). #3180 #3201 -experimental.blocks-storage.* flags renamed to -blocks-storage.* -experimental.store-gateway.* flags renamed to -store-gateway.* -experimental.querier.store-gateway-client.* flags renamed to -querier.store-gateway-client.* -experimental.querier.store-gateway-addresses flag renamed to -querier.store-gateway-addresses -store-gateway.replication-factor flag renamed to -store-gateway.sharding-ring.replication-factor -store-gateway.tokens-file-path flag renamed to store-gateway.sharding-ring.tokens-file-path [CHANGE] Ingester: Removed deprecated untyped record from chunks WAL. Only if you are running v1.0 or below, it is recommended to first upgrade to v1.1/v1.2/v1.3 and run it for a day before upgrading to v1.4 to avoid data loss. #3115 [CHANGE] Distributor API endpoints are no longer served unless target is set to distributor or all. #3112 [CHANGE] Increase the default Cassandra client replication factor to 3. #3007 [CHANGE] Blocks storage: removed the support to transfer blocks between ingesters on shutdown. When running the Cortex blocks storage, ingesters are expected to run with a persistent disk. The following metrics have been removed: #2996 cortex_ingester_sent_files cortex_ingester_received_files cortex_ingester_received_bytes_total cortex_ingester_sent_bytes_total [CHANGE] The buckets for the cortex_chunk_store_index_lookups_per_query metric have been changed to 1, 2, 4, 8, 16. #3021 [CHANGE] Blocks storage: the operation label value getrange has changed into get_range for the metrics thanos_store_bucket_cache_operation_requests_total and thanos_store_bucket_cache_operation_hits_total. #3000 [CHANGE] Experimental Delete Series: /api/v1/admin/tsdb/delete_series and /api/v1/admin/tsdb/cancel_delete_request purger APIs to return status code 204 instead of 200 for success. #2946 [CHANGE] Histogram cortex_memcache_request_duration_seconds method label value changes from Memcached.Get to Memcached.GetBatched for batched lookups, and is not reported for non-batched lookups (label value Memcached.GetMulti remains, and had exactly the same value as Get in nonbatched lookups). The same change applies to tracing spans. #3046 [CHANGE] TLS server validation is now enabled by default, a new parameter tls_insecure_skip_verify can be set to true to skip validation optionally. #3030 [CHANGE] cortex_ruler_config_update_failures_total has been removed in favor of cortex_ruler_config_last_reload_successful. #3056 [CHANGE] ruler.evaluation_delay_duration field in YAML config has been moved and renamed to limits.ruler_evaluation_delay_duration. #3098 [CHANGE] Removed obsolete results_cache.max_freshness from YAML config (deprecated since Cortex 1.2). #3145 [CHANGE] Removed obsolete -promql.lookback-delta option (deprecated since Cortex 1.2, replaced with -querier.lookback-delta). #3144 [CHANGE] Cache: added support for Redis Cluster and Redis Sentinel. #2961 The following changes have been made in Redis configuration: -redis.master_name added -redis.db added -redis.max-active-conns changed to -redis.pool-size -redis.max-conn-lifetime changed to -redis.max-connection-age -redis.max-idle-conns removed -redis.wait-on-pool-exhaustion removed [CHANGE] TLS configuration for gRPC, HTTP and etcd clients is now marked as experimental. These features are not yet fully baked, and we expect possible small breaking changes in Cortex 1.5. #3198 [CHANGE] Fixed store-gateway CLI flags inconsistencies. #3201 -store-gateway.replication-factor flag renamed to -store-gateway.sharding-ring.replication-factor -store-gateway.tokens-file-path flag renamed to store-gateway.sharding-ring.tokens-file-path [FEATURE] Logging of the source IP passed along by a reverse proxy is now supported by setting the -server.log-source-ips-enabled. For non standard headers the settings -server.log-source-ips-header and -server.log-source-ips-regex can be used. #2985 [FEATURE] Blocks storage: added shuffle sharding support to store-gateway blocks sharding. Added the following additional metrics to store-gateway: #3069 cortex_bucket_stores_tenants_discovered cortex_bucket_stores_tenants_synced [FEATURE] Experimental blocksconvert: introduce an experimental tool blocksconvert to migrate long-term storage chunks to blocks. #3092 #3122 #3127 #3162 [ENHANCEMENT] Add support for azure storage in China, German and US Government environments. #2988 [ENHANCEMENT] Query-tee: added a small tolerance to floating point sample values comparison. #2994 [ENHANCEMENT] Query-tee: add support for doing a passthrough of requests to preferred backend for unregistered routes #3018 [ENHANCEMENT] Expose storage.aws.dynamodb.backoff_config configuration file field. #3026 [ENHANCEMENT] Added cortex_request_message_bytes and cortex_response_message_bytes histograms to track received and sent gRPC message and HTTP request/response sizes. Added cortex_inflight_requests gauge to track number of inflight gRPC and HTTP requests. #3064 [ENHANCEMENT] Publish ruler\u0026rsquo;s ring metrics. #3074 [ENHANCEMENT] Add config validation to the experimental Alertmanager API. Invalid configs are no longer accepted. #3053 [ENHANCEMENT] Add \u0026ldquo;integration\u0026rdquo; as a label for cortex_alertmanager_notifications_total and cortex_alertmanager_notifications_failed_total metrics. #3056 [ENHANCEMENT] Add cortex_ruler_config_last_reload_successful and cortex_ruler_config_last_reload_successful_seconds to check status of users rule manager. #3056 [ENHANCEMENT] The configuration validation now fails if an empty YAML node has been set for a root YAML config property. #3080 [ENHANCEMENT] Memcached dial() calls now have a circuit-breaker to avoid hammering a broken cache. #3051, #3189 [ENHANCEMENT] -ruler.evaluation-delay-duration is now overridable as a per-tenant limit, ruler_evaluation_delay_duration. #3098 [ENHANCEMENT] Add TLS support to etcd client. #3102 [ENHANCEMENT] When a tenant accesses the Alertmanager UI or its API, if we have valid -alertmanager.configs.fallback we\u0026rsquo;ll use that to start the manager and avoid failing the request. #3073 [ENHANCEMENT] Add DELETE api/v1/rules/{namespace} to the Ruler. It allows all the rule groups of a namespace to be deleted. #3120 [ENHANCEMENT] Experimental Delete Series: Retry processing of Delete requests during failures. #2926 [ENHANCEMENT] Improve performance of QueryStream() in ingesters. #3177 [ENHANCEMENT] Modules included in \u0026ldquo;All\u0026rdquo; target are now visible in output of -modules CLI flag. #3155 [ENHANCEMENT] Added /debug/fgprof endpoint to debug running Cortex process using fgprof. This adds up to the existing /debug/... endpoints. #3131 [ENHANCEMENT] Blocks storage: optimised /api/v1/series for blocks storage. (#2976) [BUGFIX] Ruler: when loading rules from \u0026ldquo;local\u0026rdquo; storage, check for directory after resolving symlink. #3137 [BUGFIX] Query-frontend: Fixed rounding for incoming query timestamps, to be 100% Prometheus compatible. #2990 [BUGFIX] Querier: Merge results from chunks and blocks ingesters when using streaming of results. #3013 [BUGFIX] Querier: query /series from ingesters regardless the -querier.query-ingesters-within setting. #3035 [BUGFIX] Blocks storage: Ingester is less likely to hit gRPC message size limit when streaming data to queriers. #3015 [BUGFIX] Blocks storage: fixed memberlist support for the store-gateways and compactors ring used when blocks sharding is enabled. #3058 #3095 [BUGFIX] Fix configuration for TLS server validation, TLS skip verify was hardcoded to true for all TLS configurations and prevented validation of server certificates. #3030 [BUGFIX] Fixes the Alertmanager panicking when no -alertmanager.web.external-url is provided. #3017 [BUGFIX] Fixes the registration of the Alertmanager API metrics cortex_alertmanager_alerts_received_total and cortex_alertmanager_alerts_invalid_total. #3065 [BUGFIX] Fixes flag needs an argument: -config.expand-env error. #3087 [BUGFIX] An index optimisation actually slows things down when using caching. Moved it to the right location. #2973 [BUGFIX] Ingester: If push request contained both valid and invalid samples, valid samples were ingested but not stored to WAL of the chunks storage. This has been fixed. #3067 [BUGFIX] Cassandra: fixed consistency setting in the CQL session when creating the keyspace. #3105 [BUGFIX] Ruler: Config API would return both the record and alert in YAML response keys even when one of them must be empty. #3120 [BUGFIX] Index page now uses configured HTTP path prefix when creating links. #3126 [BUGFIX] Purger: fixed deadlock when reloading of tombstones failed. #3182 [BUGFIX] Fixed panic in flusher job, when error writing chunks to the store would cause \u0026ldquo;idle\u0026rdquo; chunks to be flushed, which triggered panic. #3140 [BUGFIX] Index page no longer shows links that are not valid for running Cortex instance. #3133 [BUGFIX] Configs: prevent validation of templates to fail when using template functions. #3157 [BUGFIX] Configuring the S3 URL with an @ but without username and password doesn\u0026rsquo;t enable the AWS static credentials anymore. #3170 [BUGFIX] Limit errors on ranged queries (api/v1/query_range) no longer return a status code 500 but 422 instead. #3167 [BUGFIX] Handle hash-collisions in the query path. Before this fix, Cortex could occasionally mix up two different series in a query, leading to invalid results, when -querier.ingester-streaming was used. #3192 1.3.0 / 2020-08-21 [CHANGE] Replace the metric cortex_alertmanager_configs with cortex_alertmanager_config_invalid exposed by Alertmanager. #2960 [CHANGE] Experimental Delete Series: Change target flag for purger from data-purger to purger. #2777 [CHANGE] Experimental blocks storage: The max concurrent queries against the long-term storage, configured via -experimental.blocks-storage.bucket-store.max-concurrent, is now a limit shared across all tenants and not a per-tenant limit anymore. The default value has changed from 20 to 100 and the following new metrics have been added: #2797 cortex_bucket_stores_gate_queries_concurrent_max cortex_bucket_stores_gate_queries_in_flight cortex_bucket_stores_gate_duration_seconds [CHANGE] Metric cortex_ingester_flush_reasons has been renamed to cortex_ingester_flushing_enqueued_series_total, and new metric cortex_ingester_flushing_dequeued_series_total with outcome label (superset of reason) has been added. #2802 #2818 #2998 [CHANGE] Experimental Delete Series: Metric cortex_purger_oldest_pending_delete_request_age_seconds would track age of delete requests since they are over their cancellation period instead of their creation time. #2806 [CHANGE] Experimental blocks storage: the store-gateway service is required in a Cortex cluster running with the experimental blocks storage. Removed the -experimental.tsdb.store-gateway-enabled CLI flag and store_gateway_enabled YAML config option. The store-gateway is now always enabled when the storage engine is blocks. #2822 [CHANGE] Experimental blocks storage: removed support for -experimental.blocks-storage.bucket-store.max-sample-count flag because the implementation was flawed. To limit the number of samples/chunks processed by a single query you can set -store.query-chunk-limit, which is now supported by the blocks storage too. #2852 [CHANGE] Ingester: Chunks flushed via /flush stay in memory until retention period is reached. This affects cortex_ingester_memory_chunks metric. #2778 [CHANGE] Querier: the error message returned when the query time range exceeds -store.max-query-length has changed from invalid query, length \u0026gt; limit (X \u0026gt; Y) to the query time range exceeds the limit (query length: X, limit: Y). #2826 [CHANGE] Add component label to metrics exposed by chunk, delete and index store clients. #2774 [CHANGE] Querier: when -querier.query-ingesters-within is configured, the time range of the query sent to ingesters is now manipulated to ensure the query start time is not older than \u0026lsquo;now - query-ingesters-within\u0026rsquo;. #2904 [CHANGE] KV: The role label which was a label of multi KV store client only has been added to metrics of every KV store client. If KV store client is not multi, then the value of role label is primary. #2837 [CHANGE] Added the engine label to the metrics exposed by the Prometheus query engine, to distinguish between ruler and querier metrics. #2854 [CHANGE] Added ruler to the single binary when started with -target=all (default). #2854 [CHANGE] Experimental blocks storage: compact head when opening TSDB. This should only affect ingester startup after it was unable to compact head in previous run. #2870 [CHANGE] Metric cortex_overrides_last_reload_successful has been renamed to cortex_runtime_config_last_reload_successful. #2874 [CHANGE] HipChat support has been removed from the alertmanager (because removed from the Prometheus upstream too). #2902 [CHANGE] Add constant label name to metric cortex_cache_request_duration_seconds. #2903 [CHANGE] Add user label to metric cortex_query_frontend_queue_length. #2939 [CHANGE] Experimental blocks storage: cleaned up the config and renamed \u0026ldquo;TSDB\u0026rdquo; to \u0026ldquo;blocks storage\u0026rdquo;. #2937 The storage engine setting value has been changed from tsdb to blocks; this affects -store.engine CLI flag and its respective YAML option. The root level YAML config has changed from tsdb to blocks_storage The prefix of all CLI flags has changed from -experimental.tsdb. to -experimental.blocks-storage. The following settings have been grouped under tsdb property in the YAML config and their CLI flags changed: -experimental.tsdb.dir changed to -experimental.blocks-storage.tsdb.dir -experimental.tsdb.block-ranges-period changed to -experimental.blocks-storage.tsdb.block-ranges-period -experimental.tsdb.retention-period changed to -experimental.blocks-storage.tsdb.retention-period -experimental.tsdb.ship-interval changed to -experimental.blocks-storage.tsdb.ship-interval -experimental.tsdb.ship-concurrency changed to -experimental.blocks-storage.tsdb.ship-concurrency -experimental.tsdb.max-tsdb-opening-concurrency-on-startup changed to -experimental.blocks-storage.tsdb.max-tsdb-opening-concurrency-on-startup -experimental.tsdb.head-compaction-interval changed to -experimental.blocks-storage.tsdb.head-compaction-interval -experimental.tsdb.head-compaction-concurrency changed to -experimental.blocks-storage.tsdb.head-compaction-concurrency -experimental.tsdb.head-compaction-idle-timeout changed to -experimental.blocks-storage.tsdb.head-compaction-idle-timeout -experimental.tsdb.stripe-size changed to -experimental.blocks-storage.tsdb.stripe-size -experimental.tsdb.wal-compression-enabled changed to -experimental.blocks-storage.tsdb.wal-compression-enabled -experimental.tsdb.flush-blocks-on-shutdown changed to -experimental.blocks-storage.tsdb.flush-blocks-on-shutdown [CHANGE] Flags -bigtable.grpc-use-gzip-compression, -ingester.client.grpc-use-gzip-compression, -querier.frontend-client.grpc-use-gzip-compression are now deprecated. #2940 [CHANGE] Limit errors reported by ingester during query-time now return HTTP status code 422. #2941 [FEATURE] Introduced ruler.for-outage-tolerance, Max time to tolerate outage for restoring \u0026ldquo;for\u0026rdquo; state of alert. #2783 [FEATURE] Introduced ruler.for-grace-period, Minimum duration between alert and restored \u0026ldquo;for\u0026rdquo; state. This is maintained only for alerts with configured \u0026ldquo;for\u0026rdquo; time greater than grace period. #2783 [FEATURE] Introduced ruler.resend-delay, Minimum amount of time to wait before resending an alert to Alertmanager. #2783 [FEATURE] Ruler: added local filesystem support to store rules (read-only). #2854 [ENHANCEMENT] Upgraded Docker base images to alpine:3.12. #2862 [ENHANCEMENT] Experimental: Querier can now optionally query secondary store. This is specified by using -querier.second-store-engine option, with values chunks or blocks. Standard configuration options for this store are used. Additionally, this querying can be configured to happen only for queries that need data older than -querier.use-second-store-before-time. Default value of zero will always query secondary store. #2747 [ENHANCEMENT] Query-tee: increased the cortex_querytee_request_duration_seconds metric buckets granularity. #2799 [ENHANCEMENT] Query-tee: fail to start if the configured -backend.preferred is unknown. #2799 [ENHANCEMENT] Ruler: Added the following metrics: #2786 cortex_prometheus_notifications_latency_seconds cortex_prometheus_notifications_errors_total cortex_prometheus_notifications_sent_total cortex_prometheus_notifications_dropped_total cortex_prometheus_notifications_queue_length cortex_prometheus_notifications_queue_capacity cortex_prometheus_notifications_alertmanagers_discovered [ENHANCEMENT] The behavior of the /ready was changed for the query frontend to indicate when it was ready to accept queries. This is intended for use by a read path load balancer that would want to wait for the frontend to have attached queriers before including it in the backend. #2733 [ENHANCEMENT] Experimental Delete Series: Add support for deletion of chunks for remaining stores. #2801 [ENHANCEMENT] Add -modules command line flag to list possible values for -target. Also, log warning if given target is internal component. #2752 [ENHANCEMENT] Added -ingester.flush-on-shutdown-with-wal-enabled option to enable chunks flushing even when WAL is enabled. #2780 [ENHANCEMENT] Query-tee: Support for custom API prefix by using -server.path-prefix option. #2814 [ENHANCEMENT] Query-tee: Forward X-Scope-OrgId header to backend, if present in the request. #2815 [ENHANCEMENT] Experimental blocks storage: Added -experimental.blocks-storage.tsdb.head-compaction-idle-timeout option to force compaction of data in memory into a block. #2803 [ENHANCEMENT] Experimental blocks storage: Added support for flushing blocks via /flush, /shutdown (previously these only worked for chunks storage) and by using -experimental.blocks-storage.tsdb.flush-blocks-on-shutdown option. #2794 [ENHANCEMENT] Experimental blocks storage: Added support to enforce max query time range length via -store.max-query-length. #2826 [ENHANCEMENT] Experimental blocks storage: Added support to limit the max number of chunks that can be fetched from the long-term storage while executing a query. The limit is enforced both in the querier and store-gateway, and is configurable via -store.query-chunk-limit. #2852 #2922 [ENHANCEMENT] Ingester: Added new metric cortex_ingester_flush_series_in_progress that reports number of ongoing flush-series operations. Useful when calling /flush handler: if cortex_ingester_flush_queue_length + cortex_ingester_flush_series_in_progress is 0, all flushes are finished. #2778 [ENHANCEMENT] Memberlist members can join cluster via SRV records. #2788 [ENHANCEMENT] Added configuration options for chunks s3 client. #2831 s3.endpoint s3.region s3.access-key-id s3.secret-access-key s3.insecure s3.sse-encryption s3.http.idle-conn-timeout s3.http.response-header-timeout s3.http.insecure-skip-verify [ENHANCEMENT] Prometheus upgraded. #2798 #2849 #2867 #2902 #2918 Optimized labels regex matchers for patterns containing literals (eg. foo.*, .*foo, .*foo.*) [ENHANCEMENT] Add metric cortex_ruler_config_update_failures_total to Ruler to track failures of loading rules files. #2857 [ENHANCEMENT] Experimental Alertmanager: Alertmanager configuration persisted to object storage using an experimental API that accepts and returns YAML-based Alertmanager configuration. #2768 [ENHANCEMENT] Ruler: -ruler.alertmanager-url now supports multiple URLs. Each URL is treated as a separate Alertmanager group. Support for multiple Alertmanagers in a group can be achieved by using DNS service discovery. #2851 [ENHANCEMENT] Experimental blocks storage: Cortex Flusher now works with blocks engine. Flusher needs to be provided with blocks-engine configuration, existing Flusher flags are not used (they are only relevant for chunks engine). Note that flush errors are only reported via log. #2877 [ENHANCEMENT] Flusher: Added -flusher.exit-after-flush option (defaults to true) to control whether Cortex should stop completely after Flusher has finished its work. #2877 [ENHANCEMENT] Added metrics cortex_config_hash and cortex_runtime_config_hash to expose hash of the currently active config file. #2874 [ENHANCEMENT] Logger: added JSON logging support, configured via the -log.format=json CLI flag or its respective YAML config option. #2386 [ENHANCEMENT] Added new flags -bigtable.grpc-compression, -ingester.client.grpc-compression, -querier.frontend-client.grpc-compression to configure compression used by gRPC. Valid values are gzip, snappy, or empty string (no compression, default). #2940 [ENHANCEMENT] Clarify limitations of the /api/v1/series, /api/v1/labels and /api/v1/label/{name}/values endpoints. #2953 [ENHANCEMENT] Ingester: added Dropped outcome to metric cortex_ingester_flushing_dequeued_series_total. #2998 [BUGFIX] Fixed a bug with api/v1/query_range where no responses would return null values for result and empty values for resultType. #2962 [BUGFIX] Fixed a bug in the index intersect code causing storage to return more chunks/series than required. #2796 [BUGFIX] Fixed the number of reported keys in the background cache queue. #2764 [BUGFIX] Fix race in processing of headers in sharded queries. #2762 [BUGFIX] Query Frontend: Do not re-split sharded requests around ingester boundaries. #2766 [BUGFIX] Experimental Delete Series: Fixed a problem with cache generation numbers prefixed to cache keys. #2800 [BUGFIX] Ingester: Flushing chunks via /flush endpoint could previously lead to panic, if chunks were already flushed before and then removed from memory during the flush caused by /flush handler. Immediate flush now doesn\u0026rsquo;t cause chunks to be flushed again. Samples received during flush triggered via /flush handler are no longer discarded. #2778 [BUGFIX] Prometheus upgraded. #2849 Fixed unknown symbol error during head compaction [BUGFIX] Fix panic when using cassandra as store for both index and delete requests. #2774 [BUGFIX] Experimental Delete Series: Fixed a data race in Purger. #2817 [BUGFIX] KV: Fixed a bug that triggered a panic due to metrics being registered with the same name but different labels when using a multi configured KV client. #2837 [BUGFIX] Query-frontend: Fix passing HTTP Host header if -frontend.downstream-url is configured. #2880 [BUGFIX] Ingester: Improve time-series distribution when -experimental.distributor.user-subring-size is enabled. #2887 [BUGFIX] Set content type to application/x-protobuf for remote_read responses. #2915 [BUGFIX] Fixed ruler and store-gateway instance registration in the ring (when sharding is enabled) when a new instance replaces abruptly terminated one, and the only difference between the two instances is the address. #2954 [BUGFIX] Fixed Missing chunks and index config causing silent failure Absence of chunks and index from schema config is not validated. #2732 [BUGFIX] Fix panic caused by KVs from boltdb being used beyond their life. #2971 [BUGFIX] Experimental blocks storage: /api/v1/series, /api/v1/labels and /api/v1/label/{name}/values only query the TSDB head regardless of the configured -experimental.blocks-storage.tsdb.retention-period. #2974 [BUGFIX] Ingester: Avoid indefinite checkpointing in case of surge in number of series. #2955 [BUGFIX] Querier: query /series from ingesters regardless the -querier.query-ingesters-within setting. #3035 [BUGFIX] Ruler: fixed an unintentional breaking change introduced in the ruler\u0026rsquo;s alertmanager_url YAML config option, which changed the value from a string to a list of strings. #2989 1.2.0 / 2020-07-01 [CHANGE] Metric cortex_kv_request_duration_seconds now includes name label to denote which client is being used as well as the backend label to denote the KV backend implementation in use. #2648 [CHANGE] Experimental Ruler: Rule groups persisted to object storage using the experimental API have an updated object key encoding to better handle special characters. Rule groups previously-stored using object storage must be renamed to the new format. #2646 [CHANGE] Query Frontend now uses Round Robin to choose a tenant queue to service next. #2553 [CHANGE] -promql.lookback-delta is now deprecated and has been replaced by -querier.lookback-delta along with lookback_delta entry under querier in the config file. -promql.lookback-delta will be removed in v1.4.0. #2604 [CHANGE] Experimental TSDB: removed -experimental.tsdb.bucket-store.binary-index-header-enabled flag. Now the binary index-header is always enabled. [CHANGE] Experimental TSDB: Renamed index-cache metrics to use original metric names from Thanos, as Cortex is not aggregating them in any way: #2627 cortex_\u0026lt;service\u0026gt;_blocks_index_cache_items_evicted_total =\u0026gt; thanos_store_index_cache_items_evicted_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_items_added_total =\u0026gt; thanos_store_index_cache_items_added_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_requests_total =\u0026gt; thanos_store_index_cache_requests_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_items_overflowed_total =\u0026gt; thanos_store_index_cache_items_overflowed_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_hits_total =\u0026gt; thanos_store_index_cache_hits_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_items =\u0026gt; thanos_store_index_cache_items{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_items_size_bytes =\u0026gt; thanos_store_index_cache_items_size_bytes{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_total_size_bytes =\u0026gt; thanos_store_index_cache_total_size_bytes{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_memcached_operations_total =\u0026gt; thanos_memcached_operations_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_memcached_operation_failures_total =\u0026gt; thanos_memcached_operation_failures_total{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_memcached_operation_duration_seconds =\u0026gt; thanos_memcached_operation_duration_seconds{name=\u0026quot;index-cache\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_index_cache_memcached_operation_skipped_total =\u0026gt; thanos_memcached_operation_skipped_total{name=\u0026quot;index-cache\u0026quot;} [CHANGE] Experimental TSDB: Renamed metrics in bucket stores: #2627 cortex_\u0026lt;service\u0026gt;_blocks_meta_syncs_total =\u0026gt; cortex_blocks_meta_syncs_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_meta_sync_failures_total =\u0026gt; cortex_blocks_meta_sync_failures_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_meta_sync_duration_seconds =\u0026gt; cortex_blocks_meta_sync_duration_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_meta_sync_consistency_delay_seconds =\u0026gt; cortex_blocks_meta_sync_consistency_delay_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_meta_synced =\u0026gt; cortex_blocks_meta_synced{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_block_loads_total =\u0026gt; cortex_bucket_store_block_loads_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_block_load_failures_total =\u0026gt; cortex_bucket_store_block_load_failures_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_block_drops_total =\u0026gt; cortex_bucket_store_block_drops_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_block_drop_failures_total =\u0026gt; cortex_bucket_store_block_drop_failures_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_blocks_loaded =\u0026gt; cortex_bucket_store_blocks_loaded{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_data_touched =\u0026gt; cortex_bucket_store_series_data_touched{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_data_fetched =\u0026gt; cortex_bucket_store_series_data_fetched{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_data_size_touched_bytes =\u0026gt; cortex_bucket_store_series_data_size_touched_bytes{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_data_size_fetched_bytes =\u0026gt; cortex_bucket_store_series_data_size_fetched_bytes{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_blocks_queried =\u0026gt; cortex_bucket_store_series_blocks_queried{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_get_all_duration_seconds =\u0026gt; cortex_bucket_store_series_get_all_duration_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_merge_duration_seconds =\u0026gt; cortex_bucket_store_series_merge_duration_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_refetches_total =\u0026gt; cortex_bucket_store_series_refetches_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_series_result_series =\u0026gt; cortex_bucket_store_series_result_series{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_cached_postings_compressions_total =\u0026gt; cortex_bucket_store_cached_postings_compressions_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_cached_postings_compression_errors_total =\u0026gt; cortex_bucket_store_cached_postings_compression_errors_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_cached_postings_compression_time_seconds =\u0026gt; cortex_bucket_store_cached_postings_compression_time_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_cached_postings_original_size_bytes_total =\u0026gt; cortex_bucket_store_cached_postings_original_size_bytes_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_bucket_store_cached_postings_compressed_size_bytes_total =\u0026gt; cortex_bucket_store_cached_postings_compressed_size_bytes_total{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_sync_seconds =\u0026gt; cortex_bucket_stores_blocks_sync_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_blocks_last_successful_sync_timestamp_seconds =\u0026gt; cortex_bucket_stores_blocks_last_successful_sync_timestamp_seconds{component=\u0026quot;\u0026lt;service\u0026gt;\u0026quot;} [CHANGE] Available command-line flags are printed to stdout, and only when requested via -help. Using invalid flag no longer causes printing of all available flags. #2691 [CHANGE] Experimental Memberlist ring: randomize gossip node names to avoid conflicts when running multiple clients on the same host, or reusing host names (eg. pods in statefulset). Node name randomization can be disabled by using -memberlist.randomize-node-name=false. #2715 [CHANGE] Memberlist KV client is no longer considered experimental. #2725 [CHANGE] Experimental Delete Series: Make delete request cancellation duration configurable. #2760 [CHANGE] Removed -store.fullsize-chunks option which was undocumented and unused (it broke ingester hand-overs). #2656 [CHANGE] Query with no metric name that has previously resulted in HTTP status code 500 now returns status code 422 instead. #2571 [FEATURE] TLS config options added for GRPC clients in Querier (Query-frontend client \u0026amp; Ingester client), Ruler, Store Gateway, as well as HTTP client in Config store client. #2502 [FEATURE] The flag -frontend.max-cache-freshness is now supported within the limits overrides, to specify per-tenant max cache freshness values. The corresponding YAML config parameter has been changed from results_cache.max_freshness to limits_config.max_cache_freshness. The legacy YAML config parameter (results_cache.max_freshness) will continue to be supported till Cortex release v1.4.0. #2609 [FEATURE] Experimental gRPC Store: Added support to 3rd parties index and chunk stores using gRPC client/server plugin mechanism. #2220 [FEATURE] Add -cassandra.table-options flag to customize table options of Cassandra when creating the index or chunk table. #2575 [ENHANCEMENT] Propagate GOPROXY value when building build-image. This is to help the builders building the code in a Network where default Go proxy is not accessible (e.g. when behind some corporate VPN). #2741 [ENHANCEMENT] Querier: Added metric cortex_querier_request_duration_seconds for all requests to the querier. #2708 [ENHANCEMENT] Cortex is now built with Go 1.14. #2480 #2749 #2753 [ENHANCEMENT] Experimental TSDB: added the following metrics to the ingester: #2580 #2583 #2589 #2654 cortex_ingester_tsdb_appender_add_duration_seconds cortex_ingester_tsdb_appender_commit_duration_seconds cortex_ingester_tsdb_refcache_purge_duration_seconds cortex_ingester_tsdb_compactions_total cortex_ingester_tsdb_compaction_duration_seconds cortex_ingester_tsdb_wal_fsync_duration_seconds cortex_ingester_tsdb_wal_page_flushes_total cortex_ingester_tsdb_wal_completed_pages_total cortex_ingester_tsdb_wal_truncations_failed_total cortex_ingester_tsdb_wal_truncations_total cortex_ingester_tsdb_wal_writes_failed_total cortex_ingester_tsdb_checkpoint_deletions_failed_total cortex_ingester_tsdb_checkpoint_deletions_total cortex_ingester_tsdb_checkpoint_creations_failed_total cortex_ingester_tsdb_checkpoint_creations_total cortex_ingester_tsdb_wal_truncate_duration_seconds cortex_ingester_tsdb_head_active_appenders cortex_ingester_tsdb_head_series_not_found_total cortex_ingester_tsdb_head_chunks cortex_ingester_tsdb_mmap_chunk_corruptions_total cortex_ingester_tsdb_head_chunks_created_total cortex_ingester_tsdb_head_chunks_removed_total [ENHANCEMENT] Experimental TSDB: added metrics useful to alert on critical conditions of the blocks storage: #2573 cortex_compactor_last_successful_run_timestamp_seconds cortex_querier_blocks_last_successful_sync_timestamp_seconds (when store-gateway is disabled) cortex_querier_blocks_last_successful_scan_timestamp_seconds (when store-gateway is enabled) cortex_storegateway_blocks_last_successful_sync_timestamp_seconds [ENHANCEMENT] Experimental TSDB: added the flag -experimental.tsdb.wal-compression-enabled to allow to enable TSDB WAL compression. #2585 [ENHANCEMENT] Experimental TSDB: Querier and store-gateway components can now use so-called \u0026ldquo;caching bucket\u0026rdquo;, which can currently cache fetched chunks into shared memcached server. #2572 [ENHANCEMENT] Ruler: Automatically remove unhealthy rulers from the ring. #2587 [ENHANCEMENT] Query-tee: added support to /metadata, /alerts, and /rules endpoints #2600 [ENHANCEMENT] Query-tee: added support to query results comparison between two different backends. The comparison is disabled by default and can be enabled via -proxy.compare-responses=true. #2611 [ENHANCEMENT] Query-tee: improved the query-tee to not wait all backend responses before sending back the response to the client. The query-tee now sends back to the client first successful response, while honoring the -backend.preferred option. #2702 [ENHANCEMENT] Thanos and Prometheus upgraded. #2602 #2604 #2634 #2659 #2686 #2756 TSDB now holds less WAL files after Head Truncation. TSDB now does memory-mapping of Head chunks and reduces memory usage. [ENHANCEMENT] Experimental TSDB: decoupled blocks deletion from blocks compaction in the compactor, so that blocks deletion is not blocked by a busy compactor. The following metrics have been added: #2623 cortex_compactor_block_cleanup_started_total cortex_compactor_block_cleanup_completed_total cortex_compactor_block_cleanup_failed_total cortex_compactor_block_cleanup_last_successful_run_timestamp_seconds [ENHANCEMENT] Experimental TSDB: Use shared cache for metadata. This is especially useful when running multiple querier and store-gateway components to reduce number of object store API calls. #2626 #2640 [ENHANCEMENT] Experimental TSDB: when -querier.query-store-after is configured and running the experimental blocks storage, the time range of the query sent to the store is now manipulated to ensure the query end time is not more recent than \u0026lsquo;now - query-store-after\u0026rsquo;. #2642 [ENHANCEMENT] Experimental TSDB: small performance improvement in concurrent usage of RefCache, used during samples ingestion. #2651 [ENHANCEMENT] The following endpoints now respond appropriately to an Accept header with the value application/json #2673 /distributor/all_user_stats /distributor/ha_tracker /ingester/ring /store-gateway/ring /compactor/ring /ruler/ring /services [ENHANCEMENT] Experimental Cassandra backend: Add -cassandra.num-connections to allow increasing the number of TCP connections to each Cassandra server. #2666 [ENHANCEMENT] Experimental Cassandra backend: Use separate Cassandra clients and connections for reads and writes. #2666 [ENHANCEMENT] Experimental Cassandra backend: Add -cassandra.reconnect-interval to allow specifying the reconnect interval to a Cassandra server that has been marked DOWN by the gocql driver. Also change the default value of the reconnect interval from 60s to 1s. #2687 [ENHANCEMENT] Experimental Cassandra backend: Add option -cassandra.convict-hosts-on-failure=false to not convict host of being down when a request fails. #2684 [ENHANCEMENT] Experimental TSDB: Applied a jitter to the period bucket scans in order to better distribute bucket operations over the time and increase the probability of hitting the shared cache (if configured). #2693 [ENHANCEMENT] Experimental TSDB: Series limit per user and per metric now work in TSDB blocks. #2676 [ENHANCEMENT] Experimental Memberlist: Added ability to periodically rejoin the memberlist cluster. #2724 [ENHANCEMENT] Experimental Delete Series: Added the following metrics for monitoring processing of delete requests: #2730 cortex_purger_load_pending_requests_attempts_total: Number of attempts that were made to load pending requests with status. cortex_purger_oldest_pending_delete_request_age_seconds: Age of oldest pending delete request in seconds. cortex_purger_pending_delete_requests_count: Count of requests which are in process or are ready to be processed. [ENHANCEMENT] Experimental TSDB: Improved compactor to hard-delete also partial blocks with an deletion mark (even if the deletion mark threshold has not been reached). #2751 [ENHANCEMENT] Experimental TSDB: Introduced a consistency check done by the querier to ensure all expected blocks have been queried via the store-gateway. If a block is missing on a store-gateway, the querier retries fetching series from missing blocks up to 3 times. If the consistency check fails once all retries have been exhausted, the query execution fails. The following metrics have been added: #2593 #2630 #2689 #2695 cortex_querier_blocks_consistency_checks_total cortex_querier_blocks_consistency_checks_failed_total cortex_querier_storegateway_refetches_per_query [ENHANCEMENT] Delete requests can now be canceled #2555 [ENHANCEMENT] Table manager can now provision tables for delete store #2546 [BUGFIX] Ruler: Ensure temporary rule files with special characters are properly mapped and cleaned up. #2506 [BUGFIX] Fixes #2411, Ensure requests are properly routed to the prometheus api embedded in the query if -server.path-prefix is set. #2372 [BUGFIX] Experimental TSDB: fixed chunk data corruption when querying back series using the experimental blocks storage. #2400 [BUGFIX] Fixed collection of tracing spans from Thanos components used internally. #2655 [BUGFIX] Experimental TSDB: fixed memory leak in ingesters. #2586 [BUGFIX] QueryFrontend: fixed a situation where HTTP error is ignored and an incorrect status code is set. #2590 [BUGFIX] Ingester: Fix an ingester starting up in the JOINING state and staying there forever. #2565 [BUGFIX] QueryFrontend: fixed a panic (integer divide by zero) in the query-frontend. The query-frontend now requires the -querier.default-evaluation-interval config to be set to the same value of the querier. #2614 [BUGFIX] Experimental TSDB: when the querier receives a /series request with a time range older than the data stored in the ingester, it now ignores the requested time range and returns known series anyway instead of returning an empty response. This aligns the behaviour with the chunks storage. #2617 [BUGFIX] Cassandra: fixed an edge case leading to an invalid CQL query when querying the index on a Cassandra store. #2639 [BUGFIX] Ingester: increment series per metric when recovering from WAL or transfer. #2674 [BUGFIX] Fixed wrong number of arguments for 'mget' command Redis error when a query has no chunks to lookup from storage. #2700 #2796 [BUGFIX] Ingester: Automatically remove old tmp checkpoints, fixing a potential disk space leak after an ingester crashes. #2726 1.1.0 / 2020-05-21 This release brings the usual mix of bugfixes and improvements. The biggest change is that WAL support for chunks is now considered to be production-ready!\nPlease make sure to review renamed metrics, and update your dashboards and alerts accordingly.\n [CHANGE] Added v1 API routes documented in #2327. #2372 Added -http.alertmanager-http-prefix flag which allows the configuration of the path where the Alertmanager API and UI can be reached. The default is set to /alertmanager. Added -http.prometheus-http-prefix flag which allows the configuration of the path where the Prometheus API and UI can be reached. The default is set to /prometheus. Updated the index hosted at the root prefix to point to the updated routes. Legacy routes hardcoded with the /api/prom prefix now respect the -http.prefix flag. [CHANGE] The metrics cortex_distributor_ingester_appends_total and distributor_ingester_append_failures_total now include a type label to differentiate between samples and metadata. #2336 [CHANGE] The metrics for number of chunks and bytes flushed to the chunk store are renamed. Note that previous metrics were counted pre-deduplication, while new metrics are counted after deduplication. #2463 cortex_ingester_chunks_stored_total \u0026gt; cortex_chunk_store_stored_chunks_total cortex_ingester_chunk_stored_bytes_total \u0026gt; cortex_chunk_store_stored_chunk_bytes_total [CHANGE] Experimental TSDB: renamed blocks meta fetcher metrics: #2375 cortex_querier_bucket_store_blocks_meta_syncs_total \u0026gt; cortex_querier_blocks_meta_syncs_total cortex_querier_bucket_store_blocks_meta_sync_failures_total \u0026gt; cortex_querier_blocks_meta_sync_failures_total cortex_querier_bucket_store_blocks_meta_sync_duration_seconds \u0026gt; cortex_querier_blocks_meta_sync_duration_seconds cortex_querier_bucket_store_blocks_meta_sync_consistency_delay_seconds \u0026gt; cortex_querier_blocks_meta_sync_consistency_delay_seconds [CHANGE] Experimental TSDB: Modified default values for compactor.deletion-delay option from 48h to 12h and -experimental.tsdb.bucket-store.ignore-deletion-marks-delay from 24h to 6h. #2414 [CHANGE] WAL: Default value of -ingester.checkpoint-enabled changed to true. #2416 [CHANGE] trace_id field in log files has been renamed to traceID. #2518 [CHANGE] Slow query log has a different output now. Previously used url field has been replaced with host and path, and query parameters are logged as individual log fields with qs_ prefix. #2520 [CHANGE] WAL: WAL and checkpoint compression is now disabled. #2436 [CHANGE] Update in dependency go-kit/kit from v0.9.0 to v0.10.0. HTML escaping disabled in JSON Logger. #2535 [CHANGE] Experimental TSDB: Removed cortex_\u0026lt;service\u0026gt;_ prefix from Thanos objstore metrics and added component label to distinguish which Cortex component is doing API calls to the object storage when running in single-binary mode: #2568 cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operations_total renamed to thanos_objstore_bucket_operations_total{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operation_failures_total renamed to thanos_objstore_bucket_operation_failures_total{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_operation_duration_seconds renamed to thanos_objstore_bucket_operation_duration_seconds{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} cortex_\u0026lt;service\u0026gt;_thanos_objstore_bucket_last_successful_upload_time renamed to thanos_objstore_bucket_last_successful_upload_time{component=\u0026quot;\u0026lt;name\u0026gt;\u0026quot;} [CHANGE] FIFO cache: The -\u0026lt;prefix\u0026gt;.fifocache.size CLI flag has been renamed to -\u0026lt;prefix\u0026gt;.fifocache.max-size-items as well as its YAML config option size renamed to max_size_items. #2319 [FEATURE] Ruler: The -ruler.evaluation-delay flag was added to allow users to configure a default evaluation delay for all rules in cortex. The default value is 0 which is the current behavior. #2423 [FEATURE] Experimental: Added a new object storage client for OpenStack Swift. #2440 [FEATURE] TLS config options added to the Server. #2535 [FEATURE] Experimental: Added support for /api/v1/metadata Prometheus-based endpoint. #2549 [FEATURE] Add ability to limit concurrent queries to Cassandra with -cassandra.query-concurrency flag. #2562 [FEATURE] Experimental TSDB: Introduced store-gateway service used by the experimental blocks storage to load and query blocks. The store-gateway optionally supports blocks sharding and replication via a dedicated hash ring, configurable via -experimental.store-gateway.sharding-enabled and -experimental.store-gateway.sharding-ring.* flags. The following metrics have been added: #2433 #2458 #2469 #2523 cortex_querier_storegateway_instances_hit_per_query [ENHANCEMENT] Experimental TSDB: sample ingestion errors are now reported via existing cortex_discarded_samples_total metric. #2370 [ENHANCEMENT] Failures on samples at distributors and ingesters return the first validation error as opposed to the last. #2383 [ENHANCEMENT] Experimental TSDB: Added cortex_querier_blocks_meta_synced, which reflects current state of synced blocks over all tenants. #2392 [ENHANCEMENT] Added cortex_distributor_latest_seen_sample_timestamp_seconds metric to see how far behind Prometheus servers are in sending data. #2371 [ENHANCEMENT] FIFO cache to support eviction based on memory usage. Added -\u0026lt;prefix\u0026gt;.fifocache.max-size-bytes CLI flag and YAML config option max_size_bytes to specify memory limit of the cache. #2319, #2527 [ENHANCEMENT] Added -querier.worker-match-max-concurrent. Force worker concurrency to match the -querier.max-concurrent option. Overrides -querier.worker-parallelism. #2456 [ENHANCEMENT] Added the following metrics for monitoring delete requests: #2445 cortex_purger_delete_requests_received_total: Number of delete requests received per user. cortex_purger_delete_requests_processed_total: Number of delete requests processed per user. cortex_purger_delete_requests_chunks_selected_total: Number of chunks selected while building delete plans per user. cortex_purger_delete_requests_processing_failures_total: Number of delete requests processing failures per user. [ENHANCEMENT] Single Binary: Added query-frontend to the single binary. Single binary users will now benefit from various query-frontend features. Primarily: sharding, parallelization, load shedding, additional caching (if configured), and query retries. #2437 [ENHANCEMENT] Allow 1w (where w denotes week) and 1y (where y denotes year) when setting -store.cache-lookups-older-than and -store.max-look-back-period. #2454 [ENHANCEMENT] Optimize index queries for matchers using \u0026ldquo;a|b|c\u0026rdquo;-type regex. #2446 #2475 [ENHANCEMENT] Added per tenant metrics for queries and chunks and bytes read from chunk store: #2463 cortex_chunk_store_fetched_chunks_total and cortex_chunk_store_fetched_chunk_bytes_total cortex_query_frontend_queries_total (per tenant queries counted by the frontend) [ENHANCEMENT] WAL: New metrics cortex_ingester_wal_logged_bytes_total and cortex_ingester_checkpoint_logged_bytes_total added to track total bytes logged to disk for WAL and checkpoints. #2497 [ENHANCEMENT] Add de-duplicated chunks counter cortex_chunk_store_deduped_chunks_total which counts every chunk not sent to the store because it was already sent by another replica. #2485 [ENHANCEMENT] Query-frontend now also logs the POST data of long queries. #2481 [ENHANCEMENT] WAL: Ingester WAL records now have type header and the custom WAL records have been replaced by Prometheus TSDB\u0026rsquo;s WAL records. Old records will not be supported from 1.3 onwards. Note: once this is deployed, you cannot downgrade without data loss. #2436 [ENHANCEMENT] Redis Cache: Added idle_timeout, wait_on_pool_exhaustion and max_conn_lifetime options to redis cache configuration. #2550 [ENHANCEMENT] WAL: the experimental tag has been removed on the WAL in ingesters. #2560 [ENHANCEMENT] Use newer AWS API for paginated queries - removes \u0026lsquo;Deprecated\u0026rsquo; message from logfiles. #2452 [ENHANCEMENT] Experimental memberlist: Add retry with backoff on memberlist join other members. #2705 [ENHANCEMENT] Experimental TSDB: when the store-gateway sharding is enabled, unhealthy store-gateway instances are automatically removed from the ring after 10 consecutive -experimental.store-gateway.sharding-ring.heartbeat-timeout periods. #2526 [BUGFIX] Ruler: Ensure temporary rule files with special characters are properly mapped and cleaned up. #2506 [BUGFIX] Ensure requests are properly routed to the prometheus api embedded in the query if -server.path-prefix is set. Fixes #2411. #2372 [BUGFIX] Experimental TSDB: Fixed chunk data corruption when querying back series using the experimental blocks storage. #2400 [BUGFIX] Cassandra Storage: Fix endpoint TLS host verification. #2109 [BUGFIX] Experimental TSDB: Fixed response status code from 422 to 500 when an error occurs while iterating chunks with the experimental blocks storage. #2402 [BUGFIX] Ring: Fixed a situation where upgrading from pre-1.0 cortex with a rolling strategy caused new 1.0 ingesters to lose their zone value in the ring until manually forced to re-register. #2404 [BUGFIX] Distributor: /all_user_stats now show API and Rule Ingest Rate correctly. #2457 [BUGFIX] Fixed version, revision and branch labels exported by the cortex_build_info metric. #2468 [BUGFIX] QueryFrontend: fixed a situation where span context missed when downstream_url is used. #2539 [BUGFIX] Querier: Fixed a situation where querier would crash because of an unresponsive frontend instance. #2569 1.0.1 / 2020-04-23 [BUGFIX] Fix gaps when querying ingesters with replication factor = 3 and 2 ingesters in the cluster. #2503 1.0.0 / 2020-04-02 This is the first major release of Cortex. We made a lot of breaking changes in this release which have been detailed below. Please also see the stability guarantees we provide as part of a major release: https://cortexmetrics.io/docs/configuration/v1guarantees/\n [CHANGE] Remove the following deprecated flags: #2339\n -metrics.error-rate-query (use -metrics.write-throttle-query instead). -store.cardinality-cache-size (use -store.index-cache-read.enable-fifocache and -store.index-cache-read.fifocache.size instead). -store.cardinality-cache-validity (use -store.index-cache-read.enable-fifocache and -store.index-cache-read.fifocache.duration instead). -distributor.limiter-reload-period (flag unused) -ingester.claim-on-rollout (flag unused) -ingester.normalise-tokens (flag unused) [CHANGE] Renamed YAML file options to be more consistent. See full config file changes below. #2273\n [CHANGE] AWS based autoscaling has been removed. You can only use metrics based autoscaling now. -applicationautoscaling.url has been removed. See https://cortexmetrics.io/docs/production/aws/#dynamodb-capacity-provisioning on how to migrate. #2328\n [CHANGE] Renamed the memcache.write-back-goroutines and memcache.write-back-buffer flags to background.write-back-concurrency and background.write-back-buffer. This affects the following flags: #2241\n -frontend.memcache.write-back-buffer \u0026ndash;\u0026gt; -frontend.background.write-back-buffer -frontend.memcache.write-back-goroutines \u0026ndash;\u0026gt; -frontend.background.write-back-concurrency -store.index-cache-read.memcache.write-back-buffer \u0026ndash;\u0026gt; -store.index-cache-read.background.write-back-buffer -store.index-cache-read.memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.index-cache-read.background.write-back-concurrency -store.index-cache-write.memcache.write-back-buffer \u0026ndash;\u0026gt; -store.index-cache-write.background.write-back-buffer -store.index-cache-write.memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.index-cache-write.background.write-back-concurrency -memcache.write-back-buffer \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-buffer. Note the next change log for the difference. -memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-concurrency. Note the next change log for the difference. [CHANGE] Renamed the chunk cache flags to have store.chunks-cache. as prefix. This means the following flags have been changed: #2241\n -cache.enable-fifocache \u0026ndash;\u0026gt; -store.chunks-cache.cache.enable-fifocache -default-validity \u0026ndash;\u0026gt; -store.chunks-cache.default-validity -fifocache.duration \u0026ndash;\u0026gt; -store.chunks-cache.fifocache.duration -fifocache.size \u0026ndash;\u0026gt; -store.chunks-cache.fifocache.size -memcache.write-back-buffer \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-buffer. Note the previous change log for the difference. -memcache.write-back-goroutines \u0026ndash;\u0026gt; -store.chunks-cache.background.write-back-concurrency. Note the previous change log for the difference. -memcached.batchsize \u0026ndash;\u0026gt; -store.chunks-cache.memcached.batchsize -memcached.consistent-hash \u0026ndash;\u0026gt; -store.chunks-cache.memcached.consistent-hash -memcached.expiration \u0026ndash;\u0026gt; -store.chunks-cache.memcached.expiration -memcached.hostname \u0026ndash;\u0026gt; -store.chunks-cache.memcached.hostname -memcached.max-idle-conns \u0026ndash;\u0026gt; -store.chunks-cache.memcached.max-idle-conns -memcached.parallelism \u0026ndash;\u0026gt; -store.chunks-cache.memcached.parallelism -memcached.service \u0026ndash;\u0026gt; -store.chunks-cache.memcached.service -memcached.timeout \u0026ndash;\u0026gt; -store.chunks-cache.memcached.timeout -memcached.update-interval \u0026ndash;\u0026gt; -store.chunks-cache.memcached.update-interval -redis.enable-tls \u0026ndash;\u0026gt; -store.chunks-cache.redis.enable-tls -redis.endpoint \u0026ndash;\u0026gt; -store.chunks-cache.redis.endpoint -redis.expiration \u0026ndash;\u0026gt; -store.chunks-cache.redis.expiration -redis.max-active-conns \u0026ndash;\u0026gt; -store.chunks-cache.redis.max-active-conns -redis.max-idle-conns \u0026ndash;\u0026gt; -store.chunks-cache.redis.max-idle-conns -redis.password \u0026ndash;\u0026gt; -store.chunks-cache.redis.password -redis.timeout \u0026ndash;\u0026gt; -store.chunks-cache.redis.timeout [CHANGE] Rename the -store.chunk-cache-stubs to -store.chunks-cache.cache-stubs to be more inline with above. #2241\n [CHANGE] Change prefix of flags -dynamodb.periodic-table.* to -table-manager.index-table.*. #2359\n [CHANGE] Change prefix of flags -dynamodb.chunk-table.* to -table-manager.chunk-table.*. #2359\n [CHANGE] Change the following flags: #2359\n -dynamodb.poll-interval \u0026ndash;\u0026gt; -table-manager.poll-interval -dynamodb.periodic-table.grace-period \u0026ndash;\u0026gt; -table-manager.periodic-table.grace-period [CHANGE] Renamed the following flags: #2273\n -dynamodb.chunk.gang.size \u0026ndash;\u0026gt; -dynamodb.chunk-gang-size -dynamodb.chunk.get.max.parallelism \u0026ndash;\u0026gt; -dynamodb.chunk-get-max-parallelism [CHANGE] Don\u0026rsquo;t support mixed time units anymore for duration. For example, 168h5m0s doesn\u0026rsquo;t work anymore, please use just one unit (s|m|h|d|w|y). #2252\n [CHANGE] Utilize separate protos for rule state and storage. Experimental ruler API will not be functional until the rollout is complete. #2226\n [CHANGE] Frontend worker in querier now starts after all Querier module dependencies are started. This fixes issue where frontend worker started to send queries to querier before it was ready to serve them (mostly visible when using experimental blocks storage). #2246\n [CHANGE] Lifecycler component now enters Failed state on errors, and doesn\u0026rsquo;t exit the process. (Important if you\u0026rsquo;re vendoring Cortex and use Lifecycler) #2251\n [CHANGE] /ready handler now returns 200 instead of 204. #2330\n [CHANGE] Better defaults for the following options: #2344\n -\u0026lt;prefix\u0026gt;.consul.consistent-reads: Old default: true, new default: false. This reduces the load on Consul. -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit: Old default: 0, new default: 1. This rate limits the reads to 1 per second. Which is good enough for ring watches. -distributor.health-check-ingesters: Old default: false, new default: true. -ingester.max-stale-chunk-idle: Old default: 0, new default: 2m. This lets us expire series that we know are stale early. -ingester.spread-flushes: Old default: false, new default: true. This allows to better de-duplicate data and use less space. -ingester.chunk-age-jitter: Old default: 20mins, new default: 0. This is to enable the -ingester.spread-flushes to true. -\u0026lt;prefix\u0026gt;.memcached.batchsize: Old default: 0, new default: 1024. This allows batching of requests and keeps the concurrent requests low. -\u0026lt;prefix\u0026gt;.memcached.consistent-hash: Old default: false, new default: true. This allows for better cache hits when the memcaches are scaled up and down. -querier.batch-iterators: Old default: false, new default: true. -querier.ingester-streaming: Old default: false, new default: true. [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.postings-cache-compression-enabled to enable postings compression when storing to cache. #2335\n [CHANGE] Experimental TSDB: Added -compactor.deletion-delay, which is time before a block marked for deletion is deleted from bucket. If not 0, blocks will be marked for deletion and compactor component will delete blocks marked for deletion from the bucket. If delete-delay is 0, blocks will be deleted straight away. Note that deleting blocks immediately can cause query failures, if store gateway / querier still has the block loaded, or compactor is ignoring the deletion because it\u0026rsquo;s compacting the block at the same time. Default value is 48h. #2335\n [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.index-cache.postings-compression-enabled, to set duration after which the blocks marked for deletion will be filtered out while fetching blocks used for querying. This option allows querier to ignore blocks that are marked for deletion with some delay. This ensures store can still serve blocks that are meant to be deleted but do not have a replacement yet. Default is 24h, half of the default value for -compactor.deletion-delay. #2335\n [CHANGE] Experimental TSDB: Added -experimental.tsdb.bucket-store.index-cache.memcached.max-item-size to control maximum size of item that is stored to memcached. Defaults to 1 MiB. #2335\n [FEATURE] Added experimental storage API to the ruler service that is enabled when the -experimental.ruler.enable-api is set to true #2269\n -ruler.storage.type flag now allows s3,gcs, and azure values -ruler.storage.(s3|gcs|azure) flags exist to allow the configuration of object clients set for rule storage [CHANGE] Renamed table manager metrics. #2307 #2359\n cortex_dynamo_sync_tables_seconds -\u0026gt; cortex_table_manager_sync_duration_seconds cortex_dynamo_table_capacity_units -\u0026gt; cortex_table_capacity_units [FEATURE] Flusher target to flush the WAL. #2075\n -flusher.wal-dir for the WAL directory to recover from. -flusher.concurrent-flushes for number of concurrent flushes. -flusher.flush-op-timeout is duration after which a flush should timeout. [FEATURE] Ingesters can now have an optional availability zone set, to ensure metric replication is distributed across zones. This is set via the -ingester.availability-zone flag or the availability_zone field in the config file. #2317\n [ENHANCEMENT] Better re-use of connections to DynamoDB and S3. #2268\n [ENHANCEMENT] Reduce number of goroutines used while executing a single index query. #2280\n [ENHANCEMENT] Experimental TSDB: Add support for local filesystem backend. #2245\n [ENHANCEMENT] Experimental TSDB: Added memcached support for the TSDB index cache. #2290\n [ENHANCEMENT] Experimental TSDB: Removed gRPC server to communicate between querier and BucketStore. #2324\n [ENHANCEMENT] Allow 1w (where w denotes week) and 1y (where y denotes year) when setting table period and retention. #2252\n [ENHANCEMENT] Added FIFO cache metrics for current number of entries and memory usage. #2270\n [ENHANCEMENT] Output all config fields to /config API, including those with empty value. #2209\n [ENHANCEMENT] Add \u0026ldquo;missing_metric_name\u0026rdquo; and \u0026ldquo;metric_name_invalid\u0026rdquo; reasons to cortex_discarded_samples_total metric. #2346\n [ENHANCEMENT] Experimental TSDB: sample ingestion errors are now reported via existing cortex_discarded_samples_total metric. #2370\n [BUGFIX] Ensure user state metrics are updated if a transfer fails. #2338\n [BUGFIX] Fixed etcd client keepalive settings. #2278\n [BUGFIX] Register the metrics of the WAL. #2295\n [BUXFIX] Experimental TSDB: fixed error handling when ingesting out of bound samples. #2342\n Known issues This experimental blocks storage in Cortex 1.0.0 has a bug which may lead to the error cannot iterate chunk for series when running queries. This bug has been fixed in #2400. If you\u0026rsquo;re running the experimental blocks storage, please build Cortex from master. Config file breaking changes In this section you can find a config file diff showing the breaking changes introduced in Cortex. You can also find the full configuration file reference doc in the website.\n### ingester_config # Period with which to attempt to flush chunks. # CLI flag: -ingester.flush-period -[flushcheckperiod: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_period: \u0026lt;duration\u0026gt; | default = 1m0s] # Period chunks will remain in memory after flushing. # CLI flag: -ingester.retain-period -[retainperiod: \u0026lt;duration\u0026gt; | default = 5m0s] +[retain_period: \u0026lt;duration\u0026gt; | default = 5m0s] # Maximum chunk idle time before flushing. # CLI flag: -ingester.max-chunk-idle -[maxchunkidle: \u0026lt;duration\u0026gt; | default = 5m0s] +[max_chunk_idle_time: \u0026lt;duration\u0026gt; | default = 5m0s] # Maximum chunk idle time for chunks terminating in stale markers before # flushing. 0 disables it and a stale series is not flushed until the # max-chunk-idle timeout is reached. # CLI flag: -ingester.max-stale-chunk-idle -[maxstalechunkidle: \u0026lt;duration\u0026gt; | default = 0s] +[max_stale_chunk_idle_time: \u0026lt;duration\u0026gt; | default = 2m0s] # Timeout for individual flush operations. # CLI flag: -ingester.flush-op-timeout -[flushoptimeout: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_op_timeout: \u0026lt;duration\u0026gt; | default = 1m0s] # Maximum chunk age before flushing. # CLI flag: -ingester.max-chunk-age -[maxchunkage: \u0026lt;duration\u0026gt; | default = 12h0m0s] +[max_chunk_age: \u0026lt;duration\u0026gt; | default = 12h0m0s] -# Range of time to subtract from MaxChunkAge to spread out flushes +# Range of time to subtract from -ingester.max-chunk-age to spread out flushes # CLI flag: -ingester.chunk-age-jitter -[chunkagejitter: \u0026lt;duration\u0026gt; | default = 20m0s] +[chunk_age_jitter: \u0026lt;duration\u0026gt; | default = 0] # Number of concurrent goroutines flushing to dynamodb. # CLI flag: -ingester.concurrent-flushes -[concurrentflushes: \u0026lt;int\u0026gt; | default = 50] +[concurrent_flushes: \u0026lt;int\u0026gt; | default = 50] -# If true, spread series flushes across the whole period of MaxChunkAge +# If true, spread series flushes across the whole period of +# -ingester.max-chunk-age. # CLI flag: -ingester.spread-flushes -[spreadflushes: \u0026lt;boolean\u0026gt; | default = false] +[spread_flushes: \u0026lt;boolean\u0026gt; | default = true] # Period with which to update the per-user ingestion rates. # CLI flag: -ingester.rate-update-period -[rateupdateperiod: \u0026lt;duration\u0026gt; | default = 15s] +[rate_update_period: \u0026lt;duration\u0026gt; | default = 15s] ### querier_config # The maximum number of concurrent queries. # CLI flag: -querier.max-concurrent -[maxconcurrent: \u0026lt;int\u0026gt; | default = 20] +[max_concurrent: \u0026lt;int\u0026gt; | default = 20] # Use batch iterators to execute query, as opposed to fully materialising the # series in memory. Takes precedent over the -querier.iterators flag. # CLI flag: -querier.batch-iterators -[batchiterators: \u0026lt;boolean\u0026gt; | default = false] +[batch_iterators: \u0026lt;boolean\u0026gt; | default = true] # Use streaming RPCs to query ingester. # CLI flag: -querier.ingester-streaming -[ingesterstreaming: \u0026lt;boolean\u0026gt; | default = false] +[ingester_streaming: \u0026lt;boolean\u0026gt; | default = true] # Maximum number of samples a single query can load into memory. # CLI flag: -querier.max-samples -[maxsamples: \u0026lt;int\u0026gt; | default = 50000000] +[max_samples: \u0026lt;int\u0026gt; | default = 50000000] # The default evaluation interval or step size for subqueries. # CLI flag: -querier.default-evaluation-interval -[defaultevaluationinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[default_evaluation_interval: \u0026lt;duration\u0026gt; | default = 1m0s] ### query_frontend_config # URL of downstream Prometheus. # CLI flag: -frontend.downstream-url -[downstream: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[downstream_url: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### ruler_config # URL of alerts return path. # CLI flag: -ruler.external.url -[externalurl: \u0026lt;url\u0026gt; | default = ] +[external_url: \u0026lt;url\u0026gt; | default = ] # How frequently to evaluate rules # CLI flag: -ruler.evaluation-interval -[evaluationinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[evaluation_interval: \u0026lt;duration\u0026gt; | default = 1m0s] # How frequently to poll for rule changes # CLI flag: -ruler.poll-interval -[pollinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[poll_interval: \u0026lt;duration\u0026gt; | default = 1m0s] -storeconfig: +storage: # file path to store temporary rule files for the prometheus rule managers # CLI flag: -ruler.rule-path -[rulepath: \u0026lt;string\u0026gt; | default = \u0026#34;/rules\u0026#34;] +[rule_path: \u0026lt;string\u0026gt; | default = \u0026#34;/rules\u0026#34;] # URL of the Alertmanager to send notifications to. # CLI flag: -ruler.alertmanager-url -[alertmanagerurl: \u0026lt;url\u0026gt; | default = ] +[alertmanager_url: \u0026lt;url\u0026gt; | default = ] # Use DNS SRV records to discover alertmanager hosts. # CLI flag: -ruler.alertmanager-discovery -[alertmanagerdiscovery: \u0026lt;boolean\u0026gt; | default = false] +[enable_alertmanager_discovery: \u0026lt;boolean\u0026gt; | default = false] # How long to wait between refreshing alertmanager hosts. # CLI flag: -ruler.alertmanager-refresh-interval -[alertmanagerrefreshinterval: \u0026lt;duration\u0026gt; | default = 1m0s] +[alertmanager_refresh_interval: \u0026lt;duration\u0026gt; | default = 1m0s] # If enabled requests to alertmanager will utilize the V2 API. # CLI flag: -ruler.alertmanager-use-v2 -[alertmanangerenablev2api: \u0026lt;boolean\u0026gt; | default = false] +[enable_alertmanager_v2: \u0026lt;boolean\u0026gt; | default = false] # Capacity of the queue for notifications to be sent to the Alertmanager. # CLI flag: -ruler.notification-queue-capacity -[notificationqueuecapacity: \u0026lt;int\u0026gt; | default = 10000] +[notification_queue_capacity: \u0026lt;int\u0026gt; | default = 10000] # HTTP timeout duration when sending notifications to the Alertmanager. # CLI flag: -ruler.notification-timeout -[notificationtimeout: \u0026lt;duration\u0026gt; | default = 10s] +[notification_timeout: \u0026lt;duration\u0026gt; | default = 10s] # Distribute rule evaluation using ring backend # CLI flag: -ruler.enable-sharding -[enablesharding: \u0026lt;boolean\u0026gt; | default = false] +[enable_sharding: \u0026lt;boolean\u0026gt; | default = false] # Time to spend searching for a pending ruler when shutting down. # CLI flag: -ruler.search-pending-for -[searchpendingfor: \u0026lt;duration\u0026gt; | default = 5m0s] +[search_pending_for: \u0026lt;duration\u0026gt; | default = 5m0s] # Period with which to attempt to flush rule groups. # CLI flag: -ruler.flush-period -[flushcheckperiod: \u0026lt;duration\u0026gt; | default = 1m0s] +[flush_period: \u0026lt;duration\u0026gt; | default = 1m0s] ### alertmanager_config # Base path for data storage. # CLI flag: -alertmanager.storage.path -[datadir: \u0026lt;string\u0026gt; | default = \u0026#34;data/\u0026#34;] +[data_dir: \u0026lt;string\u0026gt; | default = \u0026#34;data/\u0026#34;] # will be used to prefix all HTTP endpoints served by Alertmanager. If omitted, # relevant URL components will be derived automatically. # CLI flag: -alertmanager.web.external-url -[externalurl: \u0026lt;url\u0026gt; | default = ] +[external_url: \u0026lt;url\u0026gt; | default = ] # How frequently to poll Cortex configs # CLI flag: -alertmanager.configs.poll-interval -[pollinterval: \u0026lt;duration\u0026gt; | default = 15s] +[poll_interval: \u0026lt;duration\u0026gt; | default = 15s] # Listen address for cluster. # CLI flag: -cluster.listen-address -[clusterbindaddr: \u0026lt;string\u0026gt; | default = \u0026#34;0.0.0.0:9094\u0026#34;] +[cluster_bind_address: \u0026lt;string\u0026gt; | default = \u0026#34;0.0.0.0:9094\u0026#34;] # Explicit address to advertise in cluster. # CLI flag: -cluster.advertise-address -[clusteradvertiseaddr: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[cluster_advertise_address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # Time to wait between peers to send notifications. # CLI flag: -cluster.peer-timeout -[peertimeout: \u0026lt;duration\u0026gt; | default = 15s] +[peer_timeout: \u0026lt;duration\u0026gt; | default = 15s] # Filename of fallback config to use if none specified for instance. # CLI flag: -alertmanager.configs.fallback -[fallbackconfigfile: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[fallback_config_file: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # Root of URL to generate if config is http://internal.monitor # CLI flag: -alertmanager.configs.auto-webhook-root -[autowebhookroot: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[auto_webhook_root: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### table_manager_config -store: +storage: -# How frequently to poll DynamoDB to learn our capacity. -# CLI flag: -dynamodb.poll-interval -[dynamodb_poll_interval: \u0026lt;duration\u0026gt; | default = 2m0s] +# How frequently to poll backend to learn our capacity. +# CLI flag: -table-manager.poll-interval +[poll_interval: \u0026lt;duration\u0026gt; | default = 2m0s] -# DynamoDB periodic tables grace period (duration which table will be -# created/deleted before/after it\u0026#39;s needed). -# CLI flag: -dynamodb.periodic-table.grace-period +# Periodic tables grace period (duration which table will be created/deleted +# before/after it\u0026#39;s needed). +# CLI flag: -table-manager.periodic-table.grace-period [creation_grace_period: \u0026lt;duration\u0026gt; | default = 10m0s] index_tables_provisioning: # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.periodic-table.enable-ondemand-throughput-mode - [provisioned_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.index-table.enable-ondemand-throughput-mode + [enable_ondemand_throughput_mode: \u0026lt;boolean\u0026gt; | default = false] # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.periodic-table.inactive-enable-ondemand-throughput-mode - [inactive_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.index-table.inactive-enable-ondemand-throughput-mode + [enable_inactive_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] chunk_tables_provisioning: # Enables on demand throughput provisioning for the storage provider (if - # supported). Applies only to tables which are not autoscaled - # CLI flag: -dynamodb.chunk-table.enable-ondemand-throughput-mode - [provisioned_throughput_on_demand_mode: \u0026lt;boolean\u0026gt; | default = false] + # supported). Applies only to tables which are not autoscaled. Supported by + # DynamoDB + # CLI flag: -table-manager.chunk-table.enable-ondemand-throughput-mode + [enable_ondemand_throughput_mode: \u0026lt;boolean\u0026gt; | default = false] ### storage_config aws: - dynamodbconfig: + dynamodb: # DynamoDB endpoint URL with escaped Key and Secret encoded. If only region # is specified as a host, proper endpoint will be deduced. Use # inmemory:///\u0026lt;table-name\u0026gt; to use a mock in-memory implementation. # CLI flag: -dynamodb.url - [dynamodb: \u0026lt;url\u0026gt; | default = ] + [dynamodb_url: \u0026lt;url\u0026gt; | default = ] # DynamoDB table management requests per second limit. # CLI flag: -dynamodb.api-limit - [apilimit: \u0026lt;float\u0026gt; | default = 2] + [api_limit: \u0026lt;float\u0026gt; | default = 2] # DynamoDB rate cap to back off when throttled. # CLI flag: -dynamodb.throttle-limit - [throttlelimit: \u0026lt;float\u0026gt; | default = 10] + [throttle_limit: \u0026lt;float\u0026gt; | default = 10] - - # ApplicationAutoscaling endpoint URL with escaped Key and Secret encoded. - # CLI flag: -applicationautoscaling.url - [applicationautoscaling: \u0026lt;url\u0026gt; | default = ] # Queue length above which we will scale up capacity # CLI flag: -metrics.target-queue-length - [targetqueuelen: \u0026lt;int\u0026gt; | default = 100000] + [target_queue_length: \u0026lt;int\u0026gt; | default = 100000] # Scale up capacity by this multiple # CLI flag: -metrics.scale-up-factor - [scaleupfactor: \u0026lt;float\u0026gt; | default = 1.3] + [scale_up_factor: \u0026lt;float\u0026gt; | default = 1.3] # Ignore throttling below this level (rate per second) # CLI flag: -metrics.ignore-throttle-below - [minthrottling: \u0026lt;float\u0026gt; | default = 1] + [ignore_throttle_below: \u0026lt;float\u0026gt; | default = 1] # query to fetch ingester queue length # CLI flag: -metrics.queue-length-query - [queuelengthquery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;] + [queue_length_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(avg_over_time(cortex_ingester_flush_queue_length{job=\\\u0026#34;cortex/ingester\\\u0026#34;}[2m]))\u0026#34;] # query to fetch throttle rates per table # CLI flag: -metrics.write-throttle-query - [throttlequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] + [write_throttle_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_throttled_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] # query to fetch write capacity usage per table # CLI flag: -metrics.usage-query - [usagequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;] + [write_usage_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.BatchWriteItem\\\u0026#34;}[15m])) by (table) \u0026gt; 0\u0026#34;] # query to fetch read capacity usage per table # CLI flag: -metrics.read-usage-query - [readusagequery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;] + [read_usage_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(rate(cortex_dynamo_consumed_capacity_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;}[1h])) by (table) \u0026gt; 0\u0026#34;] # query to fetch read errors per table # CLI flag: -metrics.read-error-query - [readerrorquery: \u0026lt;string\u0026gt; | default = \u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] + [read_error_query: \u0026lt;string\u0026gt; | default = \u0026#34;sum(increase(cortex_dynamo_failures_total{operation=\\\u0026#34;DynamoDB.QueryPages\\\u0026#34;,error=\\\u0026#34;ProvisionedThroughputExceededException\\\u0026#34;}[1m])) by (table) \u0026gt; 0\u0026#34;] # Number of chunks to group together to parallelise fetches (zero to # disable) - # CLI flag: -dynamodb.chunk.gang.size - [chunkgangsize: \u0026lt;int\u0026gt; | default = 10] + # CLI flag: -dynamodb.chunk-gang-size + [chunk_gang_size: \u0026lt;int\u0026gt; | default = 10] # Max number of chunk-get operations to start in parallel - # CLI flag: -dynamodb.chunk.get.max.parallelism - [chunkgetmaxparallelism: \u0026lt;int\u0026gt; | default = 32] + # CLI flag: -dynamodb.chunk.get-max-parallelism + [chunk_get_max_parallelism: \u0026lt;int\u0026gt; | default = 32] backoff_config: # Minimum delay when backing off. # CLI flag: -bigtable.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -bigtable.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -bigtable.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] # If enabled, once a tables info is fetched, it is cached. # CLI flag: -bigtable.table-cache.enabled - [tablecacheenabled: \u0026lt;boolean\u0026gt; | default = true] + [table_cache_enabled: \u0026lt;boolean\u0026gt; | default = true] # Duration to cache tables before checking again. # CLI flag: -bigtable.table-cache.expiration - [tablecacheexpiration: \u0026lt;duration\u0026gt; | default = 30m0s] + [table_cache_expiration: \u0026lt;duration\u0026gt; | default = 30m0s] # Cache validity for active index entries. Should be no higher than # -ingester.max-chunk-idle. # CLI flag: -store.index-cache-validity -[indexcachevalidity: \u0026lt;duration\u0026gt; | default = 5m0s] +[index_cache_validity: \u0026lt;duration\u0026gt; | default = 5m0s] ### ingester_client_config grpc_client_config: backoff_config: # Minimum delay when backing off. # CLI flag: -ingester.client.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -ingester.client.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -ingester.client.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] ### frontend_worker_config -# Address of query frontend service. +# Address of query frontend service, in host:port format. # CLI flag: -querier.frontend-address -[address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +[frontend_address: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # How often to query DNS. # CLI flag: -querier.dns-lookup-period -[dnslookupduration: \u0026lt;duration\u0026gt; | default = 10s] +[dns_lookup_duration: \u0026lt;duration\u0026gt; | default = 10s] grpc_client_config: backoff_config: # Minimum delay when backing off. # CLI flag: -querier.frontend-client.backoff-min-period - [minbackoff: \u0026lt;duration\u0026gt; | default = 100ms] + [min_period: \u0026lt;duration\u0026gt; | default = 100ms] # Maximum delay when backing off. # CLI flag: -querier.frontend-client.backoff-max-period - [maxbackoff: \u0026lt;duration\u0026gt; | default = 10s] + [max_period: \u0026lt;duration\u0026gt; | default = 10s] # Number of times to backoff and retry before failing. # CLI flag: -querier.frontend-client.backoff-retries - [maxretries: \u0026lt;int\u0026gt; | default = 10] + [max_retries: \u0026lt;int\u0026gt; | default = 10] ### consul_config # ACL Token used to interact with Consul. -# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acltoken -[acltoken: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +# CLI flag: -\u0026lt;prefix\u0026gt;.consul.acl-token +[acl_token: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] # HTTP timeout when talking to Consul # CLI flag: -\u0026lt;prefix\u0026gt;.consul.client-timeout -[httpclienttimeout: \u0026lt;duration\u0026gt; | default = 20s] +[http_client_timeout: \u0026lt;duration\u0026gt; | default = 20s] # Enable consistent reads to Consul. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.consistent-reads -[consistentreads: \u0026lt;boolean\u0026gt; | default = true] +[consistent_reads: \u0026lt;boolean\u0026gt; | default = false] # Rate limit when watching key or prefix in Consul, in requests per second. 0 # disables the rate limit. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-rate-limit -[watchkeyratelimit: \u0026lt;float\u0026gt; | default = 0] +[watch_rate_limit: \u0026lt;float\u0026gt; | default = 1] # Burst size used in rate limit. Values less than 1 are treated as 1. # CLI flag: -\u0026lt;prefix\u0026gt;.consul.watch-burst-size -[watchkeyburstsize: \u0026lt;int\u0026gt; | default = 1] +[watch_burst_size: \u0026lt;int\u0026gt; | default = 1] ### configstore_config # URL of configs API server. # CLI flag: -\u0026lt;prefix\u0026gt;.configs.url -[configsapiurl: \u0026lt;url\u0026gt; | default = ] +[configs_api_url: \u0026lt;url\u0026gt; | default = ] # Timeout for requests to Weave Cloud configs service. # CLI flag: -\u0026lt;prefix\u0026gt;.configs.client-timeout -[clienttimeout: \u0026lt;duration\u0026gt; | default = 5s] +[client_timeout: \u0026lt;duration\u0026gt; | default = 5s] 0.7.0 / 2020-03-16 Cortex 0.7.0 is a major step forward the upcoming 1.0 release. In this release, we\u0026rsquo;ve got 164 contributions from 26 authors. Thanks to all contributors! ❤️\nPlease be aware that Cortex 0.7.0 introduces some breaking changes. You\u0026rsquo;re encouraged to read all the [CHANGE] entries below before upgrading your Cortex cluster. In particular:\n Cleaned up some configuration options in preparation for the Cortex 1.0.0 release (see also the annotated config file breaking changes below): Removed CLI flags support to configure the schema (see how to migrate from flags to schema file) Renamed CLI flag -config-yaml to -schema-config-file Removed CLI flag -store.min-chunk-age in favor of -querier.query-store-after. The corresponding YAML config option ingestermaxquerylookback has been renamed to query_ingesters_within Deprecated CLI flag -frontend.cache-split-interval in favor of -querier.split-queries-by-interval Renamed the YAML config option defaul_validity to default_validity Removed the YAML config option config_store (in the alertmanager YAML config) in favor of store Removed the YAML config root block configdb in favor of configs. This change is also reflected in the following CLI flags renaming: -database.* -\u0026gt; -configs.database.* -database.migrations -\u0026gt; -configs.database.migrations-dir Removed the fluentd-based billing infrastructure including the CLI flags: -distributor.enable-billing -billing.max-buffered-events -billing.retry-delay -billing.ingester Removed support for using denormalised tokens in the ring. Before upgrading, make sure your Cortex cluster is already running v0.6.0 or an earlier version with -ingester.normalise-tokens=true Full changelog [CHANGE] Removed support for flags to configure schema. Further, the flag for specifying the config file (-config-yaml) has been deprecated. Please use -schema-config-file. See the Schema Configuration documentation for more details on how to configure the schema using the YAML file. #2221 [CHANGE] In the config file, the root level config_store config option has been moved to alertmanager \u0026gt; store \u0026gt; configdb. #2125 [CHANGE] Removed unnecessary frontend.cache-split-interval in favor of querier.split-queries-by-interval both to reduce configuration complexity and guarantee alignment of these two configs. Starting from now, -querier.cache-results may only be enabled in conjunction with -querier.split-queries-by-interval (previously the cache interval default was 24h so if you want to preserve the same behaviour you should set -querier.split-queries-by-interval=24h). #2040 [CHANGE] Renamed Configs configuration options. #2187 configuration options -database.* -\u0026gt; -configs.database.* -database.migrations -\u0026gt; -configs.database.migrations-dir config file configdb.uri: -\u0026gt; configs.database.uri: configdb.migrationsdir: -\u0026gt; configs.database.migrations_dir: configdb.passwordfile: -\u0026gt; configs.database.password_file: [CHANGE] Moved -store.min-chunk-age to the Querier config as -querier.query-store-after, allowing the store to be skipped during query time if the metrics wouldn\u0026rsquo;t be found. The YAML config option ingestermaxquerylookback has been renamed to query_ingesters_within to match its CLI flag. #1893 [CHANGE] Renamed the cache configuration setting defaul_validity to default_validity. #2140 [CHANGE] Remove fluentd-based billing infrastructure and flags such as -distributor.enable-billing. #1491 [CHANGE] Removed remaining support for using denormalised tokens in the ring. If you\u0026rsquo;re still running ingesters with denormalised tokens (Cortex 0.4 or earlier, with -ingester.normalise-tokens=false), such ingesters will now be completely invisible to distributors and need to be either switched to Cortex 0.6.0 or later, or be configured to use normalised tokens. #2034 [CHANGE] The frontend http server will now send 502 in case of deadline exceeded and 499 if the user requested cancellation. #2156 [CHANGE] We now enforce queries to be up to -querier.max-query-into-future into the future (defaults to 10m). #1929 -store.min-chunk-age has been removed -querier.query-store-after has been added in it\u0026rsquo;s place. [CHANGE] Removed unused /validate_expr endpoint. #2152 [CHANGE] Updated Prometheus dependency to v2.16.0. This Prometheus version uses Active Query Tracker to limit concurrent queries. In order to keep -querier.max-concurrent working, Active Query Tracker is enabled by default, and is configured to store its data to active-query-tracker directory (relative to current directory when Cortex started). This can be changed by using -querier.active-query-tracker-dir option. Purpose of Active Query Tracker is to log queries that were running when Cortex crashes. This logging happens on next Cortex start. #2088 [CHANGE] Default to BigChunk encoding; may result in slightly higher disk usage if many timeseries have a constant value, but should generally result in fewer, bigger chunks. #2207 [CHANGE] WAL replays are now done while the rest of Cortex is starting, and more specifically, when HTTP server is running. This makes it possible to scrape metrics during WAL replays. Applies to both chunks and experimental blocks storage. #2222 [CHANGE] Cortex now has /ready probe for all services, not just ingester and querier as before. In single-binary mode, /ready reports 204 only if all components are running properly. #2166 [CHANGE] If you are vendoring Cortex and use its components in your project, be aware that many Cortex components no longer start automatically when they are created. You may want to review PR and attached document. #2166 [CHANGE] Experimental TSDB: the querier in-memory index cache used by the experimental blocks storage shifted from per-tenant to per-querier. The -experimental.tsdb.bucket-store.index-cache-size-bytes now configures the per-querier index cache max size instead of a per-tenant cache and its default has been increased to 1GB. #2189 [CHANGE] Experimental TSDB: TSDB head compaction interval and concurrency is now configurable (defaults to 1 min interval and 5 concurrent head compactions). New options: -experimental.tsdb.head-compaction-interval and -experimental.tsdb.head-compaction-concurrency. #2172 [CHANGE] Experimental TSDB: switched the blocks storage index header to the binary format. This change is expected to have no visible impact, except lower startup times and memory usage in the queriers. It\u0026rsquo;s possible to switch back to the old JSON format via the flag -experimental.tsdb.bucket-store.binary-index-header-enabled=false. #2223 [CHANGE] Experimental Memberlist KV store can now be used in single-binary Cortex. Attempts to use it previously would fail with panic. This change also breaks existing binary protocol used to exchange gossip messages, so this version will not be able to understand gossiped Ring when used in combination with the previous version of Cortex. Easiest way to upgrade is to shutdown old Cortex installation, and restart it with new version. Incremental rollout works too, but with reduced functionality until all components run the same version. #2016 [FEATURE] Added a read-only local alertmanager config store using files named corresponding to their tenant id. #2125 [FEATURE] Added flag -experimental.ruler.enable-api to enable the ruler api which implements the Prometheus API /api/v1/rules and /api/v1/alerts endpoints under the configured -http.prefix. #1999 [FEATURE] Added sharding support to compactor when using the experimental TSDB blocks storage. #2113 [FEATURE] Added ability to override YAML config file settings using environment variables. #2147 -config.expand-env [FEATURE] Added flags to disable Alertmanager notifications methods. #2187 -configs.notifications.disable-email -configs.notifications.disable-webhook [FEATURE] Add /config HTTP endpoint which exposes the current Cortex configuration as YAML. #2165 [FEATURE] Allow Prometheus remote write directly to ingesters. #1491 [FEATURE] Introduced new standalone service query-tee that can be used for testing purposes to send the same Prometheus query to multiple backends (ie. two Cortex clusters ingesting the same metrics) and compare the performances. #2203 [FEATURE] Fan out parallelizable queries to backend queriers concurrently. #1878 querier.parallelise-shardable-queries (bool) Requires a shard-compatible schema (v10+) This causes the number of traces to increase accordingly. The query-frontend now requires a schema config to determine how/when to shard queries, either from a file or from flags (i.e. by the config-yaml CLI flag). This is the same schema config the queriers consume. The schema is only required to use this option. It\u0026rsquo;s also advised to increase downstream concurrency controls as well: querier.max-outstanding-requests-per-tenant querier.max-query-parallelism querier.max-concurrent server.grpc-max-concurrent-streams (for both query-frontends and queriers) [FEATURE] Added user sub rings to distribute users to a subset of ingesters. #1947 -experimental.distributor.user-subring-size [FEATURE] Add flag -experimental.tsdb.stripe-size to expose TSDB stripe size option. #2185 [FEATURE] Experimental Delete Series: Added support for Deleting Series with Prometheus style API. Needs to be enabled first by setting -purger.enable to true. Deletion only supported when using boltdb and filesystem as index and object store respectively. Support for other stores to follow in separate PRs #2103 [ENHANCEMENT] Alertmanager: Expose Per-tenant alertmanager metrics #2124 [ENHANCEMENT] Add status label to cortex_alertmanager_configs metric to gauge the number of valid and invalid configs. #2125 [ENHANCEMENT] Cassandra Authentication: added the custom_authenticators config option that allows users to authenticate with cassandra clusters using password authenticators that are not approved by default in gocql #2093 [ENHANCEMENT] Cassandra Storage: added max_retries, retry_min_backoff and retry_max_backoff configuration options to enable retrying recoverable errors. #2054 [ENHANCEMENT] Allow to configure HTTP and gRPC server listen address, maximum number of simultaneous connections and connection keepalive settings. -server.http-listen-address -server.http-conn-limit -server.grpc-listen-address -server.grpc-conn-limit -server.grpc.keepalive.max-connection-idle -server.grpc.keepalive.max-connection-age -server.grpc.keepalive.max-connection-age-grace -server.grpc.keepalive.time -server.grpc.keepalive.timeout [ENHANCEMENT] PostgreSQL: Bump up github.com/lib/pq from v1.0.0 to v1.3.0 to support PostgreSQL SCRAM-SHA-256 authentication. #2097 [ENHANCEMENT] Cassandra Storage: User no longer need CREATE privilege on \u0026lt;all keyspaces\u0026gt; if given keyspace exists. #2032 [ENHANCEMENT] Cassandra Storage: added password_file configuration options to enable reading Cassandra password from file. #2096 [ENHANCEMENT] Configs API: Allow GET/POST configs in YAML format. #2181 [ENHANCEMENT] Background cache writes are batched to improve parallelism and observability. #2135 [ENHANCEMENT] Add automatic repair for checkpoint and WAL. #2105 [ENHANCEMENT] Support lastEvaluation and evaluationTime in /api/v1/rules endpoints and make order of groups stable. #2196 [ENHANCEMENT] Skip expired requests in query-frontend scheduling. #2082 [ENHANCEMENT] Add ability to configure gRPC keepalive settings. #2066 [ENHANCEMENT] Experimental TSDB: Export TSDB Syncer metrics from Compactor component, they are prefixed with cortex_compactor_. #2023 [ENHANCEMENT] Experimental TSDB: Added dedicated flag -experimental.tsdb.bucket-store.tenant-sync-concurrency to configure the maximum number of concurrent tenants for which blocks are synched. #2026 [ENHANCEMENT] Experimental TSDB: Expose metrics for objstore operations (prefixed with cortex_\u0026lt;component\u0026gt;_thanos_objstore_, component being one of ingester, querier and compactor). #2027 [ENHANCEMENT] Experimental TSDB: Added support for Azure Storage to be used for block storage, in addition to S3 and GCS. #2083 [ENHANCEMENT] Experimental TSDB: Reduced memory allocations in the ingesters when using the experimental blocks storage. #2057 [ENHANCEMENT] Experimental Memberlist KV: expose -memberlist.gossip-to-dead-nodes-time and -memberlist.dead-node-reclaim-time options to control how memberlist library handles dead nodes and name reuse. #2131 [BUGFIX] Alertmanager: fixed panic upon applying a new config, caused by duplicate metrics registration in the NewPipelineBuilder function. #211 [BUGFIX] Azure Blob ChunkStore: Fixed issue causing invalid chunk checksum errors. #2074 [BUGFIX] The gauge cortex_overrides_last_reload_successful is now only exported by components that use a RuntimeConfigManager. Previously, for components that do not initialize a RuntimeConfigManager (such as the compactor) the gauge was initialized with 0 (indicating error state) and then never updated, resulting in a false-negative permanent error state. #2092 [BUGFIX] Fixed WAL metric names, added the cortex_ prefix. [BUGFIX] Restored histogram cortex_configs_request_duration_seconds #2138 [BUGFIX] Fix wrong syntax for url in config-file-reference. #2148 [BUGFIX] Fixed some 5xx status code returned by the query-frontend when they should actually be 4xx. #2122 [BUGFIX] Fixed leaked goroutines in the querier. #2070 [BUGFIX] Experimental TSDB: fixed /all_user_stats and /api/prom/user_stats endpoints when using the experimental TSDB blocks storage. #2042 [BUGFIX] Experimental TSDB: fixed ruler to correctly work with the experimental TSDB blocks storage. #2101 Changes to denormalised tokens in the ring Cortex 0.4.0 is the last version that can write denormalised tokens. Cortex 0.5.0 and above always write normalised tokens.\nCortex 0.6.0 is the last version that can read denormalised tokens. Starting with Cortex 0.7.0 only normalised tokens are supported, and ingesters writing denormalised tokens to the ring (running Cortex 0.4.0 or earlier with -ingester.normalise-tokens=false) are ignored by distributors. Such ingesters should either switch to using normalised tokens, or be upgraded to Cortex 0.5.0 or later.\nKnown issues The gRPC streaming for ingesters doesn\u0026rsquo;t work when using the experimental TSDB blocks storage. Please do not enable -querier.ingester-streaming if you\u0026rsquo;re using the TSDB blocks storage. If you want to enable it, you can build Cortex from master given the issue has been fixed after Cortex 0.7 branch has been cut and the fix wasn\u0026rsquo;t included in the 0.7 because related to an experimental feature. Annotated config file breaking changes In this section you can find a config file diff showing the breaking changes introduced in Cortex 0.7. You can also find the full configuration file reference doc in the website.\n### Root level config # \u0026#34;configdb\u0026#34; has been moved to \u0026#34;alertmanager \u0026gt; store \u0026gt; configdb\u0026#34;. -[configdb: \u0026lt;configdb_config\u0026gt;] # \u0026#34;config_store\u0026#34; has been renamed to \u0026#34;configs\u0026#34;. -[config_store: \u0026lt;configstore_config\u0026gt;] +[configs: \u0026lt;configs_config\u0026gt;] ### `distributor_config` # The support to hook an external billing system has been removed. -[enable_billing: \u0026lt;boolean\u0026gt; | default = false] -billing: - [maxbufferedevents: \u0026lt;int\u0026gt; | default = 1024] - [retrydelay: \u0026lt;duration\u0026gt; | default = 500ms] - [ingesterhostport: \u0026lt;string\u0026gt; | default = \u0026#34;localhost:24225\u0026#34;] ### `querier_config` # \u0026#34;ingestermaxquerylookback\u0026#34; has been renamed to \u0026#34;query_ingesters_within\u0026#34;. -[ingestermaxquerylookback: \u0026lt;duration\u0026gt; | default = 0s] +[query_ingesters_within: \u0026lt;duration\u0026gt; | default = 0s] ### `queryrange_config` results_cache: cache: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] # \u0026#34;cache_split_interval\u0026#34; has been deprecated in favor of \u0026#34;split_queries_by_interval\u0026#34;. - [cache_split_interval: \u0026lt;duration\u0026gt; | default = 24h0m0s] ### `alertmanager_config` # The \u0026#34;store\u0026#34; config block has been added. This includes \u0026#34;configdb\u0026#34; which previously # was the \u0026#34;configdb\u0026#34; root level config block. +store: + [type: \u0026lt;string\u0026gt; | default = \u0026#34;configdb\u0026#34;] + [configdb: \u0026lt;configstore_config\u0026gt;] + local: + [path: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] ### `storage_config` index_queries_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] ### `chunk_store_config` chunk_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] write_dedupe_cache_config: # \u0026#34;defaul_validity\u0026#34; has been renamed to \u0026#34;default_validity\u0026#34;. - [defaul_validity: \u0026lt;duration\u0026gt; | default = 0s] + [default_validity: \u0026lt;duration\u0026gt; | default = 0s] # \u0026#34;min_chunk_age\u0026#34; has been removed in favor of \u0026#34;querier \u0026gt; query_store_after\u0026#34;. -[min_chunk_age: \u0026lt;duration\u0026gt; | default = 0s] ### `configs_config` -# \u0026#34;uri\u0026#34; has been moved to \u0026#34;database \u0026gt; uri\u0026#34;. -[uri: \u0026lt;string\u0026gt; | default = \u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;] -# \u0026#34;migrationsdir\u0026#34; has been moved to \u0026#34;database \u0026gt; migrations_dir\u0026#34;. -[migrationsdir: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] -# \u0026#34;passwordfile\u0026#34; has been moved to \u0026#34;database \u0026gt; password_file\u0026#34;. -[passwordfile: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] +database: + [uri: \u0026lt;string\u0026gt; | default = \u0026#34;postgres://postgres@configs-db.weave.local/configs?sslmode=disable\u0026#34;] + [migrations_dir: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] + [password_file: \u0026lt;string\u0026gt; | default = \u0026#34;\u0026#34;] 0.6.1 / 2020-02-05 [BUGFIX] Fixed parsing of the WAL configuration when specified in the YAML config file. #2071 0.6.0 / 2020-01-28 Note that the ruler flags need to be changed in this upgrade. You\u0026rsquo;re moving from a single node ruler to something that might need to be sharded. Further, if you\u0026rsquo;re using the configs service, we\u0026rsquo;ve upgraded the migration library and this requires some manual intervention. See full instructions below to upgrade your PostgreSQL.\n [CHANGE] The frontend component now does not cache results if it finds a Cache-Control header and if one of its values is no-store. #1974 [CHANGE] Flags changed with transition to upstream Prometheus rules manager: -ruler.client-timeout is now ruler.configs.client-timeout in order to match ruler.configs.url. -ruler.group-timeouthas been removed. -ruler.num-workers has been removed. -ruler.rule-path has been added to specify where the prometheus rule manager will sync rule files. -ruler.storage.type has beem added to specify the rule store backend type, currently only the configdb. -ruler.poll-interval has been added to specify the interval in which to poll new rule groups. -ruler.evaluation-interval default value has changed from 15s to 1m to match the default evaluation interval in Prometheus. Ruler sharding requires a ring which can be configured via the ring flags prefixed by ruler.ring.. #1987 [CHANGE] Use relative links from /ring page to make it work when used behind reverse proxy. #1896 [CHANGE] Deprecated -distributor.limiter-reload-period flag. #1766 [CHANGE] Ingesters now write only normalised tokens to the ring, although they can still read denormalised tokens used by other ingesters. -ingester.normalise-tokens is now deprecated, and ignored. If you want to switch back to using denormalised tokens, you need to downgrade to Cortex 0.4.0. Previous versions don\u0026rsquo;t handle claiming tokens from normalised ingesters correctly. #1809 [CHANGE] Overrides mechanism has been renamed to \u0026ldquo;runtime config\u0026rdquo;, and is now separate from limits. Runtime config is simply a file that is reloaded by Cortex every couple of seconds. Limits and now also multi KV use this mechanism.\nNew arguments were introduced: -runtime-config.file (defaults to empty) and -runtime-config.reload-period (defaults to 10 seconds), which replace previously used -limits.per-user-override-config and -limits.per-user-override-period options. Old options are still used if -runtime-config.file is not specified. This change is also reflected in YAML configuration, where old limits.per_tenant_override_config and limits.per_tenant_override_period fields are replaced with runtime_config.file and runtime_config.period respectively. #1749 [CHANGE] Cortex now rejects data with duplicate labels. Previously, such data was accepted, with duplicate labels removed with only one value left. #1964 [CHANGE] Changed the default value for -distributor.ha-tracker.prefix from collectors/ to ha-tracker/ in order to not clash with other keys (ie. ring) stored in the same key-value store. #1940 [FEATURE] Experimental: Write-Ahead-Log added in ingesters for more data reliability against ingester crashes. #1103 --ingester.wal-enabled: Setting this to true enables writing to WAL during ingestion. --ingester.wal-dir: Directory where the WAL data should be stored and/or recovered from. --ingester.checkpoint-enabled: Set this to true to enable checkpointing of in-memory chunks to disk. --ingester.checkpoint-duration: This is the interval at which checkpoints should be created. --ingester.recover-from-wal: Set this to true to recover data from an existing WAL. For more information, please checkout the \u0026ldquo;Ingesters with WAL\u0026rdquo; guide. [FEATURE] The distributor can now drop labels from samples (similar to the removal of the replica label for HA ingestion) per user via the distributor.drop-label flag. #1726 [FEATURE] Added flag debug.mutex-profile-fraction to enable mutex profiling #1969 [FEATURE] Added global ingestion rate limiter strategy. Deprecated -distributor.limiter-reload-period flag. #1766 [FEATURE] Added support for Microsoft Azure blob storage to be used for storing chunk data. #1913 [FEATURE] Added readiness probe endpoint/ready to queriers. #1934 [FEATURE] Added \u0026ldquo;multi\u0026rdquo; KV store that can interact with two other KV stores, primary one for all reads and writes, and secondary one, which only receives writes. Primary/secondary store can be modified in runtime via runtime-config mechanism (previously \u0026ldquo;overrides\u0026rdquo;). #1749 [FEATURE] Added support to store ring tokens to a file and read it back on startup, instead of generating/fetching the tokens to/from the ring. This feature can be enabled with the flag -ingester.tokens-file-path. #1750 [FEATURE] Experimental TSDB: Added /series API endpoint support with TSDB blocks storage. #1830 [FEATURE] Experimental TSDB: Added TSDB blocks compactor component, which iterates over users blocks stored in the bucket and compact them according to the configured block ranges. #1942 [ENHANCEMENT] metric cortex_ingester_flush_reasons gets a new reason value: Spread, when -ingester.spread-flushes option is enabled. #1978 [ENHANCEMENT] Added password and enable_tls options to redis cache configuration. Enables usage of Microsoft Azure Cache for Redis service. #1923 [ENHANCEMENT] Upgraded Kubernetes API version for deployments from extensions/v1beta1 to apps/v1. #1941 [ENHANCEMENT] Experimental TSDB: Open existing TSDB on startup to prevent ingester from becoming ready before it can accept writes. The max concurrency is set via --experimental.tsdb.max-tsdb-opening-concurrency-on-startup. #1917 [ENHANCEMENT] Experimental TSDB: Querier now exports aggregate metrics from Thanos bucket store and in memory index cache (many metrics to list, but all have cortex_querier_bucket_store_ or cortex_querier_blocks_index_cache_ prefix). #1996 [ENHANCEMENT] Experimental TSDB: Improved multi-tenant bucket store. #1991 Allowed to configure the blocks sync interval via -experimental.tsdb.bucket-store.sync-interval (0 disables the sync) Limited the number of tenants concurrently synched by -experimental.tsdb.bucket-store.block-sync-concurrency Renamed cortex_querier_sync_seconds metric to cortex_querier_blocks_sync_seconds Track cortex_querier_blocks_sync_seconds metric for the initial sync too [BUGFIX] Fixed unnecessary CAS operations done by the HA tracker when the jitter is enabled. #1861 [BUGFIX] Fixed ingesters getting stuck in a LEAVING state after coming up from an ungraceful exit. #1921 [BUGFIX] Reduce memory usage when ingester Push() errors. #1922 [BUGFIX] Table Manager: Fixed calculation of expected tables and creation of tables from next active schema considering grace period. #1976 [BUGFIX] Experimental TSDB: Fixed ingesters consistency during hand-over when using experimental TSDB blocks storage. #1854 #1818 [BUGFIX] Experimental TSDB: Fixed metrics when using experimental TSDB blocks storage. #1981 #1982 #1990 #1983 [BUGFIX] Experimental memberlist: Use the advertised address when sending packets to other peers of the Gossip memberlist. #1857 [BUGFIX] Experimental TSDB: Fixed incorrect query results introduced in #2604 caused by a buffer incorrectly reused while iterating samples. #2697 Upgrading PostgreSQL (if you\u0026rsquo;re using configs service) Reference: https://github.com/golang-migrate/migrate/tree/master/database/postgres#upgrading-from-v1\n Install the migrate package cli tool: https://github.com/golang-migrate/migrate/tree/master/cmd/migrate#installation Drop the schema_migrations table: DROP TABLE schema_migrations;. Run the migrate command: migrate -path \u0026lt;absolute_path_to_cortex\u0026gt;/cmd/cortex/migrations -database postgres://localhost:5432/database force 2 Known issues The cortex_prometheus_rule_group_last_evaluation_timestamp_seconds metric, tracked by the ruler, is not unregistered for rule groups not being used anymore. This issue will be fixed in the next Cortex release (see 2033).\n Write-Ahead-Log (WAL) does not have automatic repair of corrupt checkpoint or WAL segments, which is possible if ingester crashes abruptly or the underlying disk corrupts. Currently the only way to resolve this is to manually delete the affected checkpoint and/or WAL segments. Automatic repair will be added in the future releases.\n 0.4.0 / 2019-12-02 [CHANGE] The frontend component has been refactored to be easier to re-use. When upgrading the frontend, cache entries will be discarded and re-created with the new protobuf schema. #1734 [CHANGE] Removed direct DB/API access from the ruler. -ruler.configs.url has been now deprecated. #1579 [CHANGE] Removed Delta encoding. Any old chunks with Delta encoding cannot be read anymore. If ingester.chunk-encoding is set to Delta the ingester will fail to start. #1706 [CHANGE] Setting -ingester.max-transfer-retries to 0 now disables hand-over when ingester is shutting down. Previously, zero meant infinite number of attempts. #1771 [CHANGE] dynamo has been removed as a valid storage name to make it consistent for all components. aws and aws-dynamo remain as valid storage names. [CHANGE/FEATURE] The frontend split and cache intervals can now be configured using the respective flag --querier.split-queries-by-interval and --frontend.cache-split-interval. If --querier.split-queries-by-interval is not provided request splitting is disabled by default. --querier.split-queries-by-day is still accepted for backward compatibility but has been deprecated. You should now use --querier.split-queries-by-interval. We recommend a to use a multiple of 24 hours. [FEATURE] Global limit on the max series per user and metric #1760 -ingester.max-global-series-per-user -ingester.max-global-series-per-metric Requires -distributor.replication-factor and -distributor.shard-by-all-labels set for the ingesters too [FEATURE] Flush chunks with stale markers early with ingester.max-stale-chunk-idle. #1759 [FEATURE] EXPERIMENTAL: Added new KV Store backend based on memberlist library. Components can gossip about tokens and ingester states, instead of using Consul or Etcd. #1721 [FEATURE] EXPERIMENTAL: Use TSDB in the ingesters \u0026amp; flush blocks to S3/GCS ala Thanos. This will let us use an Object Store more efficiently and reduce costs. #1695 [FEATURE] Allow Query Frontend to log slow queries with frontend.log-queries-longer-than. #1744 [FEATURE] Add HTTP handler to trigger ingester flush \u0026amp; shutdown - used when running as a stateful set with the WAL enabled. #1746 [FEATURE] EXPERIMENTAL: Added GCS support to TSDB blocks storage. #1772 [ENHANCEMENT] Reduce memory allocations in the write path. #1706 [ENHANCEMENT] Consul client now follows recommended practices for blocking queries wrt returned Index value. #1708 [ENHANCEMENT] Consul client can optionally rate-limit itself during Watch (used e.g. by ring watchers) and WatchPrefix (used by HA feature) operations. Rate limiting is disabled by default. New flags added: --consul.watch-rate-limit, and --consul.watch-burst-size. #1708 [ENHANCEMENT] Added jitter to HA deduping heartbeats, configure using distributor.ha-tracker.update-timeout-jitter-max #1534 [ENHANCEMENT] Add ability to flush chunks with stale markers early. #1759 [BUGFIX] Stop reporting successful actions as 500 errors in KV store metrics. #1798 [BUGFIX] Fix bug where duplicate labels can be returned through metadata APIs. #1790 [BUGFIX] Fix reading of old, v3 chunk data. #1779 [BUGFIX] Now support IAM roles in service accounts in AWS EKS. #1803 [BUGFIX] Fixed duplicated series returned when querying both ingesters and store with the experimental TSDB blocks storage. #1778 In this release we updated the following dependencies:\n gRPC v1.25.0 (resulted in a drop of 30% CPU usage when compression is on) jaeger-client v2.20.0 aws-sdk-go to v1.25.22 0.3.0 / 2019-10-11 This release adds support for Redis as an alternative to Memcached, and also includes many optimisations which reduce CPU and memory usage.\n [CHANGE] Gauge metrics were renamed to drop the _total suffix. #1685 In Alertmanager, alertmanager_configs_total is now alertmanager_configs In Ruler, scheduler_configs_total is now scheduler_configs scheduler_groups_total is now scheduler_groups. [CHANGE] --alertmanager.configs.auto-slack-root flag was dropped as auto Slack root is not supported anymore. #1597 [CHANGE] In table-manager, default DynamoDB capacity was reduced from 3,000 units to 1,000 units. We recommend you do not run with the defaults: find out what figures are needed for your environment and set that via -dynamodb.periodic-table.write-throughput and -dynamodb.chunk-table.write-throughput. [FEATURE] Add Redis support for caching #1612 [FEATURE] Allow spreading chunk writes across multiple S3 buckets #1625 [FEATURE] Added /shutdown endpoint for ingester to shutdown all operations of the ingester. #1746 [ENHANCEMENT] Upgraded Prometheus to 2.12.0 and Alertmanager to 0.19.0. #1597 [ENHANCEMENT] Cortex is now built with Go 1.13 #1675, #1676, #1679 [ENHANCEMENT] Many optimisations, mostly impacting ingester and querier: #1574, #1624, #1638, #1644, #1649, #1654, #1702 Full list of changes: https://github.com/cortexproject/cortex/compare/v0.2.0...v0.3.0\n0.2.0 / 2019-09-05 This release has several exciting features, the most notable of them being setting -ingester.spread-flushes to potentially reduce your storage space by upto 50%.\n [CHANGE] Flags changed due to changes upstream in Prometheus Alertmanager #929: alertmanager.mesh.listen-address is now cluster.listen-address alertmanager.mesh.peer.host and alertmanager.mesh.peer.service can be replaced by cluster.peer alertmanager.mesh.hardware-address, alertmanager.mesh.nickname, alertmanager.mesh.password, and alertmanager.mesh.peer.refresh-interval all disappear. [CHANGE] \u0026ndash;claim-on-rollout flag deprecated; feature is now always on #1566 [CHANGE] Retention period must now be a multiple of periodic table duration #1564 [CHANGE] The value for the name label for the chunks memcache in all cortex_cache_ metrics is now chunksmemcache (before it was memcache) #1569 [FEATURE] Makes the ingester flush each timeseries at a specific point in the max-chunk-age cycle with -ingester.spread-flushes. This means multiple replicas of a chunk are very likely to contain the same contents which cuts chunk storage space by up to 66%. #1578 [FEATURE] Make minimum number of chunk samples configurable per user #1620 [FEATURE] Honor HTTPS for custom S3 URLs #1603 [FEATURE] You can now point the query-frontend at a normal Prometheus for parallelisation and caching #1441 [FEATURE] You can now specify http_config on alert receivers #929 [FEATURE] Add option to use jump hashing to load balance requests to memcached #1554 [FEATURE] Add status page for HA tracker to distributors #1546 [FEATURE] The distributor ring page is now easier to read with alternate rows grayed out #1621 0.1.0 / 2019-08-07 [CHANGE] HA Tracker flags were renamed to provide more clarity #1465 distributor.accept-ha-labels is now distributor.ha-tracker.enable distributor.accept-ha-samples is now distributor.ha-tracker.enable-for-all-users ha-tracker.replica is now distributor.ha-tracker.replica ha-tracker.cluster is now distributor.ha-tracker.cluster [FEATURE] You can specify \u0026ldquo;heap ballast\u0026rdquo; to reduce Go GC Churn #1489 [BUGFIX] HA Tracker no longer always makes a request to Consul/Etcd when a request is not from the active replica #1516 [BUGFIX] Queries are now correctly cancelled by the query-frontend #1508 ","excerpt":"master / unreleased [CHANGE] Blocks storage: update the default HTTP configuration values for the …","ref":"/docs/changelog/","title":"Changelog"},{"body":"","excerpt":"","ref":"/docs/proposals/","title":"Proposals"},{"body":"Cortex follows the CNCF Code of Conduct.\n","excerpt":"Cortex follows the CNCF Code of Conduct.","ref":"/docs/code-of-conduct/","title":"Code of Conduct"},{"body":"The following is only a selection of some of the major features we plan to implement in the near future. To get a more complete overview of planned features and current work, see the issue trackers for the various repositories, for example, the Cortex repo. Note that these are not ordered by priority.\nHelm charts and other packaging We have a helm chart but it needs work before it can be effectively utilised by different backends. We also don\u0026rsquo;t provide an official set of dashboards and alerts to our users yet. This is one of the most requested features and something we will tackle in the immediate future. We also plan on publishing debs, rpms along with guides on how to run Cortex on bare-metal.\nAuth Gateway Cortex server has a simple authentication mechanism (X-Scope-OrgId) but users can\u0026rsquo;t use the multitenancy features out of the box without complicated proxy configuration. It\u0026rsquo;s hard to support all the different authentication mechanisms used by different companies but plan to have a simple but opinionated auth-gateway that provides value out of the box. The configuration could be as simple as:\ntenants: - name: infra-team password: basic-auth-password - name: api-team password: basic-auth-password2 Billing and Usage analytics We have all the metrics to track how many series, samples and queries each tenant is sending but don\u0026rsquo;t have dashboards that help with this. We plan to have dashboards and UIs that will help operators monitor and control each tenants usage out of the box.\nDownsampling and Per tenant/metric retention Currently, we only support a single retention period for all metrics and tenants. For most operators, the ability to set per tenant retention and also custom retention for subsets of metrics is important. We will add support per tenant and metric retention policies. Also, we currently store all the samples we ingested, and there is no way to reduce the resolution for the metrics. We plan to add downsampling to allow users to store less data when needed.\nSoft Multitenancy Currently our multitenancy allows a tenant to view all their metrics and only their metrics. There is no way for an \u0026ldquo;admin\u0026rdquo; tenant to view all the metrics in the system but for particular teams to only view theirs. This is another feature we plan to add into Cortex.\nExemplar and Prometheus metadata support There is currently an ongoing effort in Prometheus to add exemplar support and we should be an active stakeholder in the discussion. The plan is to propagate the exemplars through remote write and make them available for querying in Cortex. We currently have experimental metadata support for Prometheus but this is using the Grafana Cloud Agent. We should help move this PR forward and also add persistence of the metadata (right now it\u0026rsquo;s only in-mem).\nBulk loading historical data This is another highly requested features. There is currently no way to backfill the existing data in local Prometheus to Cortex. The plan is to add an API for users to ship the TSDB blocks to Cortex and a side-car / command to do this.\nScalability Scalability has always been a focus for the project, but there is a lot more work to be done. We can now scale to 100s of Millions of active series but 1 Billion active series is still an unknown. We also need to make the Alertmanager horizontally scalable with the number of users.\n","excerpt":"The following is only a selection of some of the major features we plan to implement in the near …","ref":"/docs/roadmap/","title":"Roadmap"},{"body":"Because Cortex is designed to run multiple instances of each component (ingester, querier, etc.), you probably want to automate the placement and shepherding of these instances. Most users choose Kubernetes to do this, but this is not mandatory.\nConfiguration Resource requests If using Kubernetes, each container should specify resource requests so that the scheduler can place them on a node with sufficient capacity.\nFor example an ingester might request:\n resources: requests: cpu: 4 memory: 10Gi The specific values here should be adjusted based on your own experiences running Cortex - they are very dependent on rate of data arriving and other factors such as series churn.\nTake extra care with ingesters Ingesters hold hours of timeseries data in memory; you can configure Cortex to replicate the data but you should take steps to avoid losing all replicas at once:\n Don\u0026rsquo;t run multiple ingesters on the same node. Don\u0026rsquo;t run ingesters on preemptible/spot nodes. Spread out ingesters across racks / availability zones / whatever applies in your datacenters. You can ask Kubernetes to avoid running on the same node like this:\n affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: name operator: In values: - ingester topologyKey: \u0026quot;kubernetes.io/hostname\u0026quot; Give plenty of time for an ingester to hand over or flush data to store when shutting down; for Kubernetes this looks like:\n terminationGracePeriodSeconds: 2400 Ask Kubernetes to limit rolling updates to one ingester at a time, and signal the old one to stop before the new one is ready:\n strategy: rollingUpdate: maxSurge: 0 maxUnavailable: 1 Ingesters provide an HTTP hook to signal readiness when all is well; this is valuable because it stops a rolling update at the first problem:\n readinessProbe: httpGet: path: /ready port: 80 We do not recommend configuring a liveness probe on ingesters - killing them is a last resort and should not be left to a machine.\n","excerpt":"Because Cortex is designed to run multiple instances of each component (ingester, querier, etc.), …","ref":"/docs/guides/kubernetes/","title":"Running Cortex on Kubernetes"},{"body":"Cortex uses Jaeger to implement distributed tracing. We have found Jaeger invaluable for troubleshooting the behavior of Cortex in production.\nDependencies In order to send traces you will need to set up a Jaeger deployment. A deployment includes either the jaeger all-in-one binary, or else a distributed system of agents, collectors, and queriers. If running on Kubernetes, Jaeger Kubernetes is an excellent resource.\nConfiguration In order to configure Cortex to send traces you must do two things:\n Set the JAEGER_AGENT_HOST environment variable in all components to point to your Jaeger agent. This defaults to localhost. Enable sampling in the appropriate components: The Ingester and Ruler self-initiate traces and should have sampling explicitly enabled. Sampling for the Distributor and Query Frontend can be enabled in Cortex or in an upstream service such as your frontdoor. To enable sampling in Cortex components you can specify either JAEGER_SAMPLER_MANAGER_HOST_PORT for remote sampling, or JAEGER_SAMPLER_TYPE and JAEGER_SAMPLER_PARAM to manually set sampling configuration. See the Jaeger Client Go documentation for the full list of environment variables you can configure.\nNote that you must specify one of JAEGER_AGENT_HOST or JAEGER_SAMPLER_MANAGER_HOST_PORT in each component for Jaeger to be enabled, even if you plan to use the default values.\n","excerpt":"Cortex uses Jaeger to implement distributed tracing. We have found Jaeger invaluable for …","ref":"/docs/guides/tracing/","title":"Tracing"},{"body":"Cortex ingesters are semi-stateful. A running ingester holds several hours of time series data in memory, before they\u0026rsquo;re flushed to the long-term storage. When an ingester shutdowns, because of a rolling update or maintenance, the in-memory data must not be discarded in order to avoid any data loss.\nIn this document we describe the techniques employed to safely handle rolling updates, based on different setups:\n Blocks storage Chunks storage with WAL enabled Chunks storage with WAL disabled Blocks storage The Cortex blocks storage requires ingesters to run with a persistent disk where the TSDB WAL and blocks are stored (eg. a StatefulSet when deployed on Kubernetes).\nDuring a rolling update, the leaving ingester closes the open TSDBs, synchronize the data to disk (fsync) and releases the disk resources. The new ingester, which is expected to reuse the same disk of the leaving one, will replay the TSDB WAL on startup in order to load back in memory the time series that have not been compacted into a block yet.\nThe blocks storage doesn\u0026rsquo;t support the series hand-over.\nChunks storage The Cortex chunks storage optionally supports a write-ahead log (WAL). The rolling update procedure for a Cortex cluster running the chunks storage depends whether the WAL is enabled or not.\nChunks storage with WAL enabled Similarly to the blocks storage, when Cortex is running the chunks storage with WAL enabled, it requires ingesters to run with a persistent disk where the WAL is stored (eg. a StatefulSet when deployed on Kubernetes).\nDuring a rolling update, the leaving ingester closes the WAL, synchronize the data to disk (fsync) and releases the disk resources. The new ingester, which is expected to reuse the same disk of the leaving one, will replay the WAL on startup in order to load back in memory the time series data.\nFor more information about the WAL, please refer to Ingesters with WAL.\nChunks storage with WAL disabled (hand-over) When Cortex is running the chunks storage with WAL disabled, Cortex supports on-the-fly series hand-over between a leaving ingester and a joining one.\nThe hand-over is based on the ingesters state stored in the ring. Each ingester could be in one of the following states:\n PENDING JOINING ACTIVE LEAVING On startup, an ingester goes into the PENDING state. In this state, the ingester is waiting for a hand-over from another ingester that is LEAVING. If no hand-over occurs within the configured timeout period (\u0026ldquo;auto-join timeout\u0026rdquo;, configurable via -ingester.join-after option), the ingester will join the ring with a new set of random tokens (eg. during a scale up) and will switch its state to ACTIVE.\nWhen a running ingester in the ACTIVE state is notified to shutdown via SIGINT or SIGTERM Unix signal, the ingester switches to LEAVING state. In this state it cannot receive write requests anymore, but it can still receive read requests for series it has in memory.\nA LEAVING ingester looks for a PENDING ingester to start a hand-over process with. If it finds one, that ingester goes into the JOINING state and the leaver transfers all its in-memory data over to the joiner. On successful transfer the leaver removes itself from the ring and exits, while the joiner changes its state to ACTIVE, taking over ownership of the leaver\u0026rsquo;s ring tokens. As soon as the joiner switches it state to ACTIVE, it will start receive both write requests from distributors and queries from queriers.\nIf the LEAVING ingester does not find a PENDING ingester after -ingester.max-transfer-retries retries, it will flush all of its chunks to the long-term storage, then removes itself from the ring and exits. The chunks flushing to the storage may take several minutes to complete.\nHigher number of series / chunks during rolling updates During hand-over, neither the leaving nor joining ingesters will accept new samples. Distributors are aware of this, and \u0026ldquo;spill\u0026rdquo; the samples to the next ingester in the ring. This creates a set of extra \u0026ldquo;spilled\u0026rdquo; series and chunks which will idle out and flush after hand-over is complete.\nObservability The following metrics can be used to observe this process:\n cortex_member_ring_tokens_owned\nHow many tokens each ingester thinks it owns. cortex_ring_tokens_owned\nHow many tokens each ingester is seen to own by other components. cortex_ring_member_ownership_percent\nSame as cortex_ring_tokens_owned but expressed as a percentage. cortex_ring_members\nHow many ingesters can be seen in each state, by other components. cortex_ingester_sent_chunks\nNumber of chunks sent by leaving ingester. cortex_ingester_received_chunks\nNumber of chunks received by joining ingester. You can see the current state of the ring via http browser request to /ring on a distributor.\n","excerpt":"Cortex ingesters are semi-stateful. A running ingester holds several hours of time series data in …","ref":"/docs/guides/ingesters-rolling-updates/","title":"Ingesters rolling updates"},{"body":"You will want to estimate how many nodes are required, how many of each component to run, and how much storage space will be required. In practice, these will vary greatly depending on the metrics being sent to Cortex.\nSome key parameters are:\n The number of active series. If you have Prometheus already you can query prometheus_tsdb_head_series to see this number. Sampling rate, e.g. a new sample for each series every minute (the default Prometheus scrape_interval). Multiply this by the number of active series to get the total rate at which samples will arrive at Cortex. The rate at which series are added and removed. This can be very high if you monitor objects that come and go - for example if you run thousands of batch jobs lasting a minute or so and capture metrics with a unique ID for each one. Read how to analyse this on Prometheus. How compressible the time-series data are. If a metric stays at the same value constantly, then Cortex can compress it very well, so 12 hours of data sampled every 15 seconds would be around 2KB. On the other hand if the value jumps around a lot it might take 10KB. There are not currently any tools available to analyse this. How long you want to retain data for, e.g. 1 month or 2 years. Other parameters which can become important if you have particularly high values:\nNumber of different series under one metric name. Number of labels per series. Rate and complexity of queries. Now, some rules of thumb:\n Each million series in an ingester takes 15GB of RAM. Total number of series in ingesters is number of active series times the replication factor. This is with the default of 12-hour chunks - RAM required will reduce if you set -ingester.max-chunk-age lower (trading off more back-end database IO) Each million series (including churn) consumes 15GB of chunk storage and 4GB of index, per day (so multiply by the retention period). Each 100,000 samples/sec arriving takes 1 CPU in distributors. Distributors don\u0026rsquo;t need much RAM. If you turn on compression between distributors and ingesters (for example to save on inter-zone bandwidth charges at AWS/GCP) they will use significantly more CPU (approx 100% more for distributor and 50% more for ingester).\n","excerpt":"You will want to estimate how many nodes are required, how many of each component to run, and how …","ref":"/docs/guides/capacity-planning/","title":"Capacity Planning"},{"body":"","excerpt":"","ref":"/index.json","title":""},{"body":" Horizontally scalable, highly available, multi-tenant, long term Prometheus. Learn More Releases \n Companies using Cortex\n Long term storage Durably store data for longer than the lifetime of any single machine, and use this data for long term capacity planning. Blazin\u0026rsquo; fast PromQL Cortex makes your PromQL queries blazin' fast through aggressive parallelization and caching. A global view of data Cortex gives you a global view of Prometheus time series data that includes data in long-term storage, greatly expanding the usefulness of PromQL for analytical purposes. Horizontally scalable Cortex runs across multiple machines in a cluster, exceeding the throughput and storage of a single machine. This enables you to send the metrics from multiple Prometheus servers to a single Cortex cluster. We are a Cloud Native Computing Foundation Sandbox project.\n Join the community ! Join users and companies that are using Cortex in production.\n Slack Issues Twitter ","excerpt":"Horizontally scalable, highly available, multi-tenant, long term Prometheus. Learn More Releases …","ref":"/","title":"Cortex"},{"body":"","excerpt":"","ref":"/search/","title":"Search Results"}]